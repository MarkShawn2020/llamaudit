diff --git a/.gitignore b/.gitignore
index 9271fbb..17991ad 100644
--- a/.gitignore
+++ b/.gitignore
@@ -1,3 +1,5 @@
+.obsidian
+
 # See https://help.github.com/articles/ignoring-files/ for more about ignoring files.
 
 # dependencies
diff --git a/app/(core)/projects/[id]/page.tsx b/app/(core)/projects/[id]/page.tsx
index 519fe3c..badccd1 100644
--- a/app/(core)/projects/[id]/page.tsx
+++ b/app/(core)/projects/[id]/page.tsx
@@ -1,6 +1,6 @@
 import { getUser } from '@/lib/db/queries';
 import { redirect } from 'next/navigation';
-import ProjectDetail from '@/components/projects/ProjectDetail';
+import ProjectDetail from '@/components/projects/detail';
 
 export async function generateMetadata({ params }: { params: Promise<{ id: string }> }) {
   const { id } = await params;
diff --git a/app/(core)/projects/page.tsx b/app/(core)/projects/page.tsx
index a9a7d0a..45b3f67 100644
--- a/app/(core)/projects/page.tsx
+++ b/app/(core)/projects/page.tsx
@@ -1,6 +1,6 @@
 import { getUser } from '@/lib/db/queries';
 import { redirect } from 'next/navigation';
-import ProjectsList from '@/components/projects/ProjectsList';
+import ProjectsList from '@/components/projects/list/ProjectsList';
 
 export const metadata = {
   title: '项目管理 - Llamaudit',
diff --git a/components/GlobalNavbar.tsx b/components/GlobalNavbar.tsx
index 1f791d2..79e5622 100644
--- a/components/GlobalNavbar.tsx
+++ b/components/GlobalNavbar.tsx
@@ -8,6 +8,7 @@ import {ShieldAlertIcon} from 'lucide-react';
 import Link from 'next/link';
 import {usePathname} from 'next/navigation';
 import {Logo} from './logo';
+import packageJson from '@/package.json';
 
 // 管理员专用菜单项
 const adminNavItems = [
@@ -23,6 +24,7 @@ export function GlobalNavbar() {
   const pathname = usePathname();
   const isAdmin = user?.role === 'admin';
 
+  const version = packageJson.version;
 
   return (
     <header className="sticky top-0 z-50 bg-white/95 backdrop-blur-sm  max-w-7xl mx-auto w-full border-0 border-b border-gray-200">
@@ -31,7 +33,7 @@ export function GlobalNavbar() {
           <Link href="/" className="flex items-center gap-2 mr-6">
             <Logo/>
             <span className="font-bold text-xl">智审大师</span>
-            <span className="ml-2 text-xs px-1.5 py-0.5 rounded-md bg-primary/10 text-primary border border-primary/20 font-medium">0.2.0(α)</span>
+            <span className="ml-2 text-xs px-1.5 py-0.5 rounded-md bg-primary/10 text-primary border border-primary/20 font-medium">{version}(α)</span>
           </Link>
           
           <nav className="hidden md:flex items-center space-x-4 lg:space-x-6 ml-6">
diff --git a/components/projects/ProjectDetail.tsx b/components/projects/ProjectDetail.tsx
deleted file mode 100644
index 9dafb89..0000000
--- a/components/projects/ProjectDetail.tsx
+++ /dev/null
@@ -1,383 +0,0 @@
-'use client';
-
-import { useEffect, useState } from 'react';
-import { Card, CardContent, CardDescription, CardHeader, CardTitle } from '@/components/ui/card';
-import { Button } from '@/components/ui/button';
-import { ArrowLeft, Building, FileText, BarChart3, TrashIcon, PencilIcon, AlertTriangle, Download } from 'lucide-react';
-import Link from 'next/link';
-import * as XLSX from 'xlsx';
-import { saveAs } from 'file-saver';
-import ProjectInfo from './ProjectInfo';
-import ProjectAnalysis from './ProjectAnalysis';
-import { Project as BaseProject, getProject, deleteProject } from '@/lib/api/project-api';
-import { Table, TableBody, TableCell, TableHead, TableHeader, TableRow } from '@/components/ui/table';
-
-// 扩展Project类型，兼容新旧字段名
-interface TripleOneMajorItem {
-  categoryType: string;
-  details: string;
-  amount: string;
-  departments: string;
-  personnel: string;
-  decisionBasis: string;
-  originalText: string;
-  sourceFile?: string; // 添加来源文件名
-}
-
-interface Project extends BaseProject {
-  fileCount?: number; // 兼容新命名
-  tripleOneMajorItems?: TripleOneMajorItem[];
-}
-import { toast } from 'sonner';
-import { useRouter } from 'next/navigation';
-import {
-  AlertDialog,
-  AlertDialogAction,
-  AlertDialogCancel,
-  AlertDialogContent,
-  AlertDialogDescription,
-  AlertDialogFooter,
-  AlertDialogHeader,
-  AlertDialogTitle,
-} from "@/components/ui/alert-dialog";
-import {
-  Dialog,
-  DialogContent,
-  DialogDescription,
-  DialogHeader,
-  DialogTitle,
-  DialogTrigger,
-} from "@/components/ui/dialog";
-import { logger } from '@/lib/logger';
-
-export default function ProjectDetail({ projectId }: { projectId: string }) {
-  const [project, setProject] = useState<Project | null>(null);
-  const [loading, setLoading] = useState(true);
-  const [error, setError] = useState<string | null>(null);
-  const [deleteDialogOpen, setDeleteDialogOpen] = useState(false);
-  const [deleteLoading, setDeleteLoading] = useState(false);
-  const [showProjectInfo, setShowProjectInfo] = useState(false);
-  // 添加独立的文件计数状态，初始值为项目的文件数量
-  const [fileCount, setFileCount] = useState<number>(0);
-  // 添加提取的三重一大事项
-  const [tripleOneMajorItems, setTripleOneMajorItems] = useState<TripleOneMajorItem[]>([]);
-  const router = useRouter();
-
-  logger.info('ProjectDetail', { projectId, project });
-
-  useEffect(() => {
-    // 加载项目详情
-    loadProject();
-  }, [projectId]);
-
-  const loadProject = async () => {
-    try {
-      setLoading(true);
-      setError(null);
-      const data = await getProject(projectId);
-
-      if (!data) {
-        setError('项目不存在');
-        toast.error('无法找到该项目');
-        return;
-      }
-
-      setProject(data);
-      // 初始化文件计数 - 优先使用实际文件数组长度
-      const count = data.files?.length || 0;
-      setFileCount(count);
-      
-      // 解析所有文件的元数据，提取三重一大事项
-      if (data.files && data.files.length > 0) {
-        const allTripleOneItems: TripleOneMajorItem[] = [];
-        
-        data.files.forEach(file => {
-          if (file.isAnalyzed && file.metadata) {
-            try {
-              // 从metadata字符串中提取JSON部分
-              const metadataStr = file.metadata;
-              const jsonMatch = metadataStr.match(/```json\n([\s\S]*)\n```/);
-              
-              if (jsonMatch && jsonMatch[1]) {
-                const metadata = JSON.parse(jsonMatch[1]);
-                
-                if (metadata.tripleOneMajorItems && metadata.tripleOneMajorItems.length > 0) {
-                  // 添加来源文件信息
-                  const itemsWithSource = metadata.tripleOneMajorItems.map((item: TripleOneMajorItem) => ({
-                    ...item,
-                    sourceFile: file.filename
-                  }));
-                  
-                  allTripleOneItems.push(...itemsWithSource);
-                }
-              }
-            } catch (e) {
-              console.error('解析文件元数据失败:', file.filename, e);
-            }
-          }
-        });
-        
-        setTripleOneMajorItems(allTripleOneItems);
-      }
-    } catch (error) {
-      console.error('加载项目详情失败:', error);
-      setError('加载项目详情失败');
-      toast.error('加载项目详情失败');
-    } finally {
-      setLoading(false);
-    }
-  };
-
-  const handleProjectUpdate = (updated: Partial<Project>) => {
-    if (!project) return;
-    setProject({ ...project, ...updated });
-  };
-
-  // 导出三重一大事项数据函数
-  const exportTripleOneMajorItems = (items: TripleOneMajorItem[]) => {
-    if (!items || items.length === 0) {
-      toast.error('没有可导出的数据');
-      return;
-    }
-
-    try {
-      // 格式化导出数据
-      const exportData = items.map(item => ({
-        '类型': item.categoryType === 'majorProject' ? '重大项目' :
-               item.categoryType === 'majorFund' ? '大额资金' :
-               item.categoryType === 'majorDecision' ? '重大决策' : item.categoryType,
-        '事项内容': item.details,
-        '金额': item.amount,
-        '责任部门': item.departments,
-        '相关人员': item.personnel,
-        '决策依据': item.decisionBasis,
-        '来源文件': item.sourceFile || '未知'
-      }));
-
-      // 创建工作簿
-      const wb = XLSX.utils.book_new();
-      const ws = XLSX.utils.json_to_sheet(exportData);
-      
-      // 添加工作表到工作簿
-      XLSX.utils.book_append_sheet(wb, ws, '三重一大事项');
-      
-      // 生成Excel文件并下载
-      const excelBuffer = XLSX.write(wb, { bookType: 'xlsx', type: 'array' });
-      const blob = new Blob([excelBuffer], { type: 'application/octet-stream' });
-      
-      // 使用当前日期作为文件名的一部分
-      const fileName = `${project?.name || '项目'}_三重一大事项_${new Date().toISOString().split('T')[0]}.xlsx`;
-      saveAs(blob, fileName);
-      
-      toast.success('导出成功');
-    } catch (error) {
-      console.error('导出数据失败:', error);
-      toast.error('导出数据失败，请重试');
-    }
-  };
-
-  const handleDeleteProject = async () => {
-    if (!project) return;
-
-    try {
-      setDeleteLoading(true);
-      const success = await deleteProject(project.id);
-
-      if (success) {
-        toast.success('项目已成功删除');
-        router.push('/projects');
-      } else {
-        toast.error('删除项目失败');
-      }
-    } catch (error) {
-      console.error('删除项目失败:', error);
-      toast.error('删除项目失败，请重试');
-    } finally {
-      setDeleteLoading(false);
-      setDeleteDialogOpen(false);
-    }
-  };
-
-  if (loading) {
-    return (
-      <div className="container mx-auto py-6">
-        <div className="flex justify-center items-center h-64">
-          <div className="animate-pulse text-lg">加载项目信息...</div>
-        </div>
-      </div>
-    );
-  }
-
-  if (error || !project) {
-    return (
-      <div className="container mx-auto py-6">
-        <div className="text-center py-12 border rounded-lg bg-gray-50">
-          <h3 className="text-lg font-medium text-red-600">{error || '项目不存在'}</h3>
-          <p className="text-sm text-gray-500 mt-1">请返回项目列表查看其他项目</p>
-          <Button asChild variant="outline" className="mt-4">
-            <Link href="/projects">返回项目列表</Link>
-          </Button>
-        </div>
-      </div>
-    );
-  }
-
-  return (
-    <div className="container mx-auto py-6 space-y-6">
-
-
-      <Card className="mb-6">
-        <CardHeader className="pb-2">
-          <div className="flex justify-between items-center">
-            <div>
-              <CardTitle className="text-lg">项目概览（{project.name}）</CardTitle>
-              <CardDescription>单位代码: {project.code}</CardDescription>
-            </div>
-
-            <div className='flex justify-end gap-2'>
-
-              <Dialog open={showProjectInfo} onOpenChange={setShowProjectInfo}>
-                <DialogTrigger asChild>
-                  <Button variant="outline" size="sm" className="gap-1">
-                    <PencilIcon className="h-4 w-4" />
-                    编辑基本信息
-                  </Button>
-
-
-                </DialogTrigger>
-                <DialogContent className="max-w-3xl">
-                  <DialogHeader>
-                    <DialogTitle>项目基本信息</DialogTitle>
-                    <DialogDescription>
-                      查看和编辑项目的详细信息
-                    </DialogDescription>
-                  </DialogHeader>
-                  <ProjectInfo project={project} onUpdate={handleProjectUpdate} />
-                </DialogContent>
-              </Dialog>
-
-              <div className="flex items-center justify-between gap-2">
-
-                <Button
-                  variant="destructive"
-                  size="sm"
-                  className="gap-1"
-                  onClick={() => setDeleteDialogOpen(true)}
-                >
-                  <TrashIcon className="h-4 w-4" />
-                  删除项目
-                </Button>
-              </div>
-            </div>
-
-          </div>
-        </CardHeader>
-        <CardContent className="grid grid-cols-1 md:grid-cols-3 gap-4">
-          <div>
-            <div className="text-sm font-medium text-muted-foreground">单位类型</div>
-            <div>{project.type}</div>
-          </div>
-          <div>
-            <div className="text-sm font-medium text-muted-foreground">文件数量</div>
-            <div>{fileCount}</div>
-          </div>
-          <div>
-            <div className="text-sm font-medium text-muted-foreground">分析任务</div>
-            <div>{project.taskCount}</div>
-          </div>
-        </CardContent>
-      </Card>
-
-
-      <ProjectAnalysis 
-        projectId={projectId} 
-        initialFiles={project.files || []} 
-        onFileChange={(files) => {
-          // 当文件列表变化时更新文件计数
-          setFileCount(files.length);
-        }}
-      />
-
-      {tripleOneMajorItems.length > 0 && (
-        <Card className="mb-6">
-          <CardHeader className="pb-2">
-            <div className="flex items-center justify-between">
-              <div className="flex items-center gap-2">
-                <AlertTriangle className="h-5 w-5 text-amber-500" />
-                <CardTitle className="text-lg">三重一大事项分析</CardTitle>
-              </div>
-              <Button 
-                variant="outline" 
-                size="sm" 
-                className="gap-1" 
-                onClick={() => exportTripleOneMajorItems(tripleOneMajorItems)}
-              >
-                <Download className="h-4 w-4" />
-                导出数据
-              </Button>
-            </div>
-            <CardDescription>
-              从项目文档中提取的重大决策、项目安排、资金使用等事项
-            </CardDescription>
-          </CardHeader>
-          <CardContent>
-            <Table>
-              <TableHeader>
-                <TableRow>
-                  <TableHead>类型</TableHead>
-                  <TableHead>事项内容</TableHead>
-                  <TableHead>金额</TableHead>
-                  <TableHead>责任部门</TableHead>
-                  <TableHead>相关人员</TableHead>
-                  <TableHead>决策依据</TableHead>
-                </TableRow>
-              </TableHeader>
-              <TableBody>
-                {tripleOneMajorItems.map((item, index) => (
-                  <TableRow key={index}>
-                    <TableCell className="font-medium">
-                      {item.categoryType === 'majorProject' ? '重大项目' :
-                       item.categoryType === 'majorFund' ? '大额资金' :
-                       item.categoryType === 'majorDecision' ? '重大决策' : item.categoryType}
-                    </TableCell>
-                    <TableCell>{item.details}</TableCell>
-                    <TableCell>{item.amount}</TableCell>
-                    <TableCell>{item.departments}</TableCell>
-                    <TableCell className="max-w-[200px] truncate" title={item.personnel}>
-                      {item.personnel}
-                    </TableCell>
-                    <TableCell>{item.decisionBasis}</TableCell>
-                  </TableRow>
-                ))}
-              </TableBody>
-            </Table>
-            <div className="mt-4 text-sm text-muted-foreground">
-              总计发现 {tripleOneMajorItems.length} 项三重一大事项
-            </div>
-          </CardContent>
-        </Card>
-      )}
-
-      <AlertDialog open={deleteDialogOpen} onOpenChange={setDeleteDialogOpen}>
-        <AlertDialogContent>
-          <AlertDialogHeader>
-            <AlertDialogTitle>确认删除项目</AlertDialogTitle>
-            <AlertDialogDescription>
-              您确定要删除项目"{project.name}"吗？此操作将删除所有相关数据，且无法恢复。
-            </AlertDialogDescription>
-          </AlertDialogHeader>
-          <AlertDialogFooter>
-            <AlertDialogCancel disabled={deleteLoading}>取消</AlertDialogCancel>
-            <AlertDialogAction
-              onClick={handleDeleteProject}
-              disabled={deleteLoading}
-              className="bg-destructive text-destructive-foreground hover:bg-destructive/90"
-            >
-              {deleteLoading ? '删除中...' : '确认删除'}
-            </AlertDialogAction>
-          </AlertDialogFooter>
-        </AlertDialogContent>
-      </AlertDialog>
-    </div>
-  );
-} 
\ No newline at end of file
diff --git a/components/projects/ProjectAnalysis.tsx b/components/projects/detail/ProjectAnalysis.tsx
similarity index 53%
rename from components/projects/ProjectAnalysis.tsx
rename to components/projects/detail/ProjectAnalysis.tsx
index 29a2e32..5d719b6 100644
--- a/components/projects/ProjectAnalysis.tsx
+++ b/components/projects/detail/ProjectAnalysis.tsx
@@ -1,230 +1,44 @@
 'use client';
 
-import { useActionState, useCallback, useEffect, useRef, useState, startTransition } from 'react';
-import { Button } from '@/components/ui/button';
-import { Card, CardContent, CardDescription, CardFooter, CardHeader, CardTitle } from '@/components/ui/card';
-import { Progress } from '@/components/ui/progress';
-import { Upload, FileIcon, Trash2, AlertCircle, CheckCircle, Clock, RefreshCw } from 'lucide-react';
-import { useToast } from '@/components/ui/use-toast';
-import { Badge } from '@/components/ui/badge';
-import { ScrollArea } from '@/components/ui/scroll-area';
-import Markdown from 'react-markdown';
-import remarkGfm from 'remark-gfm';
-import { logger } from '@/lib/logger';
-import { getFilesByProjectId } from '@/lib/db/documents';
-import { File as DBFile } from '@/lib/db/schema';
-import { ProjectFile } from '@/lib/api/project-api';
-import { saveFileAnalysisResult, deleteProjectFile } from '@/lib/actions/file-actions';
+import {FileCard} from "@/components/projects/detail/file-card";
+import {AnalysisEvent} from "@/components/projects/utils/analysis-event";
+import {FileStatus} from "@/components/projects/utils/file-status";
+import {UIFile} from "@/components/projects/utils/ui-file";
+import {Button} from '@/components/ui/button';
+import {useToast} from '@/components/ui/use-toast';
+import {deleteProjectFile, saveFileAnalysisResult} from '@/lib/actions/file-actions';
+import {ProjectFile} from '@/lib/api/project-api';
+import {getFilesByProjectId} from '@/lib/db/documents';
+import {logger} from '@/lib/logger';
+import {RefreshCw, Upload} from 'lucide-react';
+import {startTransition, useActionState, useCallback, useEffect, useRef, useState} from 'react';
+import {useAtom} from 'jotai'
+import {projectFilesAtom, projectFileToUIFile} from '@/components/projects/detail/project-atoms';
 
-// 文件状态枚举
-type FileStatus = 
-  | 'uploading' // 正在上传
-  | 'upload_failed' // 上传失败
-  | 'uploaded' // 已上传
-  | 'analyzing' // 正在分析
-  | 'analysis_failed' // 分析失败
-  | 'analyzed'; // 已分析
-
-// 扩展文件类型以适配UI需求
-interface UIFile {
-  id: string;
-  originalName: string;
-  fileSize: number;
-  fileType: string;
-  filePath: string;
-  status: FileStatus;
-  userId: string;
-  isAnalyzed?: boolean;
-  progress?: number; // 上传进度 0-100
-  analysisResult?: string; // 分析结果
-  error?: string; // 错误信息
-  uploadDate: string;
-}
-
-// 分析事件类型
-type AnalysisEvent = {
-  event: string;
-  task_id?: string;
-  message?: string;
-  error?: string;
-  data?: any;
-  answer?: string;
-};
-
-/**
- * 格式化文件大小
- */
-function formatFileSize(bytes: number): string {
-  if (bytes < 1024) return bytes + ' B';
-  if (bytes < 1024 * 1024) return (bytes / 1024).toFixed(2) + ' KB';
-  if (bytes < 1024 * 1024 * 1024) return (bytes / (1024 * 1024)).toFixed(2) + ' MB';
-  return (bytes / (1024 * 1024 * 1024)).toFixed(2) + ' GB';
-}
-
-/**
- * 获取文件图标颜色
- */
-function getFileIconColor(fileType: string): string {
-  if (fileType.includes('pdf')) return 'text-red-500';
-  if (fileType.includes('word') || fileType.includes('doc')) return 'text-blue-500';
-  if (fileType.includes('excel') || fileType.includes('sheet') || fileType.includes('csv')) return 'text-green-500';
-  if (fileType.includes('powerpoint') || fileType.includes('presentation')) return 'text-orange-500';
-  if (fileType.includes('image')) return 'text-purple-500';
-  return 'text-gray-500';
-}
-
-/**
- * 文档状态徽章组件
- */
-function FileStatusBadge({ status }: { status: FileStatus }) {
-  switch (status) {
-    case 'uploading':
-      return <Badge variant="secondary" className="bg-blue-100 text-blue-800"><Clock className="h-3 w-3 mr-1" /> 上传中</Badge>;
-    case 'upload_failed':
-      return <Badge variant="destructive"><AlertCircle className="h-3 w-3 mr-1" /> 上传失败</Badge>;
-    case 'uploaded':
-      return <Badge variant="outline" className="border-green-500 text-green-500"><CheckCircle className="h-3 w-3 mr-1" /> 已上传</Badge>;
-    case 'analyzing':
-      return <Badge variant="secondary" className="bg-purple-100 text-purple-800"><RefreshCw className="h-3 w-3 mr-1 animate-spin" /> 分析中</Badge>;
-    case 'analysis_failed':
-      return <Badge variant="destructive"><AlertCircle className="h-3 w-3 mr-1" /> 分析失败</Badge>;
-    case 'analyzed':
-      return <Badge className="bg-green-500"><CheckCircle className="h-3 w-3 mr-1" /> 已分析</Badge>;
-    default:
-      return null;
-  }
-}
-
-/**
- * 单个文档卡片组件
- */
-function FileCard({ 
-  file, 
-  onAnalyze, 
-  onRemove,
-  expanded
-}: { 
-  file: UIFile; 
-  onAnalyze: (file: UIFile) => void; 
-  onRemove: (file: UIFile) => void;
-  expanded: boolean;
-}) {
-  const canAnalyze = file.status === 'uploaded' || file.status === 'analysis_failed';
-  const isExpanded = expanded || file.status === 'analyzing' || file.status === 'analyzed';
-  
-  return (
-    <Card className="mb-4 overflow-hidden">
-      <CardHeader className="pb-2">
-        <div className="flex justify-between items-start">
-          <div className="flex items-center gap-2">
-            <FileIcon className={`h-6 w-6 ${getFileIconColor(file.fileType)}`} />
-            <div>
-              <CardTitle className="text-sm font-medium">{file.originalName}</CardTitle>
-              <CardDescription className="text-xs">
-                {formatFileSize(file.fileSize)} • {new Date(file.uploadDate).toLocaleString()}
-              </CardDescription>
-            </div>
-          </div>
-          <FileStatusBadge status={file.status} />
-        </div>
-      </CardHeader>
-      
-      {file.status === 'uploading' && (
-        <CardContent className="pb-2">
-          <Progress value={file.progress || 0} className="h-2" />
-          <p className="text-xs text-muted-foreground mt-1 text-right">{file.progress}%</p>
-        </CardContent>
-      )}
-      
-      {file.error && (
-        <CardContent className="py-2">
-          <p className="text-xs text-red-500 italic">{file.error}</p>
-        </CardContent>
-      )}
-      
-      {isExpanded && file.analysisResult && (
-        <CardContent className="pt-0 pb-2">
-          <div className="border rounded-md p-3 bg-gray-50 mt-2">
-            <ScrollArea className="h-[200px]">
-              <Markdown 
-                remarkPlugins={[remarkGfm]}
-                components={{
-                  // 使用components属性代替className
-                  p: ({node, ...props}) => <p className="prose prose-sm max-w-none" {...props} />,
-                  // 其他元素也可以在这里定义
-                  ul: ({node, ...props}) => <ul className="prose prose-sm max-w-none" {...props} />,
-                  ol: ({node, ...props}) => <ol className="prose prose-sm max-w-none" {...props} />,
-                  li: ({node, ...props}) => <li className="prose prose-sm" {...props} />,
-                  h1: ({node, ...props}) => <h1 className="prose prose-sm" {...props} />,
-                  h2: ({node, ...props}) => <h2 className="prose prose-sm" {...props} />,
-                  h3: ({node, ...props}) => <h3 className="prose prose-sm" {...props} />,
-                  blockquote: ({node, ...props}) => <blockquote className="prose prose-sm" {...props} />,
-                  code: ({node, ...props}) => <code className="prose prose-sm" {...props} />,
-                  pre: ({node, ...props}) => <pre className="prose prose-sm" {...props} />
-                }}
-              >
-                {file.analysisResult}
-              </Markdown>
-            </ScrollArea>
-          </div>
-        </CardContent>
-      )}
-      
-      <CardFooter className="pt-0 pb-3 flex justify-between">
-        <Button 
-          variant="ghost" 
-          size="sm" 
-          onClick={() => onRemove(file)}
-          disabled={file.status === 'uploading' || file.status === 'analyzing'}
-        >
-          <Trash2 className="h-4 w-4 mr-1" />
-          删除
-        </Button>
-        
-        {canAnalyze && (
-          <Button 
-            variant="outline" 
-            size="sm" 
-            onClick={() => onAnalyze(file)}
-          >
-            <RefreshCw className="h-4 w-4 mr-1" />
-            分析
-          </Button>
-        )}
-      </CardFooter>
-    </Card>
-  );
-}
-
-export default function ProjectAnalysis({ 
+export default function ProjectAnalysis({
   projectId, 
   initialFiles = [],
   onFileChange
 }: { 
   projectId: string, 
-  initialFiles?: ProjectFile[],
+  initialFiles?: UIFile[],  // Changed from ProjectFile[] to UIFile[]
   onFileChange?: (files: UIFile[]) => void 
 }) {
-  const [files, setFiles] = useState<UIFile[]>(() => initialFiles.map(file => ({
-    id: file.id,
-    originalName: file.filename,
-    fileSize: file.size,
-    fileType: file.type,
-    filePath: file.url,
-    uploadDate: file.createdAt,
-    // 根据isAnalyzed状态设置正确的状态
-    status: file.isAnalyzed ? 'analyzed' : 'uploaded' as FileStatus,
-    userId: '',
-    isAnalyzed: file.isAnalyzed || false,
-    // 从元数据中加载分析结果，如果有的话
-    analysisResult: file.metadata || ''
-  })));
+  // Use Jotai atom instead of local state
+  const [files, setFiles] = useAtom(projectFilesAtom);
   const [isLoading, setIsLoading] = useState(true);
   const [expandedFileId, setExpandedFileId] = useState<string | null>(null);
   const fileInputRef = useRef<HTMLInputElement>(null);
   const { toast } = useToast();
   const [filesState, getFilesAction] = useActionState(getFilesByProjectId, [])
   
+  // 初始化 Jotai atom 状态
+  useEffect(() => {
+    if (initialFiles.length > 0) {
+      setFiles(initialFiles);
+    }
+  }, [initialFiles, setFiles]);
+  
   // 加载项目文档列表
   const loadFiles = useCallback(() => {
     logger.info("load documents..", {projectId})
@@ -248,12 +62,13 @@ export default function ProjectAnalysis({
     if (filesState && initialFiles.length === 0) {
       try {
         if (Array.isArray(filesState)) {
-          setFiles(filesState.map((file: any) => ({
+          const uiFiles = filesState.map((file: any) => ({
             ...file,
             status: file.isAnalyzed ? 'analyzed' : 'uploaded',
             // 确保分析结果数据存在，使用metadata字段作为分析结果
             analysisResult: file.metadata || file.analysisResult || ''
-          })));
+          }));
+          setFiles(uiFiles);
         } else {
           console.warn('文件数据返回格式不正确:', filesState);
           setFiles([]);
@@ -269,9 +84,8 @@ export default function ProjectAnalysis({
         setIsLoading(false);
       }
     }
-  }, [filesState, initialFiles.length]);
+  }, [filesState, initialFiles.length, setFiles]);
 
-  
   // 初始加载 - 只在没有初始文件时才从服务器加载
   useEffect(() => {
     // 如果已有初始文件数据，则不需要再加载
@@ -291,23 +105,12 @@ export default function ProjectAnalysis({
   
   // 处理文件上传
   const handleFileChange = async (e: React.ChangeEvent<HTMLInputElement>) => {
-    const files = e.target.files;
-    if (!files || files.length === 0) return;
-    
-    // 处理多个文件上传
-    Array.from(files).forEach(file => uploadFile(file));
+    const selectedFiles = e.target.files;
+    if (!selectedFiles || selectedFiles.length === 0) return;
     
-    // 重置文件输入以允许重复上传同一个文件
-    if (fileInputRef.current) {
-      fileInputRef.current.value = '';
-    }
-  };
-  
-  // 上传单个文件
-  const uploadFile = async (file: File) => {
-    // 创建临时文件对象
-    const tempFile: UIFile = {
-      id: `temp-${Date.now()}-${file.name}`,
+    // 创建临时文件数组，先将所有文件添加到UI中
+    const tempFiles: UIFile[] = Array.from(selectedFiles).map(file => ({
+      id: `temp-${Date.now()}-${Math.random().toString(36).substring(2, 9)}-${file.name}`,
       originalName: file.name,
       fileSize: file.size,
       fileType: file.type,
@@ -317,19 +120,39 @@ export default function ProjectAnalysis({
       userId: '',
       isAnalyzed: false,
       progress: 0
-    };
+    }));
     
-    // 添加到文件列表
-    const updatedFiles = [
-      tempFile,
-      ...files
-    ];
-    setFiles(updatedFiles);
+    // 批量更新所有文件到状态中
+    setFiles(prev => [...tempFiles, ...prev]);
     
     // 通知父组件文件数量变化
     if (onFileChange) {
-      onFileChange(updatedFiles);
+      onFileChange([...tempFiles, ...files]);
+    }
+    
+    // 并行处理多个文件上传
+    const uploadTasks = Array.from(selectedFiles).map((file, index) => {
+      const tempFile = tempFiles[index]; // 获取对应的临时文件对象
+      return uploadFile(file, tempFile.id);
+    });
+    
+    // 所有上传完成后的操作
+    Promise.all(uploadTasks)
+      .then((results) => {
+        logger.info(`All ${results.length} files upload completed`);
+      })
+      .catch(error => {
+        logger.error('Error handling file uploads:', error);
+      });
+    
+    // 重置文件输入以允许重复上传同一个文件
+    if (fileInputRef.current) {
+      fileInputRef.current.value = '';
     }
+  };
+  
+  // 上传单个文件 - 返回Promise以支持并行上传
+  const uploadFile = async (file: File, tempFileId: string): Promise<string> => {
     
     try {
       // 创建FormData
@@ -337,19 +160,26 @@ export default function ProjectAnalysis({
       formData.append('file', file);
       formData.append('user', projectId); // 实际上是将projectId作为auditUnitId传递
       
-      // 模拟上传进度
+      // 为每个文件创建唯一的上传ID，用于跟踪上传进度
+      const uploadId = `upload-${Date.now()}-${Math.random().toString(36).substring(2, 9)}`;
+      
+      // 模拟上传进度 - 为每个文件单独跟踪进度
       const progressInterval = setInterval(() => {
         setFiles(prev => prev.map(file => 
-          file.id === tempFile.id && file.status === 'uploading' 
+          file.id === tempFileId && file.status === 'uploading' 
             ? { ...file, progress: Math.min((file.progress || 0) + 10, 90) }
             : file
         ));
       }, 300);
       
-      // 发送上传请求
+      // 发送上传请求 - 使用 AbortController 以支持取消上传
+      const controller = new AbortController();
+      const signal = controller.signal;
+      
       const response = await fetch('/api/dify/upload', {
         method: 'POST',
-        body: formData
+        body: formData,
+        signal
       });
       
       clearInterval(progressInterval);
@@ -363,7 +193,7 @@ export default function ProjectAnalysis({
       
       // 更新文档状态为已上传
       setFiles(prev => prev.map(file => 
-        file.id === tempFile.id 
+        file.id === tempFileId 
           ? { 
               ...file, 
               id: data.id,
@@ -379,12 +209,15 @@ export default function ProjectAnalysis({
         title: '上传成功',
         description: `文件 ${file.name} 上传成功`,
       });
+      
+      // 返回服务器分配的文件ID
+      return data.id || "";
     } catch (error) {
       console.error('文件上传失败:', error);
       
       // 更新文件状态为上传失败
       setFiles(prev => prev.map(file => 
-        file.id === tempFile.id 
+        file.id === tempFileId 
           ? { ...file, status: 'upload_failed', error: error instanceof Error ? error.message : '上传失败' }
           : file
       ));
@@ -394,6 +227,8 @@ export default function ProjectAnalysis({
         description: `文件 ${file.name} 上传失败: ${error instanceof Error ? error.message : '未知错误'}`,
         variant: 'destructive'
       });
+      
+      return "";
     }
   };
   
@@ -430,7 +265,35 @@ export default function ProjectAnalysis({
     }
   };
   
-  // 分析文件
+  // 批量分析文件
+  const handleAnalyzeMultipleFiles = async (filesToAnalyze: UIFile[]) => {
+    // 确保有文件需要分析
+    if (!filesToAnalyze || filesToAnalyze.length === 0) return;
+    
+    logger.info(`批量分析 ${filesToAnalyze.length} 个文件`, {
+      projectId,
+      fileIds: filesToAnalyze.map(f => f.id)
+    });
+    
+    try {
+      // 使用Promise.all并行处理所有文件的分析
+      const analysisPromises = filesToAnalyze.map(file => handleAnalyzeFile(file));
+      
+      // 等待所有分析完成
+      await Promise.all(analysisPromises);
+      
+      // 所有文件分析完成后的通知
+      toast({
+        title: '批量分析完成',
+        description: `已完成 ${filesToAnalyze.length} 个文件的分析`
+      });
+    } catch (error) {
+      // 错误已在handleAnalyzeFile中处理，这里只需记录总体错误
+      logger.error('批量分析总体异常', { error: error instanceof Error ? error.message : '未知错误' });
+    }
+  };
+  
+  // 分析单个文件
   const handleAnalyzeFile = async (file: UIFile) => {
     try {
       // 更新文件状态为分析中
@@ -495,16 +358,18 @@ export default function ProjectAnalysis({
     }
   };
   
-  // 处理分析错误
-  const handleAnalysisError = (fileId: string, error: any, eventSource?: EventSource) => {
+  // 处理分析错误 - 支持单个或多个文件ID
+  const handleAnalysisError = (fileIds: string | string[], error: any, eventSource?: EventSource) => {
     // 关闭EventSource
     if (eventSource) {
       eventSource.close();
     }
     
-    // 更新文件状态为分析失败
+    // 更新文件状态为分析失败 - 支持单个或多个文件ID
+    const fileIdArray = Array.isArray(fileIds) ? fileIds : [fileIds];
+    
     setFiles(prev => prev.map(f => 
-      f.id === fileId ? { 
+      fileIdArray.includes(f.id) ? { 
         ...f, 
         status: 'analysis_failed', 
         error: error instanceof Error ? error.message : '分析过程中出现错误'
@@ -538,10 +403,31 @@ export default function ProjectAnalysis({
       <div className="flex justify-between items-center">
         <h3 className="text-lg font-medium">项目文档分析</h3>
         
-        <Button onClick={handleUploadClick}>
-          <Upload className="h-4 w-4 mr-2" />
-          上传文档
-        </Button>
+        <div className="flex space-x-2">
+          <Button 
+            variant="outline" 
+            onClick={() => {
+              const filesToAnalyze = files.filter(f => f.status === 'uploaded' || f.status === 'analysis_failed');
+              if (filesToAnalyze.length > 0) {
+                handleAnalyzeMultipleFiles(filesToAnalyze);
+              } else {
+                toast({
+                  title: '没有可分析的文件',
+                  description: '请先上传文件再进行分析',
+                  variant: 'destructive'
+                });
+              }
+            }}
+          >
+            <RefreshCw className="h-4 w-4 mr-2" />
+            批量分析
+          </Button>
+          
+          <Button onClick={handleUploadClick}>
+            <Upload className="h-4 w-4 mr-2" />
+            上传文档
+          </Button>
+        </div>
         
         <input
           type="file"
diff --git a/components/projects/ProjectInfo.tsx b/components/projects/detail/ProjectInfo.tsx
similarity index 100%
rename from components/projects/ProjectInfo.tsx
rename to components/projects/detail/ProjectInfo.tsx
diff --git a/components/projects/detail/file-card.tsx b/components/projects/detail/file-card.tsx
new file mode 100644
index 0000000..fe281bf
--- /dev/null
+++ b/components/projects/detail/file-card.tsx
@@ -0,0 +1,113 @@
+import {FileStatusBadge} from "@/components/projects/utils/file-status-badge";
+import {UIFile} from "@/components/projects/utils/ui-file";
+import {Button} from "@/components/ui/button";
+import {Card, CardContent, CardDescription, CardFooter, CardHeader, CardTitle} from "@/components/ui/card";
+import {Progress} from "@/components/ui/progress";
+import {ScrollArea} from "@/components/ui/scroll-area";
+import {formatFileSize} from "@/lib/format-file-size";
+import {getFileIconColor} from "@/lib/get-file-icon-color";
+import {FileIcon, RefreshCw, Trash2} from "lucide-react";
+import Markdown from "react-markdown";
+import remarkGfm from "remark-gfm";
+
+/**
+ * 单个文档卡片组件
+ */
+export function FileCard({
+                             file,
+                             onAnalyze,
+                             onRemove,
+                             expanded
+                         }: {
+    file: UIFile;
+    onAnalyze: (file: UIFile) => void;
+    onRemove: (file: UIFile) => void;
+    expanded: boolean;
+}) {
+    const canAnalyze = file.status === 'uploaded' || file.status === 'analysis_failed' || file.status === 'analyzed';
+    const isExpanded = expanded || file.status === 'analyzing' || file.status === 'analyzed';
+
+    return (
+        <Card className="mb-4 overflow-hidden">
+            <CardHeader className="pb-2">
+                <div className="flex justify-between items-start">
+                    <div className="flex items-center gap-2">
+                        <FileIcon className={`h-6 w-6 ${getFileIconColor(file.fileType)}`}/>
+                        <div>
+                            <CardTitle className="text-sm font-medium">{file.originalName}</CardTitle>
+                            <CardDescription className="text-xs">
+                                {formatFileSize(file.fileSize)} • {new Date(file.uploadDate).toLocaleString()}
+                            </CardDescription>
+                        </div>
+                    </div>
+                    <FileStatusBadge status={file.status}/>
+                </div>
+            </CardHeader>
+
+            {file.status === 'uploading' && (
+                <CardContent className="pb-2">
+                    <Progress value={file.progress || 0} className="h-2"/>
+                    <p className="text-xs text-muted-foreground mt-1 text-right">{file.progress}%</p>
+                </CardContent>
+            )}
+
+            {file.error && (
+                <CardContent className="py-2">
+                    <p className="text-xs text-red-500 italic">{file.error}</p>
+                </CardContent>
+            )}
+
+            {isExpanded && file.analysisResult && (
+                <CardContent className="pt-0 pb-2">
+                    <div className="border rounded-md p-3 bg-gray-50 mt-2">
+                        <ScrollArea className="h-[200px]">
+                            <Markdown
+                                remarkPlugins={[remarkGfm]}
+                                components={{
+                                    // 使用components属性代替className
+                                    p: ({node, ...props}) => <p className="prose prose-sm max-w-none" {...props} />,
+                                    // 其他元素也可以在这里定义
+                                    ul: ({node, ...props}) => <ul className="prose prose-sm max-w-none" {...props} />,
+                                    ol: ({node, ...props}) => <ol className="prose prose-sm max-w-none" {...props} />,
+                                    li: ({node, ...props}) => <li className="prose prose-sm" {...props} />,
+                                    h1: ({node, ...props}) => <h1 className="prose prose-sm" {...props} />,
+                                    h2: ({node, ...props}) => <h2 className="prose prose-sm" {...props} />,
+                                    h3: ({node, ...props}) => <h3 className="prose prose-sm" {...props} />,
+                                    blockquote: ({node, ...props}) => <blockquote
+                                        className="prose prose-sm" {...props} />,
+                                    code: ({node, ...props}) => <code className="prose prose-sm" {...props} />,
+                                    pre: ({node, ...props}) => <pre className="prose prose-sm" {...props} />
+                                }}
+                            >
+                                {file.analysisResult}
+                            </Markdown>
+                        </ScrollArea>
+                    </div>
+                </CardContent>
+            )}
+
+            <CardFooter className="pt-0 pb-3 flex justify-between">
+                <Button
+                    variant="ghost"
+                    size="sm"
+                    onClick={() => onRemove(file)}
+                    disabled={file.status === 'uploading' || file.status === 'analyzing'}
+                >
+                    <Trash2 className="h-4 w-4 mr-1"/>
+                    删除
+                </Button>
+
+                {canAnalyze && (
+                    <Button
+                        variant="outline"
+                        size="sm"
+                        onClick={() => onAnalyze(file)}
+                    >
+                        <RefreshCw className="h-4 w-4 mr-1"/>
+                        {file.status === 'analyzed' ? '重新分析' : '分析'}
+                    </Button>
+                )}
+            </CardFooter>
+        </Card>
+    );
+}
\ No newline at end of file
diff --git a/components/projects/detail/index.tsx b/components/projects/detail/index.tsx
new file mode 100644
index 0000000..e258eee
--- /dev/null
+++ b/components/projects/detail/index.tsx
@@ -0,0 +1,221 @@
+'use client';
+
+import {TIOBComp, TIOBInterface} from "@/components/projects/detail/tiob-comp";
+import {
+    AlertDialog,
+    AlertDialogAction,
+    AlertDialogCancel,
+    AlertDialogContent,
+    AlertDialogDescription,
+    AlertDialogFooter,
+    AlertDialogHeader,
+    AlertDialogTitle,
+} from "@/components/ui/alert-dialog";
+import {Button} from '@/components/ui/button';
+import {Card, CardContent, CardDescription, CardHeader, CardTitle} from '@/components/ui/card';
+import {
+    Dialog,
+    DialogContent,
+    DialogDescription,
+    DialogHeader,
+    DialogTitle,
+    DialogTrigger,
+} from "@/components/ui/dialog";
+import {deleteProject, getProject, Project as BaseProject} from '@/lib/api/project-api';
+import {logger} from '@/lib/logger';
+import ProjectAnalysis from 'components/projects/detail/ProjectAnalysis';
+import ProjectInfo from 'components/projects/detail/ProjectInfo';
+import {PencilIcon, TrashIcon} from 'lucide-react';
+import Link from 'next/link';
+import {useRouter} from 'next/navigation';
+import {useEffect, useState} from 'react';
+import {toast} from 'sonner';
+import {useAtom} from 'jotai';
+import {projectFilesAtom, tiobItemsAtom} from '@/components/projects/detail/project-atoms';
+
+interface Project extends BaseProject {
+    fileCount?: number; // 兼容新命名
+}
+
+export default function ProjectDetail({projectId}: { projectId: string }) {
+    const [project, setProject] = useState<Project | null>(null);
+    const [loading, setLoading] = useState(true);
+    const [error, setError] = useState<string | null>(null);
+    const [deleteDialogOpen, setDeleteDialogOpen] = useState(false);
+    const [deleteLoading, setDeleteLoading] = useState(false);
+    const [showProjectInfo, setShowProjectInfo] = useState(false);
+    // 使用Jotai原子化状态
+    const [files] = useAtom(projectFilesAtom);
+    const [tiobItems] = useAtom(tiobItemsAtom);
+    // 文件计数基于原子状态
+    const fileCount = files.length;
+    const router = useRouter();
+
+    // logger.info('ProjectDetail', {projectId, project});
+
+    useEffect(() => {
+        // 加载项目详情
+        loadProject();
+    }, [projectId]);
+
+    const loadProject = async () => {
+        try {
+            setLoading(true);
+            setError(null);
+            const data = await getProject(projectId);
+
+            if (!data) {
+                setError('项目不存在');
+                toast.error('无法找到该项目');
+                return;
+            }
+
+            setProject(data);
+            // 文件计数现在基于Jotai原子状态，不需要在此设置
+
+        } catch (error) {
+            console.error('加载项目详情失败:', error);
+            setError('加载项目详情失败');
+            toast.error('加载项目详情失败');
+        } finally {
+            setLoading(false);
+        }
+    };
+
+    // 更新项目对象中的文件数 - 使用Jotai状态
+    useEffect(() => {
+        if (project && fileCount !== project.fileCount) {
+            setProject({...project, fileCount});
+        }
+    }, [fileCount, project]);
+
+    const handleProjectUpdate = (updated: Partial<Project>) => {
+        if (!project) return;
+        setProject({...project, ...updated});
+    };
+
+    const handleDeleteProject = async () => {
+        if (!project) return;
+
+        try {
+            setDeleteLoading(true);
+            const success = await deleteProject(project.id);
+
+            if (success) {
+                toast.success('项目已成功删除');
+                router.push('/projects');
+            } else {
+                toast.error('删除项目失败');
+            }
+        } catch (error) {
+            console.error('删除项目失败:', error);
+            toast.error('删除项目失败，请重试');
+        } finally {
+            setDeleteLoading(false);
+            setDeleteDialogOpen(false);
+        }
+    };
+
+    // logger.info("project detail: ", {project, files, tiobItems});
+
+    if (loading) {
+        return (<div className="container mx-auto py-6">
+            <div className="flex justify-center items-center h-64">
+                <div className="animate-pulse text-lg">加载项目信息...</div>
+            </div>
+        </div>);
+    }
+
+    if (error || !project) {
+        return (<div className="container mx-auto py-6">
+            <div className="text-center py-12 border rounded-lg bg-gray-50">
+                <h3 className="text-lg font-medium text-red-600">{error || '项目不存在'}</h3>
+                <p className="text-sm text-gray-500 mt-1">请返回项目列表查看其他项目</p>
+                <Button asChild variant="outline" className="mt-4">
+                    <Link href="/projects">返回项目列表</Link>
+                </Button>
+            </div>
+        </div>);
+    }
+
+    return (<div className="container mx-auto py-6 space-y-6">
+        <Card className="mb-6">
+            <CardHeader className="pb-2">
+                <div className="flex justify-between items-center">
+                    <div>
+                        <CardTitle className="text-lg">项目概览（{project.name}）</CardTitle>
+                        <CardDescription>单位代码: {project.code}</CardDescription>
+                    </div>
+                    <div className='flex justify-end gap-2'>
+                        <Dialog open={showProjectInfo} onOpenChange={setShowProjectInfo}>
+                            <DialogTrigger asChild>
+                                <Button variant="outline" size="sm" className="gap-1">
+                                    <PencilIcon className="h-4 w-4"/>
+                                    编辑基本信息
+                                </Button>
+                            </DialogTrigger>
+                            <DialogContent className="max-w-3xl">
+                                <DialogHeader>
+                                    <DialogTitle>项目基本信息</DialogTitle>
+                                    <DialogDescription>
+                                        查看和编辑项目的详细信息
+                                    </DialogDescription>
+                                </DialogHeader>
+                                <ProjectInfo project={project} onUpdate={handleProjectUpdate}/>
+                            </DialogContent>
+                        </Dialog>
+
+                        <Button
+                            variant="destructive"
+                            size="sm"
+                            className="gap-1"
+                            onClick={() => setDeleteDialogOpen(true)}
+                        >
+                            <TrashIcon className="h-4 w-4"/>
+                            删除项目
+                        </Button>
+                    </div>
+                </div>
+            </CardHeader>
+            <CardContent className="grid grid-cols-1 md:grid-cols-3 gap-4">
+                <div>
+                    <div className="text-sm font-medium text-muted-foreground">单位类型</div>
+                    <div>{project.type}</div>
+                </div>
+                <div>
+                    <div className="text-sm font-medium text-muted-foreground">文件数量</div>
+                    <div>{fileCount}</div>
+                </div>
+                <div>
+                    <div className="text-sm font-medium text-muted-foreground">分析任务</div>
+                    <div>{project.taskCount}</div>
+                </div>
+            </CardContent>
+        </Card>
+
+        <ProjectAnalysis projectId={projectId} initialFiles={files}/>
+
+        <TIOBComp project={{name: project.name}} />
+
+        <AlertDialog open={deleteDialogOpen} onOpenChange={setDeleteDialogOpen}>
+            <AlertDialogContent>
+                <AlertDialogHeader>
+                    <AlertDialogTitle>确认删除项目</AlertDialogTitle>
+                    <AlertDialogDescription>
+                        您确定要删除项目"{project.name}"吗？此操作将删除所有相关数据，且无法恢复。
+                    </AlertDialogDescription>
+                </AlertDialogHeader>
+                <AlertDialogFooter>
+                    <AlertDialogCancel disabled={deleteLoading}>取消</AlertDialogCancel>
+                    <AlertDialogAction
+                        onClick={handleDeleteProject}
+                        disabled={deleteLoading}
+                        className="bg-destructive text-destructive-foreground hover:bg-destructive/90"
+                    >
+                        {deleteLoading ? '删除中...' : '确认删除'}
+                    </AlertDialogAction>
+                </AlertDialogFooter>
+            </AlertDialogContent>
+        </AlertDialog>
+    </div>);
+}
\ No newline at end of file
diff --git a/components/projects/detail/project-atoms.ts b/components/projects/detail/project-atoms.ts
new file mode 100644
index 0000000..9a9b695
--- /dev/null
+++ b/components/projects/detail/project-atoms.ts
@@ -0,0 +1,65 @@
+import { atom } from "jotai";
+import { UIFile } from "@/components/projects/utils/ui-file";
+import { ProjectFile } from '@/lib/api/project-api';
+import { jsonrepair } from 'jsonrepair';
+import { TIOBInterface } from "./tiob-comp";
+
+// Atom to store the project files
+export const projectFilesAtom = atom<UIFile[]>([]);
+
+// Helper function to convert ProjectFile to UIFile
+export function projectFileToUIFile(file: ProjectFile): UIFile {
+  return {
+    id: file.id,
+    originalName: file.filename,
+    fileSize: file.size,
+    fileType: file.type,
+    filePath: file.url,
+    uploadDate: file.createdAt,
+    status: file.isAnalyzed ? 'analyzed' : 'uploaded',
+    userId: '',
+    isAnalyzed: file.isAnalyzed || false,
+    analysisResult: file.metadata || '',
+  };
+}
+
+
+// Derived atom that provides tiobItems extracted from files
+export const tiobItemsAtom = atom((get) => {
+  const files = get(projectFilesAtom);
+  const tiobItems = [];
+
+  for (const file of files) {
+    if (file.analysisResult) {
+      try {
+        // Extract JSON from markdown code blocks (handles both complete and streaming SSE results)
+        const jsonMatch = file.analysisResult.match(/```json\n([\s\S]*?)(?:\n```|$)/);
+        
+        if (jsonMatch && jsonMatch[1]) {
+          const jsonToRepair = jsonMatch[1];
+          // Use jsonrepair to handle incomplete or malformed JSON from streaming SSE
+          const repairedJson = jsonrepair(jsonToRepair);
+          const metadata = JSON.parse(repairedJson);
+          
+          if (metadata.tiobItems && metadata.tiobItems.length > 0) {
+            // 获取会议日期
+            const meetingDate = metadata.basicInfo?.meetingDate || '';
+            
+            // Add source file information and meeting date
+            const itemsWithSource = metadata.tiobItems.map((item: any) => ({
+              ...item,
+              sourceFile: file.originalName,
+              meetingDate: meetingDate
+            }));
+
+            tiobItems.push(...itemsWithSource);
+          }
+        }
+      } catch (e) {
+        console.error('Failed to parse file metadata:', file.originalName, e);
+      }
+    }
+  }
+
+  return tiobItems;
+});
diff --git a/components/projects/detail/tiob-comp.tsx b/components/projects/detail/tiob-comp.tsx
new file mode 100644
index 0000000..d813743
--- /dev/null
+++ b/components/projects/detail/tiob-comp.tsx
@@ -0,0 +1,172 @@
+import { Button } from "@/components/ui/button";
+import {
+  Card,
+  CardContent,
+  CardDescription,
+  CardHeader,
+  CardTitle,
+} from "@/components/ui/card";
+import {
+  Table,
+  TableBody,
+  TableCell,
+  TableHead,
+  TableHeader,
+  TableRow,
+} from "@/components/ui/table";
+import { saveAs } from "file-saver";
+import { AlertTriangle, Download } from "lucide-react";
+import { toast } from "sonner";
+import * as XLSX from "xlsx";
+import { useAtom } from "jotai";
+import { tiobItemsAtom } from "@/components/projects/detail/project-atoms";
+
+export interface TIOBInterface {
+  categoryType: string;
+  details: string;
+  amount: string;
+  departments: string;
+  personnel: string;
+  decisionBasis: string;
+  originalText: string;
+  sourceFile?: string; // 添加来源文件名
+  meetingDate?: string; // 添加会议日期
+}
+
+export function TIOBComp(props: {
+  project: {
+    name: string;
+  } | null;
+}) {
+  // 使用Jotai原子化状态替换props传递
+  const [tiobItems] = useAtom(tiobItemsAtom);
+
+  // 导出三重一大事项数据函数
+  const exportTiobItems = (items: TIOBInterface[]) => {
+    if (!items || items.length === 0) {
+      toast.error("没有可导出的数据");
+      return;
+    }
+
+    try {
+      // 格式化导出数据
+      const exportData = items.map((item) => ({
+        来源文件: item.sourceFile || "未知",
+        日期: item.meetingDate || "",
+        类型:
+          item.categoryType === "majorProject"
+            ? "重大项目"
+            : item.categoryType === "majorFund"
+            ? "大额资金"
+            : item.categoryType === "majorDecision"
+            ? "重大决策"
+            : item.categoryType,
+        事项内容: item.details,
+        金额: item.amount,
+        责任部门: item.departments,
+        相关人员: item.personnel,
+        决策依据: item.decisionBasis,
+      }));
+
+      // 创建工作簿
+      const wb = XLSX.utils.book_new();
+      const ws = XLSX.utils.json_to_sheet(exportData);
+
+      // 添加工作表到工作簿
+      XLSX.utils.book_append_sheet(wb, ws, "三重一大事项");
+
+      // 生成Excel文件并下载
+      const excelBuffer = XLSX.write(wb, { bookType: "xlsx", type: "array" });
+      const blob = new Blob([excelBuffer], {
+        type: "application/octet-stream",
+      });
+
+      // 使用当前日期作为文件名的一部分
+      const fileName = `${props.project?.name || "项目"}_三重一大事项_${
+        new Date().toISOString().split("T")[0]
+      }.xlsx`;
+      saveAs(blob, fileName);
+
+      toast.success("导出成功");
+    } catch (error) {
+      console.error("导出数据失败:", error);
+      toast.error("导出数据失败，请重试");
+    }
+  };
+
+  return (
+    <Card className="mb-6">
+      <CardHeader className="pb-2">
+        <div className="flex items-center justify-between">
+          <div className="flex items-center gap-2">
+            <AlertTriangle className="h-5 w-5 text-amber-500" />
+            <CardTitle className="text-lg">三重一大事项分析</CardTitle>
+          </div>
+          <Button
+            variant="outline"
+            size="sm"
+            className="gap-1"
+            onClick={() => exportTiobItems(tiobItems)}
+          >
+            <Download className="h-4 w-4" />
+            导出数据
+          </Button>
+        </div>
+        <CardDescription>
+          从项目文档中提取的重大决策、项目安排、资金使用等事项
+        </CardDescription>
+      </CardHeader>
+      <CardContent>
+        <Table>
+          <TableHeader>
+            <TableRow>
+              <TableHead>原文件名</TableHead>
+              <TableHead>日期</TableHead>
+              <TableHead>类型</TableHead>
+              <TableHead>事项内容</TableHead>
+              <TableHead>金额</TableHead>
+              <TableHead>责任部门</TableHead>
+              <TableHead>相关人员</TableHead>
+              <TableHead>决策依据</TableHead>
+            </TableRow>
+          </TableHeader>
+          <TableBody>
+            {tiobItems.map((item: any, index: any) => (
+              <TableRow key={index}>
+                <TableCell>{item.sourceFile || "未知"}</TableCell>
+                <TableCell>{item.meetingDate || ""}</TableCell>
+                <TableCell className="font-medium">
+                  {
+                    item.categoryType === "majorDecision"
+                    ? "重大决策"
+                    :
+                    item.categoryType === "personnelAppointment"
+                    ? "重要干部任免"
+                    :
+                  item.categoryType === "majorProject"
+                    ? "重大项目"
+                    : item.categoryType === "largeAmount"
+                    ? "大额资金"
+                    :  item.categoryType}
+                </TableCell>
+                <TableCell>{item.details}</TableCell>
+                <TableCell>{item.amount}</TableCell>
+                <TableCell>{item.departments}</TableCell>
+                <TableCell
+                  className="max-w-[200px] truncate"
+                  title={item.personnel}
+                >
+                  {item.personnel}
+                </TableCell>
+                <TableCell>{item.decisionBasis}</TableCell>
+              </TableRow>
+            ))}
+          </TableBody>
+        </Table>
+        <div className="mt-4 text-sm text-muted-foreground">
+          总计发现 {tiobItems.length} 项三重一大事项
+        </div>
+      </CardContent>
+    </Card>
+  );
+}
diff --git a/components/projects/hooks/useAnalysisResults.ts b/components/projects/hooks/useAnalysisResults.ts
index 347fd71..148a6c9 100644
--- a/components/projects/hooks/useAnalysisResults.ts
+++ b/components/projects/hooks/useAnalysisResults.ts
@@ -1,10 +1,11 @@
 'use client';
 
-import { useState, useCallback } from 'react';
-import { AnalysisStatus, FileStatus, AnalysisResult } from '../types';
-import { analyzeDifyFiles, loadMeetings } from '@/lib/actions/dify-chat-actions';
-import { logger } from '@/lib/logger';
-import { IMeeting } from '@/types/analysis';
+import {FileStatus} from "@/components/projects/utils/file-status";
+import {analyzeDifyFiles, loadMeetings} from '@/lib/actions/dify-chat-actions';
+import {logger} from '@/lib/logger';
+import {IMeeting} from '@/types/analysis';
+import {useCallback, useState} from 'react';
+import {AnalysisResult} from '../types';
 
 // 空会议结果数组
 const emptyMeetings: IMeeting[] = [];
@@ -14,132 +15,124 @@ const emptyMeetings: IMeeting[] = [];
  * @param fileIds 文件ID列表
  * @param updateFilesStatus 更新文件分析状态的回调
  */
-export function useAnalysisResults(
-  fileIds: string[], 
-  updateFilesStatus: (fileIds: string[], status: FileStatus) => void
-) {
-  const [meetings, setMeetings] = useState<IMeeting[]>(emptyMeetings);
-  const [isAnalyzing, setIsAnalyzing] = useState(false);
-  const [loadingResults, setLoadingResults] = useState(false);
-
-  // 处理分析请求
-  const handleAnalyze = useCallback(async (selectedFileIds: string[]) => {
-    if (selectedFileIds.length === 0) return;
-    
-    try {
-      setIsAnalyzing(true);
-      // 更新所选文件状态为分析中
-      updateFilesStatus(selectedFileIds, 'analyzing');
-      
-      logger.info(`开始分析文件`, { fileCount: selectedFileIds.length });
-      
-      // 调用Dify API进行文件分析
-      // 注意: 目前还使用旧的API，实际实现时应创建新的API直接返回会议和决策项
-      const oldResults = await analyzeDifyFiles(selectedFileIds);
-      
-      // 从旧数据结构中构建会议和决策项
-      const newMeetings: IMeeting[] = [];
-      
-      // 需要创建一个新的函数 analyzeMeetingsFromFiles 来直接生成符合 IMeeting 的数据
-      // 这里仅作为迁移期的转换处理
-      
-      if (oldResults) {
-        // 为每个分类创建对应的会议记录
-        const categoryTypeMappings: {[key: string]: string} = {
-          'majorDecisions': 'majorDecision',
-          'personnelAppointments': 'personnelAppointment',
-          'majorProjects': 'majorProject',
-          'largeAmounts': 'largeAmount'
-        };
-        
-        const categoryNameMappings: {[key: string]: string} = {
-          'majorDecisions': '重大决策会议',
-          'personnelAppointments': '重要干部任免会议',
-          'majorProjects': '重大项目会议',
-          'largeAmounts': '大额资金会议'
-        };
-        
-        // 遍历每个三重一大类型
-        for (const [category, items] of Object.entries(oldResults)) {
-          if (items.length > 0) {
-            const meetingDate = new Date().toISOString();
-            const documentNo = `${category.substring(0, 2).toUpperCase()}-${new Date().getFullYear()}`;
-            
-            newMeetings.push({
-              meetingDate: meetingDate,
-              documentNo: documentNo,
-              meetingTopic: categoryNameMappings[category] || `${category} 会议`,
-              conclusion: `通过${categoryNameMappings[category]}事项`,
-              summary: `讨论并批准${categoryNameMappings[category]}事项`,
-              documentName: `${categoryNameMappings[category]}纪要`,
-              isTripleOneMeeting: true,
-              keyDecisionItems: items.map((item: AnalysisResult) => ({
-                categoryType: categoryTypeMappings[category] || 'other',
-                details: item.eventDetails || '',
-                amount: item.amountInvolved ? `￥${item.amountInvolved}` : '',
-                departments: item.relatedDepartments ? item.relatedDepartments.split(',') : [],
-                personnel: item.relatedPersonnel ? item.relatedPersonnel.split(',') : [],
-                decisionBasis: item.decisionBasis || '',
-                originalText: item.originalText || ''
-              }))
+export function useAnalysisResults(fileIds: string[], updateFilesStatus: (fileIds: string[], status: FileStatus) => void) {
+    const [meetings, setMeetings] = useState<IMeeting[]>(emptyMeetings);
+    const [isAnalyzing, setIsAnalyzing] = useState(false);
+    const [loadingResults, setLoadingResults] = useState(false);
+
+    // 处理分析请求
+    const handleAnalyze = useCallback(async (selectedFileIds: string[]) => {
+        if (selectedFileIds.length === 0) return;
+
+        try {
+            setIsAnalyzing(true);
+            // 更新所选文件状态为分析中
+            updateFilesStatus(selectedFileIds, 'analyzing');
+
+            logger.info(`开始分析文件`, {fileCount: selectedFileIds.length});
+
+            // 调用Dify API进行文件分析
+            // 注意: 目前还使用旧的API，实际实现时应创建新的API直接返回会议和决策项
+            const oldResults = await analyzeDifyFiles(selectedFileIds);
+
+            // 从旧数据结构中构建会议和决策项
+            const newMeetings: IMeeting[] = [];
+
+            // 需要创建一个新的函数 analyzeMeetingsFromFiles 来直接生成符合 IMeeting 的数据
+            // 这里仅作为迁移期的转换处理
+
+            if (oldResults) {
+                // 为每个分类创建对应的会议记录
+                const categoryTypeMappings: { [key: string]: string } = {
+                    'majorDecisions': 'majorDecision',
+                    'personnelAppointments': 'personnelAppointment',
+                    'majorProjects': 'majorProject',
+                    'largeAmounts': 'largeAmount'
+                };
+
+                const categoryNameMappings: { [key: string]: string } = {
+                    'majorDecisions': '重大决策会议',
+                    'personnelAppointments': '重要干部任免会议',
+                    'majorProjects': '重大项目会议',
+                    'largeAmounts': '大额资金会议'
+                };
+
+                // 遍历每个三重一大类型
+                for (const [category, items] of Object.entries(oldResults)) {
+                    if (items.length > 0) {
+                        const meetingDate = new Date().toISOString();
+                        const documentNo = `${category.substring(0, 2).toUpperCase()}-${new Date().getFullYear()}`;
+
+                        newMeetings.push({
+                            meetingDate: meetingDate,
+                            documentNo: documentNo,
+                            meetingTopic: categoryNameMappings[category] || `${category} 会议`,
+                            conclusion: `通过${categoryNameMappings[category]}事项`,
+                            summary: `讨论并批准${categoryNameMappings[category]}事项`,
+                            documentName: `${categoryNameMappings[category]}纪要`,
+                            isTiobMeeting: true,
+                            keyDecisionItems: items.map((item: AnalysisResult) => ({
+                                categoryType: categoryTypeMappings[category] || 'other',
+                                details: item.eventDetails || '',
+                                amount: item.amountInvolved ? `￥${item.amountInvolved}` : '',
+                                departments: item.relatedDepartments ? item.relatedDepartments.split(',') : [],
+                                personnel: item.relatedPersonnel ? item.relatedPersonnel.split(',') : [],
+                                decisionBasis: item.decisionBasis || '',
+                                originalText: item.originalText || ''
+                            }))
+                        });
+                    }
+                }
+            }
+
+            // 设置会议数据
+            setMeetings(newMeetings);
+
+            // 更新文件状态为已分析
+            updateFilesStatus(selectedFileIds, 'analyzed');
+            logger.info('分析完成，找到会议数量', {
+                meetingsCount: newMeetings.length,
+                keyDecisionsCount: newMeetings.reduce((total: number, meeting: IMeeting) => total + (meeting.keyDecisionItems?.length || 0), 0)
+            });
+        } catch (error) {
+            logger.error('分析过程中发生错误:', {error});
+            // 更新文件状态为错误
+            updateFilesStatus(selectedFileIds, 'analysis_failed');
+        } finally {
+            setIsAnalyzing(false);
+        }
+    }, [updateFilesStatus]);
+
+    // 加载分析结果
+    const loadResults = useCallback(async () => {
+        if (fileIds.length === 0) return;
+
+        try {
+            setLoadingResults(true);
+            logger.info('加载会议和决策项数据', {fileCount: fileIds.length});
+
+            // 从数据库直接加载会议和决策项数据
+            const meetings = await loadMeetings(fileIds);
+
+            // 设置会议数据
+            setMeetings(meetings);
+            logger.info('已加载会议数据', {
+                meetingsCount: meetings.length,
+                keyDecisionsCount: meetings.reduce((total: number, meeting: IMeeting) => total + (meeting.keyDecisionItems?.length || 0), 0)
             });
-          }
+        } catch (error) {
+            logger.error('加载会议数据时发生错误:', {error});
+        } finally {
+            setLoadingResults(false);
         }
-      }
-      
-      // 设置会议数据
-      setMeetings(newMeetings);
-      
-      // 更新文件状态为已分析
-      updateFilesStatus(selectedFileIds, 'analyzed');
-      logger.info('分析完成，找到会议数量', {
-        meetingsCount: newMeetings.length,
-        keyDecisionsCount: newMeetings.reduce((total: number, meeting: IMeeting) => 
-          total + (meeting.keyDecisionItems?.length || 0), 0)
-      });
-    } catch (error) {
-      logger.error('分析过程中发生错误:', { error });
-      // 更新文件状态为错误
-      updateFilesStatus(selectedFileIds, 'error');
-    } finally {
-      setIsAnalyzing(false);
-    }
-  }, [updateFilesStatus]);
-
-  // 加载分析结果
-  const loadResults = useCallback(async () => {
-    if (fileIds.length === 0) return;
-    
-    try {
-      setLoadingResults(true);
-      logger.info('加载会议和决策项数据', { fileCount: fileIds.length });
-      
-      // 从数据库直接加载会议和决策项数据
-      const meetings = await loadMeetings(fileIds);
-      
-      // 设置会议数据
-      setMeetings(meetings);
-      logger.info('已加载会议数据', {
-        meetingsCount: meetings.length,
-        keyDecisionsCount: meetings.reduce((total: number, meeting: IMeeting) => 
-          total + (meeting.keyDecisionItems?.length || 0), 0)
-      });
-    } catch (error) {
-      logger.error('加载会议数据时发生错误:', { error });
-    } finally {
-      setLoadingResults(false);
-    }
-  }, [fileIds]);
-
-  // 初始加载结果
-  // useEffect(() => {
-  //   loadResults();
-  // }, [loadResults]);
-
-  return {
-    meetings,
-    isAnalyzing,
-    loadingResults,
-    handleAnalyze
-  };
+    }, [fileIds]);
+
+    // 初始加载结果
+    // useEffect(() => {
+    //   loadResults();
+    // }, [loadResults]);
+
+    return {
+        meetings, isAnalyzing, loadingResults, handleAnalyze
+    };
 }
diff --git a/components/projects/hooks/useStreamingAnalysis.ts b/components/projects/hooks/useStreamingAnalysis.ts
index 123681f..5d39bc8 100644
--- a/components/projects/hooks/useStreamingAnalysis.ts
+++ b/components/projects/hooks/useStreamingAnalysis.ts
@@ -1,7 +1,7 @@
 'use client';
 
+import {FileStatus} from "@/components/projects/utils/file-status";
 import { useState, useCallback, useRef, useEffect } from 'react';
-import { FileStatus } from '../types';
 import { streamAnalyzeDifyFiles, cancelDifyAnalysis, DifySSEMessage } from '@/lib/actions/dify-streaming-actions';
 import { logger } from '@/lib/logger';
 import { IKeyDecisionItem, IMeeting } from '@/types/analysis';
@@ -137,7 +137,7 @@ export function useStreamingAnalysis(
         // 关闭连接
         closeEventSource(fileId);
         // 更新文件状态
-        updateFilesStatus([fileId], 'error');
+        updateFilesStatus([fileId], 'analysis_failed');
       }
     } else {
       // 取消所有分析
@@ -179,7 +179,7 @@ export function useStreamingAnalysis(
       closeEventSource();
       // 更新所有文件状态
       const fileIds = Array.from(fileTasks.keys());
-      updateFilesStatus(fileIds, 'error');
+      updateFilesStatus(fileIds, 'analysis_failed');
     }
     
     // 重置全局分析状态
@@ -228,10 +228,10 @@ useEffect(() => {
         if (jsonData["会议数据"] && Array.isArray(jsonData["会议数据"])) {
           parsedData.meetingData = jsonData["会议数据"] as IMeeting[];
         }
-        // 检查是否包含basicInfo和tripleOneMajorItems
+        // 检查是否包含basicInfo和tiobItems
         else if (jsonData["basicInfo"]) {
           const meetingInfo = jsonData["basicInfo"];
-          const keyDecisionItems = (jsonData["tripleOneMajorItems"] || []) as IKeyDecisionItem[];
+          const keyDecisionItems = (jsonData["tiobItems"] || []) as IKeyDecisionItem[];
 
           // 处理会议数据
           if (Array.isArray(meetingInfo)) {
@@ -311,7 +311,7 @@ useEffect(() => {
             }
             
             // 更新文件状态
-            updateFilesStatus([fileId], 'error');
+            updateFilesStatus([fileId], 'analysis_failed');
             shouldUpdateGlobalState = true;
           } 
           else if (message.event === 'done') {
@@ -511,7 +511,7 @@ const startStreamingAnalysis = useCallback(async (fileIds: string[]) => {
             return newTasks;
           });
           
-          updateFilesStatus([fileId], 'error');
+          updateFilesStatus([fileId], 'analysis_failed');
         };
         
         logger.info('文件SSE连接已建立', { fileId });
@@ -529,14 +529,14 @@ const startStreamingAnalysis = useCallback(async (fileIds: string[]) => {
           return newTasks;
         });
         
-        updateFilesStatus([fileId], 'error');
+        updateFilesStatus([fileId], 'analysis_failed');
       }
     }
   } catch (error) {
     logger.error('启动批量流式分析时出错', { error });
     setError(error instanceof Error ? error.message : '启动分析失败');
     setIsAnalyzing(false);
-    updateFilesStatus(fileIds, 'error');
+    updateFilesStatus(fileIds, 'analysis_failed');
   }
 }, [updateFilesStatus, createMessageHandler, setExpandedFileIds]);
   
@@ -552,9 +552,9 @@ const startStreamingAnalysis = useCallback(async (fileIds: string[]) => {
           logger.info('成功从流式结果中提取会议数据');
           
           // 如果有分开的basicInfo和三重一大事项列表，需要组装
-          if (jsonData["basicInfo"] && jsonData["tripleOneMajorItems"]) {
+          if (jsonData["basicInfo"] && jsonData["tiobItems"]) {
             const meetingInfo = jsonData["basicInfo"];
-            const keyDecisionItems = (jsonData["tripleOneMajorItems"] || []) as IKeyDecisionItem[];
+            const keyDecisionItems = (jsonData["tiobItems"] || []) as IKeyDecisionItem[];
             
             if (Array.isArray(meetingInfo)) {
               // 返回了多个会议
diff --git a/components/projects/ProjectsList.tsx b/components/projects/list/ProjectsList.tsx
similarity index 100%
rename from components/projects/ProjectsList.tsx
rename to components/projects/list/ProjectsList.tsx
diff --git a/components/projects/types.ts b/components/projects/types.ts
index 9d89b1f..3fca687 100644
--- a/components/projects/types.ts
+++ b/components/projects/types.ts
@@ -2,12 +2,6 @@
 
 import { IMeeting } from '@/types/analysis';
 
-// 文件状态类型
-export type FileStatus = 'pending' | 'analyzing' | 'analyzed' | 'error';
-
-// 分析结果状态类型
-export type AnalysisStatus = 'pending' | 'processing' | 'completed' | 'error';
-
 // 已废弃，使用新的 IMeeting 和 IKeyDecisionItem 接口
 // 此处仅利用定义一个兼容类型，方便迁移期间使用
 export interface AnalysisResult {
diff --git a/components/projects/utils/analysis-event.tsx b/components/projects/utils/analysis-event.tsx
new file mode 100644
index 0000000..9b179f1
--- /dev/null
+++ b/components/projects/utils/analysis-event.tsx
@@ -0,0 +1,9 @@
+// 分析事件类型
+export type AnalysisEvent = {
+    event: string;
+    task_id?: string;
+    message?: string;
+    error?: string;
+    data?: any;
+    answer?: string;
+};
\ No newline at end of file
diff --git a/components/projects/utils/file-status-badge.tsx b/components/projects/utils/file-status-badge.tsx
new file mode 100644
index 0000000..778435f
--- /dev/null
+++ b/components/projects/utils/file-status-badge.tsx
@@ -0,0 +1,28 @@
+import {FileStatus} from "@/components/projects/utils/file-status";
+import {Badge} from "@/components/ui/badge";
+import {AlertCircle, CheckCircle, Clock, RefreshCw} from "lucide-react";
+
+/**
+ * 文档状态徽章组件
+ */
+export function FileStatusBadge({status}: { status: FileStatus }) {
+    switch (status) {
+        case 'uploading':
+            return <Badge variant="secondary" className="bg-blue-100 text-blue-800"><Clock
+                className="h-3 w-3 mr-1"/> 上传中</Badge>;
+        case 'upload_failed':
+            return <Badge variant="destructive"><AlertCircle className="h-3 w-3 mr-1"/> 上传失败</Badge>;
+        case 'uploaded':
+            return <Badge variant="outline" className="border-green-500 text-green-500"><CheckCircle
+                className="h-3 w-3 mr-1"/> 已上传</Badge>;
+        case 'analyzing':
+            return <Badge variant="secondary" className="bg-purple-100 text-purple-800"><RefreshCw
+                className="h-3 w-3 mr-1 animate-spin"/> 分析中</Badge>;
+        case 'analysis_failed':
+            return <Badge variant="destructive"><AlertCircle className="h-3 w-3 mr-1"/> 分析失败</Badge>;
+        case 'analyzed':
+            return <Badge className="bg-green-500"><CheckCircle className="h-3 w-3 mr-1"/> 已分析</Badge>;
+        default:
+            return null;
+    }
+}
\ No newline at end of file
diff --git a/components/projects/utils/file-status.tsx b/components/projects/utils/file-status.tsx
new file mode 100644
index 0000000..ce646a3
--- /dev/null
+++ b/components/projects/utils/file-status.tsx
@@ -0,0 +1,9 @@
+// 文件状态枚举
+export type FileStatus =
+    | 'pending'
+    | 'uploading' // 正在上传
+    | 'upload_failed' // 上传失败
+    | 'uploaded' // 已上传
+    | 'analyzing' // 正在分析
+    | 'analysis_failed' // 分析失败
+    | 'analyzed'; // 已分析
\ No newline at end of file
diff --git a/components/projects/utils/ui-file.tsx b/components/projects/utils/ui-file.tsx
new file mode 100644
index 0000000..0395c77
--- /dev/null
+++ b/components/projects/utils/ui-file.tsx
@@ -0,0 +1,17 @@
+// 扩展文件类型以适配UI需求
+import {FileStatus} from "@/components/projects/utils/file-status";
+
+export interface UIFile {
+    id: string;
+    originalName: string;
+    fileSize: number;
+    fileType: string;
+    filePath: string;
+    status: FileStatus;
+    userId: string;
+    isAnalyzed?: boolean;
+    progress?: number; // 上传进度 0-100
+    analysisResult?: string; // 分析结果
+    error?: string; // 错误信息
+    uploadDate: string;
+}
\ No newline at end of file
diff --git "a/data/dify - \345\256\241\350\256\241\345\244\247\345\270\210.md" "b/data/dify - \345\256\241\350\256\241\345\244\247\345\270\210.md"
new file mode 100644
index 0000000..317c8c0
--- /dev/null
+++ "b/data/dify - \345\256\241\350\256\241\345\244\247\345\270\210.md"	
@@ -0,0 +1,304 @@
+你是一个专业的审计辅助工具，专门用于从会议纪要文档中提取"三重一大"相关信息并进行结构化输出。
+
+## 背景说明
+
+"三重一大"是指：
+- 重大决策：涉及单位战略调整、改制重组、民生政策等全局性事项
+- 重要干部任免：包括领导班子成员、关键岗位人员的选拔任用
+- 重大项目：如重大基建、海外投资、并购等高风险项目
+- 大额资金：单笔或累计超过规定限额的资金运作
+
+## 你的任务
+
+1. 仔细阅读用户上传的会议纪要文档
+2. 判断文档是否属于"三重一大"相关会议
+3. 如果是，从文档中提取以下结构化信息
+
+## 需要提取的字段
+
+1. 会议基本信息:
+   - meetingDate
+   - documentNo
+   - meetingTopic
+
+2. 三重一大具体事项:
+   - categoryType: majorDecision/personnelAppointment/majorProject/largeAmount
+   - details
+   - amount
+   - departments
+   - personnel
+   - decisionBasis
+   - originalText
+
+## 处理要求
+
+1. **精准提取**：确保提取的信息准确无误，特别是会议时间、资金数额、人员姓名等关键信息
+2. **类别判断**：根据内容准确判断事项类别，一份文档可能包含多个类别的事项
+3. **数据标准化**：
+   - 日期格式统一为"YYYY-MM-DD"
+   - 金额格式统一为数字+单位（如"500万元"）
+   - 人名格式统一，避免职务和姓名混淆
+4. **缺失处理**：对于文档中未明确提及的字段，标记为"未提及"
+
+## 特殊情况处理
+
+1. **一份文档多个事项**：如果一份会议纪要包含多个"三重一大"事项，为每个事项单独提取信息
+2. **无三重一大事项**：如果文档是会议纪要但不包含"三重一大"事项，仍提取会议基本信息，但标记该会议不属于"三重一大"
+3. **模糊信息**：对于表述模糊的信息，尝试从上下文推断，并在对应字段中注明"（推断）"
+4. **非标准格式**：对于非标准格式的文档，灵活调整提取策略，确保信息完整性
+5. **不相关文档**：如果文档与会议纪要无关，标记不是三重一大会议，并简要说明原因
+
+## 分析步骤
+
+1. 首先判断文档是否为会议纪要
+2. 提取基本信息（时间、文号、议题等）
+3. 分析会议内容，识别是否涉及"三重一大"事项
+4. 根据内容确定具体事项类别
+5. 提取详细信息并结构化输出
+
+请记住，你的分析结果将用于审计工作，准确性至关重要。
+
+## 示例
+
+### 示例1：重大决策会议
+
+**输入：**
+```
+A公司董事会会议纪要
+文号：A-2025-003
+日期：2025年3月15日
+
+议题：战略重组计划审议
+
+出席人员：
+- 张伟（董事长）
+- 李明（总经理）
+- 王芳（财务总监）
+- 陈杰（运营总监）
+
+会议摘要：
+董事会审议并讨论了公司的战略重组计划。经过充分讨论，董事会一致批准了将北方分部和南方分部的研发部门合并的计划，预计整合成本为350万元。
+
+结论：
+1. 批准研发部门整合计划
+2. 拨款350万元用于重组费用
+3. 计划于2025年4月1日开始实施
+4. 人力资源部和财务部负责协调过渡工作
+```
+
+**输出：**
+```json
+{
+  "basicInfo": {
+    "meetingDate": "2025-03-15",
+    "documentNo": "A-2025-003",
+    "meetingTopic": "战略重组计划审议",
+  },
+  "tiobItems": [
+    {
+      "categoryType": "majorDecision",
+      "details": "将北方分部和南方分部的研发部门合并",
+      "amount": "350万元",
+      "departments": "研发部门、人力资源部、财务部",
+      "personnel": "未提及",
+      "decisionBasis": "董事会一致批准",
+      "originalText": "董事会一致批准了将北方分部和南方分部的研发部门合并的计划，预计整合成本为350万元。"
+    },
+    {
+      "categoryType": "largeAmount",
+      "details": "重组费用拨款",
+      "amount": "350万元",
+      "departments": "财务部",
+      "personnel": "未提及",
+      "decisionBasis": "董事会一致批准",
+      "originalText": "拨款350万元用于重组费用"
+    }
+  ]
+}
+```
+
+### 示例2：重要干部任免会议
+
+**输入：**
+```
+国有企业人事委员会会议纪要
+文号：SOE-HR-2025-042
+日期：2025年2月8日
+
+议题：关键岗位任命
+
+出席人员：
+- 刘梅（人力资源总监）
+- 赵军（主席）
+- 吴玲（委员会成员）
+- 孙涛（委员会成员）
+
+会议摘要：
+人事委员会召开会议，讨论并批准了几个关键岗位的任命。在审核候选人资历和绩效记录后，委员会做出了以下决定：
+
+决定：
+1. 任命黄小明为新任首席技术官，自2025年3月1日起生效
+2. 提拔张丽丽为国际业务总监
+3. 将徐成从市场部调任至新成立的数字化转型办公室担任负责人
+
+实施要求：
+- 人力资源部于2025年2月15日前发出正式任命函
+- 薪酬调整按照公司高管岗位政策执行
+- 一周内提交过渡计划
+```
+
+**输出：**
+```json
+{
+  "basicInfo": {
+    "meetingDate": "2025-02-08",
+    "documentNo": "SOE-HR-2025-042",
+    "meetingTopic": "关键岗位任命",
+  },
+  "tiobItems": [
+    {
+      "categoryType": "personnelAppointment",
+      "details": "任命新任首席技术官",
+      "amount": "未提及",
+      "departments": "人力资源部、技术部",
+      "personnel": "黄小明",
+      "decisionBasis": "审核候选人资历和绩效记录",
+      "originalText": "任命黄小明为新任首席技术官，自2025年3月1日起生效"
+    },
+    {
+      "categoryType": "personnelAppointment",
+      "details": "提拔为国际业务总监",
+      "amount": "未提及",
+      "departments": "人力资源部、国际业务部",
+      "personnel": "张丽丽",
+      "decisionBasis": "审核候选人资历和绩效记录",
+      "originalText": "提拔张丽丽为国际业务总监"
+    },
+    {
+      "categoryType": "personnelAppointment",
+      "details": "调任数字化转型办公室负责人",
+      "amount": "未提及",
+      "departments": "人力资源部、市场部、数字化转型办公室",
+      "personnel": "徐成",
+      "decisionBasis": "审核候选人资历和绩效记录",
+      "originalText": "将徐成从市场部调任至新成立的数字化转型办公室担任负责人"
+    }
+  ]
+}
+```
+
+### 示例3：重大项目会议
+
+**输入：**
+```
+基础设施投资委员会会议
+文号：IIC-2025-007
+日期：2025年4月23日
+
+项目审议：东南区域数据中心建设
+
+参会人员：
+- 杨主任
+- 周工程师长
+- 高财务总监
+- 林项目经理
+- 外部顾问王博士
+
+项目详情：
+委员会审议了在东南区域建设新数据中心的提案。该项目预估预算为7800万元，建设周期为18个月。该设施将容纳关键IT基础设施，支持公司在该地区的数字化扩展。
+
+风险评估：
+- 财务风险：中等（大额资本支出）
+- 技术风险：低（成熟技术）
+- 进度风险：中等（天气依赖性）
+
+决定：
+经过充分讨论，委员会批准了该项目，附带以下条件：
+1. 总预算不超过7800万元，否则需要额外批准
+2. 项目分三个阶段执行，设置阶段性审查
+3. 需要提交月度进度报告
+4. 工程部门负责实施，财务部门进行监督
+
+下一步行动：
+- 与选定供应商进行最终合同谈判
+- 土地收购在2025年5月30日前完成
+- 奠基仪式定于2025年6月15日举行
+```
+
+**输出：**
+```json
+{
+  "basicInfo": {
+    "meetingDate": "2025-04-23",
+    "documentNo": "IIC-2025-007",
+    "meetingTopic": "东南区域数据中心建设",
+  },
+  "tiobItems": [
+    {
+      "categoryType": "majorProject",
+      "details": "在东南区域建设新数据中心",
+      "amount": "7800万元",
+      "departments": "工程部门、财务部门",
+      "personnel": "杨主任、周工程师长、高财务总监、林项目经理、外部顾问王博士",
+      "decisionBasis": "委员会审议和讨论",
+      "originalText": "经过充分讨论，委员会批准了该项目，附带以下条件：总预算不超过7800万元，否则需要额外批准"
+    },
+    {
+      "categoryType": "largeAmount",
+      "details": "数据中心建设预算分配",
+      "amount": "7800万元",
+      "departments": "财务部门",
+      "personnel": "高财务总监",
+      "decisionBasis": "委员会批准",
+      "originalText": "总预算不超过7800万元，否则需要额外批准"
+    }
+  ]
+}
+```
+
+### 示例4：非三重一大会议
+
+**输入：**
+```
+部门周例会
+日期：2025年5月5日
+
+议程：
+1. 团队更新
+2. 项目状态回顾
+3. 即将到来的截止日期
+4. 其他事项
+
+讨论记录：
+- 市场团队报告了第一季度活动成功完成
+- IT服务台注意到工单量增加，考虑临时增加人手
+- 人力资源部门提醒下周年度绩效评估截止日期
+- 办公室经理宣布周末将进行大楼维护
+
+行动项：
+- 所有团队负责人在周五前提交第二季度计划
+- 俊负责调查IT工单激增情况并汇报
+- 梅负责分发绩效评估模板
+- 所有人在周末维护前备份电脑
+```
+
+**输出：**
+```json
+{
+  "basicInfo": {
+    "meetingDate": "2025-05-05",
+    "documentNo": "未提及",
+    "meetingTopic": "部门周例会",
+  },
+  "tiobItems": []
+}
+```
+
+## 用户文档
+
+{{#1744224803363.text#}}
+
+## 特别注意
+- 最终的输出应该是一个标准、严格的 json 文件
+- 这个 json 使用 ```json{内容}``` code block 表示
+- 不需要解释，只要输出 json 结构体即可
\ No newline at end of file
diff --git a/data/example.json b/data/example.json
index 738c855..57645de 100644
--- a/data/example.json
+++ b/data/example.json
@@ -6,7 +6,7 @@
     "conclusion": "原则同意选取拆除单位进行房屋拆除，要求规范推进",
     "summary": "会议讨论通过房屋拆除工作方案，并部署苗木资产管理工作。包含：1.选定拆除单位推进征收房屋拆除 2.制定征收区域苗木管理方案 3.强调国有资产保全措施",
     "documentName": "书记专题会议纪要",
-    "isTripleOneMeeting": true
+    "isTiobMeeting": true
   },
   "三重一大具体事项": [
     {
diff --git a/docs/alibaba/Upload objects directly to OSS from clients - Object Storage Service.md b/docs/alibaba/Upload objects directly to OSS from clients - Object Storage Service.md
deleted file mode 100644
index a38e8b6..0000000
--- a/docs/alibaba/Upload objects directly to OSS from clients - Object Storage Service.md	
+++ /dev/null
@@ -1,256 +0,0 @@
----
-title: Upload objects directly to OSS from clients - Object Storage Service
-source: https://www.alibabacloud.com/help/en/oss/use-cases/uploading-objects-to-oss-directly-from-clients/
----
-
-Unlock the Power of AI
-
-1 million free tokens
-
-88% Price Reduction
-
-Activate Now
-English
-  Cart
-Console
-Log In
-Home Page
-Object Storage Service
-Use Cases
-Direct client uploads
-Search for Help Content
-Upload objects directly to OSS from clients
-Updated at: 2024-11-15 06:15
-Product
-Community
-
-A direct client upload allows you to upload data directly to Object Storage Service (OSS) from clients. The direct client upload solution accelerates uploads and reduces the resource usage of the application server by eliminating the need to transfer objects to and from the application server. This topic describes the benefits, implementation methods, and best practices of this solution.
-
-Benefits
-
-In the traditional server and client architecture, uploading data to OSS from the application server is the common upload method. The client uploads objects to the application server, and then the application server uploads the objects to OSS. During the upload process, data must be transferred twice over the network. This results in a waste of network resources and an increase in the resource usage of the application server. To resolve this issue, you can upload objects directly to OSS without the need to upload the objects to the application server.
-
-Implementation methods
-
-To upload data directly to OSS from clients, you must resolve the following issues:
-
-CORS
-
-If your client is a web client or mini program, you must allow cross-origin resource sharing (CORS). In most cases, browsers and mini programs prohibit CORS to ensure data security. This prevents your client code from being used to connect to OSS. You can configure CORS rules to allow web applications or mini programs on a specific domain name to access OSS. For more information, see CORS.
-
-Security authorization
-
-To upload an object to OSS, you need to use the AccessKey pair of a RAM user to complete signing for authentication. However, if the client uses a permanent AccessKey pair, AccessKey pair leaks may occur, which causes data security risks. To resolve this issue, you can use one of the following solutions to implement secure upload:
-
-Obtain temporary access credentials from STS on the application server
-
-In most object upload scenarios, we recommend that you use Security Token Service (STS) SDKs to obtain temporary access credentials on the application server, and then use the temporary access credentials and OSS SDKs to upload objects from the client directly to OSS. The client can reuse the temporary access credentials on the application server to generate a signature. This is suitable for scenarios in which multipart upload and resumable upload are used to upload large objects. However, frequent calls to STS may cause throttling. In this case, we recommend that you cache the temporary access credentials and renew them before they expire. To further prevent abuses of temporary access credentials on the client, we recommend that you configure additional policies to restrict the use of the temporary access credentials. For more information, see What is STS?
-
-Obtain a signature and POST policy for PostObject from the application server
-
-In scenarios in which you want to limit the attributes of an object to upload, you need to obtain information required to call the PostObject operation from the application server. The required information includes a signature and a POST policy. Then, the client can use the obtained information to upload the object directly to OSS without using OSS SDKs. You can use the policy generated by the application server to limit the attributes of the object, such as the object size and type. This solution is suitable for scenarios in which you want to upload objects by using HTML forms. This solution does not support multipart upload and resumable upload. For more information, see PostObject.
-
-Obtain a signed URL for PutObject from the application server
-
-For simple object upload scenarios, you can use OSS SDKs on the application server to obtain a signed URL that is required to call the PutObject operation. Then, the client can use the signed URL to upload an object without using OSS SDKs. This solution is not suitable for multipart upload and resumable upload. The application server generates a signed URL for each part and returns the signed URL to the client. This increases the number of interactions with the application server and the complexity of network requests. In addition, the client may modify the content or order of the parts, which results in an invalid combined object. For more information, see Include a V1 signature in a URL.
-
-Obtain temporary access credentials from STS on the application serverObtain a signature and POST policy for PostObject from the application serverObtain a signed URL for PutObject from the application server
-
-The following figure shows how to upload an object to OSS from a client by using STS temporary access credentials returned from the application server.
-
-The client requests temporary access credentials from the application server.
-
-The application server uses STS SDKs to call the AssumeRole operation to obtain temporary access credentials.
-
-STS generates and returns the temporary access credentials to the application server.
-
-The application server returns the temporary access credentials to the client.
-
-The client uses OSS SDKs to upload an object to OSS by using the temporary access credentials.
-
-OSS returns a success response to the client.
-
-Examples
-
-The following examples provide only core code blocks. For complete code samples, download the sts.zip package.
-
-Server-side sample code
-
-The following sample code provides examples on how the application server obtains temporary access credentials from STS:
-
-Note
-
-The sample code can be deployed in Function Compute. oss-upload-sts-app
-
-PythonJavaGoPHPNode.jsRubyC#
- 
-import json
-from alibabacloud_tea_openapi.models import Config
-from alibabacloud_sts20150401.client import Client as Sts20150401Client
-from alibabacloud_sts20150401 import models as sts_20150401_models
-from alibabacloud_credentials.client import Client as CredentialClient
-
-# Replace <YOUR_ROLE_ARN> with the Alibaba Cloud Resource Name (ARN) of the RAM role that has the permissions to upload objects to the OSS bucket. 
-role_arn_for_oss_upload = '<YOUR_ROLE_ARN>'
-# Replace <YOUR_REGION_ID> with the ID of the region of the STS service. Example: cn-hangzhou. 
-region_id = '<YOUR_REGION_ID>'
-
-def get_sts_token():
-    # If you do not specify parameters when you initialize CredentialClient, the default credential chain is used. 
-    # If you run the program on your local computer, you can obtain the AccessKey pair from the ALIBABA_CLOUD_ACCESS_KEY_ID and ALIBABA_CLOUD_ACCESS_KEY_SECRET environment variables.
-    # If you run the program on Elastic Compute Service (ECS) or Elastic Container Instance, you can specify the role of the bound instance by configuring the ALIBABA_CLOUD_ECS_METADATA environment variable. The SDK automatically obtains the temporary access credentials from STS. 
-    config = Config(region_id=region_id, credential=CredentialClient())
-    sts_client = Sts20150401Client(config=config)
-    assume_role_request = sts_20150401_models.AssumeRoleRequest(
-        role_arn=role_arn_for_oss_upload,
-        # Replace <YOUR_ROLE_SESSION_NAME> with your custom session name, such as oss-role-session. 
-        role_session_name='<YOUR_ROLE_SESSION_NAME>'
-    )
-    response = sts_client.assume_role(assume_role_request)
-    token = json.dumps(response.body.credentials.to_map())
-    return token
-
-
-Client-side sample code
-
-The following sample code provides an example on how to use the temporary access credentials to upload an object to OSS from a web client:
-
-JavaScript
- 
-let credentials = null;
-const form = document.querySelector("form");
-form.addEventListener("submit", async (event) => {
-  event.preventDefault();
-  // Reobtain temporary access credentials only if they expire. This reduces the number of calls to STS. 
-  if (isCredentialsExpired(credentials)) {
-    const response = await fetch("/get_sts_token_for_oss_upload", {
-      method: "GET",
-    });
-    if (!response.ok) {
-      // Handle HTTP error codes. 
-      throw new Error(
-        'Failed to obtain STS token: ${response.status} ${response.statusText}'
-      );
-    }
-    credentials = await response.json();
-  }
-  const client = new OSS({
-    // Replace <YOUR_BUCKET> with the name of the OSS bucket. 
-    bucket: "<YOUR_BUCKET>",
-    // Replace <YOUR_REGION> with the ID of the region in which the OSS bucket is located. Example: oss-cn-hangzhou. 
-    region: "oss-<YOUR_REGION>",
-    accessKeyId: credentials.AccessKeyId,
-    accessKeySecret: credentials.AccessKeySecret,
-    stsToken: credentials.SecurityToken,
-  });
-
-  const fileInput = document.querySelector("#file");
-  const file = fileInput.files[0];
-  const result = await client.put(file.name, file);
-  console.log(result);
-});
-
-/**
- * Determine whether the temporary access credentials expire. 
- **/
-function isCredentialsExpired(credentials) {
-  if (!credentials) {
-    return true;
-  }
-  const expireDate = new Date(credentials.Expiration);
-  const now = new Date();
-  // If the remaining validity period of the temporary access credentials is less than 1 minute, the temporary access credentials are considered expired. 
-  return expireDate.getTime() - now.getTime() <= 60000;
-}
-Best practices
-
-For information about the best practices for uploading data to OSS from clients, see the following topics:
-
-Overview of uploading objects to OSS from web clients
-
-Set up direct data transfer for mobile applications
-
-Feedback
-Previous: Overview
-Next: Upload objects to OSS from web applications
-
-About
-
-About Alibaba Cloud
-Pricing Models
-Products
-Customers
-Partners
-Startups
-Apsara Conference
-Alibaba Cloud Summit
-
-Promotions
-
-Free Trial
-Simple Application Server
-
-Explore
-
-China Gateway
-ICP License Support
-Getting Started
-Blog
-Marketplace
-Training & Certification
-
-Support
-
-Contact Sales
-Submit a Ticket
-After-Sales Support
-Security Report
-Feedback
-Pricing Calculator
-
-Resources
-
-Documentation Center
-Alibaba Cloud MVP
-Security & Compliance
-Press Room
-WHOIS
-Site Map
-Status
-
-Products & Solutions
-
-Elastic Compute Service
-CDN
-Anti-DDoS
-Object Storage Service
-eCommerce
-Web Hosting
-Security
-
-Hot Content
-
-Japan Site
-ECS Documentation
-How to get Domains
-Software Infrastructure
-Learning Path
-New Users
-
-Recommended
-
-Topic Center
-Cloud Computing
-Industries
-Developers
-Web Developing
-Tutorials
-PHP Tutorials
-
-Find Us
-
-Payment Methods We Support
-
-Careers About Us Privacy Policy Legal Notice List Links
-© 2009-2025 Copyright by Alibaba Cloud All rights reserved
-Alibaba Group Taobao Marketplace Tmall Juhuasuan AliExpress Alibaba.com 1688 Alimama Fliggy YunOS Amap UCWeb Umeng Xiami DingTalk Alipay
diff --git a/docs/alibaba/oss.md b/docs/alibaba/oss.md
deleted file mode 100644
index cb9de04..0000000
--- a/docs/alibaba/oss.md
+++ /dev/null
@@ -1,4090 +0,0 @@
-Skip to content
-Navigation Menu
-ali-sdk
-ali-oss
-
-Type / to search
-Code
-Issues
-98
-Pull requests
-26
-Actions
-Projects
-Wiki
-Security
-Insights
-Owner avatar
-ali-oss
-Public
-ali-sdk/ali-oss
-Go to file
-t
-Name		
-YunZZY
-YunZZY
-Merge pull request #1345 from ali-sdk/release
-eb6289d
- · 
-3 months ago
-.github
-feat: multipartUpload supports setting storage-class header (#1308)
-8 months ago
-.husky
-chore: add commitlint (#1105)
-3 years ago
-dist
-chore(release): 6.22.0 [skip ci]
-3 months ago
-example
-chore: add prettier and batch format code (#1222)
-2 years ago
-lib
-chore(release): 6.22.0 [skip ci]
-3 months ago
-shims
-feat: support signature v4 (#1277)
-last year
-task
-feat: support PostObject policy v4 signature and restore archive obje…
-4 months ago
-test
-chore(release): 6.22.0 (#1343)
-3 months ago
-.eslintignore
-fix: add check to file of get(#1228)
-7 months ago
-.eslintrc.js
-feat: putBucketInventory supports new fields (#1290)
-8 months ago
-.gitignore
-chore: update package-lock.json and readme(#1260)
-7 months ago
-.prettierignore
-fix: add check to file of get(#1228)
-7 months ago
-.prettierrc
-feat: listObjectsV2 (#888)
-5 years ago
-.releaserc
-chore: add github workflow release.yml (#1243)
-2 years ago
-.snyk
-fix: package.json & .snyk to reduce vulnerabilities (#655)
-6 years ago
-AUTHORS
-chore: bump 6.2.0 (#685)
-6 years ago
-CHANGELOG.md
-chore(release): 6.22.0 (#1343)
-3 months ago
-LICENSE
-transfer to ali-sdk/ali-oss
-10 years ago
-README.md
-feat: support PostObject policy v4 signature and restore archive obje…
-4 months ago
-SECURITY.md
-Update SECURITY.md (#989)
-4 years ago
-UPGRADING.md
-chore: add prettier and batch format code (#1222)
-2 years ago
-browser-build.js
-chore: add github workflow release.yml (#1243)
-2 years ago
-codecov.yml
-feat: add async task (#818)
-5 years ago
-commitlint.config.js
-chore: add github workflow release.yml (#1243)
-2 years ago
-karma.conf.js
-chore(release): 6.22.0 (#1343)
-3 months ago
-nyc.config.js
-feat: add async task (#818)
-5 years ago
-package-lock.json
-feat: support PostObject policy v4 signature and restore archive obje…
-4 months ago
-package.json
-chore(release): 6.22.0 [skip ci]
-3 months ago
-publish-check.js
-chore: add prettier and batch format code (#1222)
-2 years ago
-publish-npm-check.js
-chore: add prettier and batch format code (#1222)
-2 years ago
-publish.js
-chore: add prettier and batch format code (#1222)
-2 years ago
-tsconfig-cjs.json
-feat: add async task (#818)
-5 years ago
-tsconfig.json
-chore: add prettier and batch format code (#1222)
-2 years ago
-Repository files navigation
-README
-MIT license
-Security
-oss-js-sdk
-NPM version build status coverage David deps
-
-aliyun OSS(Object Storage Service) js client for Node and Browser env.
-
-NOTE： For SDK 5.X document, please go to README.md
-
-Install
-npm install ali-oss --save
-Compatibility
-Node
-Node.js >= 8.0.0 required. You can use 4.x in Node.js < 8.
-
-Browser
-IE >= 10 & Edge
-Major versions of Chrome/Firefox/Safari
-Major versions of Android/iOS/WP
-Note:
-
-For Lower browsers you can refer to PostObject, if you want to see more practices ,please refer to Web Post
-QA
-Please log in to the official website and contact technical support.
-
-License
-MIT
-
-OSS Usage
-OSS, Object Storage Service. Equal to well known Amazon S3.
-
-All operation use es7 async/await to implement. All api is async function.
-
-Summary
-Node Usage
-
-Browser Usage
-
-Data Regions
-
-Create Account
-
-Create A Bucket Instance
-
-oss(options)
-Bucket Operations
-
-Base
-.listBuckets(query[, options])
-.putBucket(name[, options])
-.useBucket(name)
-.deleteBucket(name[, options])
-.getBucketInfo(name)
-.getBucketStat(name)
-.getBucketLocation(name)
-ACL
-.putBucketACL(name, acl[, options])
-.getBucketACL(name[, options])
-Logging
-.putBucketLogging(name, prefix[, options])
-.getBucketLogging(name[, options])
-.deleteBucketLogging(name[, options])
-Website
-.putBucketWebsite(name, config[, options])
-.getBucketWebsite(name[, options])
-.deleteBucketWebsite(name, region[, options])
-Referer
-.putBucketReferer(name, allowEmpty, referers[, options])
-.getBucketReferer(name[, options])
-.deleteBucketReferer(name[, options])
-Lifecycle
-.putBucketLifecycle(name, rules[, options])
-.getBucketLifecycle(name[, options])
-.deleteBucketLifecycle(name[, options])
-CORS
-.putBucketCORS(name, rules[, options])
-.getBucketCORS(name[, options])
-.deleteBucketCORS(name[, options])
-RequestPayment
-.getBucketRequestPayment(bucketName[, options])
-.putBucketRequestPayment(bucketName, payer[, options])
-BucketEncryption
-.putBucketEncryption(name[, rules])
-.getBucketEncryption(name)
-.deleteBucketEncryption(name)
-tagging
-.putBucketTags(name, tag[, options])
-.getBucketTags(name, [, options])
-.deleteBucketTags(name, [, options])
-policy
-.putBucketPolicy(name, policy[, options])
-.getBucketPolicy(name, [, options])
-.deleteBucketPolicy(name, [, options])
-versioning
-.getBucketVersioning(name, [, options])
-.putBucketVersioning(name, status[, options])
-inventory
-.getBucketInventory(name, inventoryId[, options])
-.putBucketInventory(name, inventory[, options])
-.deleteBucketInventory(name, inventoryId[, options])
-.listBucketInventory(name, [, options])
-worm
-.abortBucketWorm(name[, options])
-.completeBucketWorm(name, wormId[, options])
-.extendBucketWorm(name, wormId, days[, options])
-.getBucketWorm(name[, options])
-.initiateBucketWorm(name, days[, options])
-Object Operations
-
-.list(query[, options])
-.listV2(query[, options])
-.getBucketVersions(query[, options])
-.put(name, file[, options])
-.putStream(name, stream[, options])
-.append(name, file[, options])
-.getObjectUrl(name[, baseUrl])
-.generateObjectUrl(name[, baseUrl])
-.head(name[, options])
-.getObjectMeta(name[, options])
-.get(name[, file, options])
-.getStream(name[, options])
-.delete(name[, options])
-.copy(name, sourceName[, sourceBucket, options])
-.putMeta(name, meta[, options])
-.deleteMulti(names[, options])
-.signatureUrl(name[, options, strictObjectNameValidation])
-.asyncSignatureUrl(name[, options, strictObjectNameValidation])
-.signatureUrlV4(method, expires[, request, objectName, additionalHeaders])
-.putACL(name, acl[, options])
-.getACL(name[, options])
-.restore(name[, options])
-.putSymlink(name, targetName[, options])
-.getSymlink(name[, options])
-.initMultipartUpload(name[, options])
-.uploadPart(name, uploadId, partNo, file, start, end[, options])
-.uploadPartCopy(name, uploadId, partNo, range, sourceData[, options])
-.completeMultipartUpload(name, uploadId, parts[, options])
-.multipartUpload(name, file[, options])
-.multipartUploadCopy(name, sourceData[, options])
-.listParts(name, uploadId[, query, options])
-.listUploads(query[, options])
-.abortMultipartUpload(name, uploadId[, options])
-.calculatePostSignature(policy)
-.signPostObjectPolicyV4(policy, date)
-.getObjectTagging(name, [, options])
-.putObjectTagging(name, tag[, options])
-.deleteObjectTagging(name, [, options])
-RTMP Operations
-
-.putChannel(id, conf[, options])
-.getChannel(id[, options])
-.deleteChannel(id[, options])
-.putChannelStatus(id, status[, options])
-.getChannelStatus(id[, options])
-.listChannels(query[, options])
-.getChannelHistory(id[, options])
-.createVod(id, name, time[, options])
-.getRtmpUrl(channelId[, options])
-Create A Image Service Instance
-
-oss.ImageClient(options)
-Image Operations
-
-imgClient.get(name, file[, options])
-imgClient.getStream(name[, options])
-imgClient.getExif(name[, options])
-imgClient.getInfo(name[, options])
-imgClient.putStyle(name, style[, options])
-imgClient.getStyle(name[, options])
-imgClient.listStyle([options])
-imgClient.deleteStyle(name[, options])
-imgClient.signatureUrl(name)
-Known Errors
-
-Node Usage
-Compatibility
-Node: >= 8.0.0
-Basic usage
-1.install SDK using npm
-
-npm install ali-oss --save
-2.for example:
-
-const OSS = require('ali-oss');
-const store = new OSS({
-  region: '<oss region>',
-  accessKeyId: '<Your accessKeyId>',
-  accessKeySecret: '<Your accessKeySecret>',
-  bucket: '<Your bucket name>'
-});
-Browser Usage
-You can use most of the functionalities of ali-oss in browser with some exceptions:
-
-put object with streaming: no chunked encoding, we use multipart upload instead
-get object to local file: we cannot manipulate file system in browser, we provide signed object url for downloading needs
-bucket operations(listBuckets, putBucketLogging, etc) will fail: OSS server currently do not support CORS requests for bucket operations (will probably be fixed later)
-Compatibility
-IE >= 10 & Edge
-Major versions of Chrome/Firefox/Safari
-Major versions of Android/iOS/WP
-Note: Because some browsers do not support promises, you need to introduce promise compatible libraries.
-For example: IE10 and IE11 need to introduce a promise-polyfill.
-
-Setup
-Bucket setup
-As browser-side javascript involves CORS operations. You need to setup your bucket CORS rules to allow CORS operations:
-
-set allowed origins to '*'
-allowed methods to 'PUT, GET, POST, DELETE, HEAD'
-set allowed headers to '*'
-expose 'ETag' in expose headers
-STS setup
-As we don't want to expose the accessKeyId/accessKeySecret in the browser, a common practice is to use STS to grant temporary access.
-
-Basic usage
-Include the sdk lib in the <script> tag and you have OSS available for creating client.
-
-// x.x.x The specific version number represented // we recommend introducing offline resources, because the usability of
-online resources depends on the stability of the cdn server.
-<!-- Introducing online resources -->
-<script src="http://gosspublic.alicdn.com/aliyun-oss-sdk-x.x.x.min.js"></script>
-<!-- Introducing offline resources -->
-<script src="./aliyun-oss-sdk-x.x.x.min.js"></script>
-
-<script type="text/javascript">
-  const store = new OSS({
-    region: 'oss-cn-hangzhou',
-    accessKeyId: '<access-key-id>',
-    accessKeySecret: '<access-key-secret>',
-    bucket: '<bucket-name>',
-    stsToken: '<security-token>'
-  });
-
-  store
-    .list()
-    .then(result => {
-      console.log('objects: %j', result.objects);
-      return store.put('my-obj', new OSS.Buffer('hello world'));
-    })
-    .then(result => {
-      console.log('put result: %j', result);
-      return store.get('my-obj');
-    })
-    .then(result => {
-      console.log('get result: %j', result.content.toString());
-    });
-</script>
-The full sample can be found here.
-
-How to build
-npm run build-dist
-And see the build artifacts under dist/.
-
-Data Regions
-OSS current data regions.
-
-region	country	city	endpoint	internal endpoint
-oss-cn-hangzhou	China	HangZhou	oss-cn-hangzhou.aliyuncs.com	oss-cn-hangzhou-internal.aliyuncs.com
-oss-cn-shanghai	China	ShangHai	oss-cn-shanghai.aliyuncs.com	oss-cn-shanghai-internal.aliyuncs.com
-oss-cn-qingdao	China	QingDao	oss-cn-qingdao.aliyuncs.com	oss-cn-qingdao-internal.aliyuncs.com
-oss-cn-beijing	China	BeiJing	oss-cn-beijing.aliyuncs.com	oss-cn-beijing-internal.aliyuncs.com
-oss-cn-shenzhen	China	ShenZhen	oss-cn-shenzhen.aliyuncs.com	oss-cn-shenzhen-internal.aliyuncs.com
-oss-cn-hongkong	China	HongKong	oss-cn-hongkong.aliyuncs.com	oss-cn-hongkong-internal.aliyuncs.com
-oss-us-west-1	US	Silicon Valley	oss-us-west-1.aliyuncs.com	oss-us-west-1-internal.aliyuncs.com
-oss-ap-southeast-1	Singapore	Singapore	oss-ap-southeast-1.aliyuncs.com	oss-ap-southeast-1-internal.aliyuncs.com
-Create Account
-Go to OSS website, create a new account for new user.
-
-After account created, you can create the OSS instance and get the accessKeyId and accessKeySecret.
-
-Create A Bucket Instance
-Each OSS instance required accessKeyId, accessKeySecret and bucket.
-
-oss(options)
-Create a Bucket store instance.
-
-options:
-
-accessKeyId {String} access key you create on aliyun console website
-accessKeySecret {String} access secret you create
-[stsToken] {String} used by temporary authorization, detail see
-[refreshSTSToken] {Function} used by auto set stsToken、accessKeyId、accessKeySecret when sts info expires. return value must be object contains stsToken、accessKeyId、accessKeySecret
-[refreshSTSTokenInterval] {number} use time (ms) of refresh STSToken interval it should be less than sts info expire interval, default is 300000ms(5min)
-[bucket] {String} the default bucket you want to access If you don't have any bucket, please use putBucket() create one first.
-[endpoint] {String} oss region domain. It takes priority over region. Set as extranet domain name, intranet domain name, accelerated domain name, etc. according to different needs. please see endpoints
-[region] {String} the bucket data region location, please see Data Regions, default is oss-cn-hangzhou.
-[internal] {Boolean} access OSS with aliyun internal network or not, default is false. If your servers are running on aliyun too, you can set true to save a lot of money.
-[secure] {Boolean} instruct OSS client to use HTTPS (secure: true) or HTTP (secure: false) protocol.
-[timeout] {String|Number} instance level timeout for all operations, default is 60s.
-[cname] {Boolean}, default false, access oss with custom domain name. if true, you can fill endpoint field with your custom domain name,
-[isRequestPay] {Boolean}, default false, whether request payer function of the bucket is open, if true, will send headers 'x-oss-request-payer': 'requester' to oss server. the details you can see requestPay
-[useFetch] {Boolean}, default false, it just work in Browser, if true,it means upload object with fetch mode ,else XMLHttpRequest
-[enableProxy] {Boolean}, Enable proxy request, default is false. NOTE: When enabling proxy request, please ensure that proxy-agent is installed.
-[proxy] {String | Object}, proxy agent uri or options, default is null.
-[retryMax] {Number}, used by auto retry send request count when request error is net error or timeout. NOTE: Not support put with stream, putStream, append with stream because the stream can only be consumed once
-[maxSockets] {Number} Maximum number of sockets to allow per host. Default is infinity
-[authorizationV4] {Boolean} Use V4 signature. Default is false.
-example:
-
-basic usage
-const OSS = require('ali-oss');
-
-const store = new OSS({
-  accessKeyId: 'your access key',
-  accessKeySecret: 'your access secret',
-  bucket: 'your bucket name',
-  region: 'oss-cn-hangzhou'
-});
-use accelerate endpoint
-Global accelerate endpoint: oss-accelerate.aliyuncs.com
-Accelerate endpoint of regions outside mainland China: oss-accelerate-overseas.aliyuncs.com
-const OSS = require('ali-oss');
-
-const store = new OSS({
-  accessKeyId: 'your access key',
-  accessKeySecret: 'your access secret',
-  bucket: 'your bucket name',
-  endpoint: 'oss-accelerate.aliyuncs.com'
-});
-use custom domain
-const OSS = require('ali-oss');
-
-const store = new OSS({
-  accessKeyId: 'your access key',
-  accessKeySecret: 'your access secret',
-  cname: true,
-  endpoint: 'your custome domain'
-});
-use STS and refreshSTSToken
-const OSS = require('ali-oss');
-
-const store = new OSS({
-  accessKeyId: 'your STS key',
-  accessKeySecret: 'your STS secret',
-  stsToken: 'your STS token',
-  refreshSTSToken: async () => {
-    const info = await fetch('you sts server');
-    return {
-      accessKeyId: info.accessKeyId,
-      accessKeySecret: info.accessKeySecret,
-      stsToken: info.stsToken
-    };
-  },
-  refreshSTSTokenInterval: 300000
-});
-retry request with stream
-for (let i = 0; i <= store.options.retryMax; i++) {
-  try {
-    const result = await store.putStream('<example-object>', fs.createReadStream('<example-path>'));
-    console.log(result);
-    break; // break if success
-  } catch (e) {
-    console.log(e);
-  }
-}
-use V4 signature, and use optional additionalHeaders option which type is a string array, and the values inside need to be included in the header.
-const OSS = require('ali-oss');
-
-const store = new OSS({
-  accessKeyId: 'your access key',
-  accessKeySecret: 'your access secret',
-  bucket: 'your bucket name',
-  region: 'oss-cn-hangzhou',
-  authorizationV4: true
-});
-
-try {
-  const bucketInfo = await store.getBucketInfo('your bucket name');
-  console.log(bucketInfo);
-} catch (e) {
-  console.log(e);
-}
-
-try {
-  const putObjectResult = await store.put('your bucket name', 'your object name', {
-    headers: {
-      // The headers of this request
-      header1: 'value1',
-      header2: 'value2'
-    },
-    // The keys of the request headers that need to be calculated into the V4 signature. Please ensure that these additional headers are included in the request headers.
-    additionalHeaders: ['additional header1', 'additional header2']
-  });
-  console.log(putObjectResult);
-} catch (e) {
-  console.log(e);
-}
-Bucket Operations
-.listBuckets(query[, options])
-List buckets in this account.
-
-parameters:
-
-[query] {Object} query parameters, default is null
-[prefix] {String} search buckets using prefix key
-[marker] {String} search start from marker, including marker key
-[max-keys] {String|Number} max buckets, default is 100, limit to 1000
-[options] {Object} optional parameters
-[timeout] {Number} the operation timeout
-Success will return buckets list on buckets properties.
-
-buckets {Array} bucket meta info list Each BucketMeta will contains blow properties:
-name {String} bucket name
-region {String} bucket store data region, e.g.: oss-cn-hangzhou-a
-creationDate {String} bucket create GMT date, e.g.: 2015-02-19T08:39:44.000Z
-storageClass {String} e.g.: Standard, IA, Archive
-owner {Object} object owner, including id and displayName
-isTruncated {Boolean} truncate or not
-nextMarker {String} next marker string
-res {Object} response info, including
-status {Number} response status
-headers {Object} response headers
-size {Number} response size
-rt {Number} request total use time (ms)
-example:
-
-List top 10 buckets
-store
-  .listBuckets({
-    'max-keys': 10
-  })
-  .then(result => {
-    console.log(result);
-  });
-.putBucket(name[, options])
-Create a new bucket.
-
-parameters:
-
-name {String} bucket name If bucket exists and not belong to current account, will throw BucketAlreadyExistsError. If bucket not exists, will create a new bucket and set it's ACL.
-[options] {Object} optional parameters
-[acl] {String} include private,public-read,public-read-write
-[storageClass] {String} the storage type include (Standard,IA,Archive)
-[dataRedundancyType] {String} default LRS, include LRS,ZRS
-[timeout] {Number} the operation timeout
-Success will return the bucket name on bucket properties.
-
-bucket {String} bucket name
-res {Object} response info, including
-status {Number} response status
-headers {Object} response headers
-size {Number} response size
-rt {Number} request total use time (ms)
-example:
-
-Create a bucket name helloworld location on HongKong
-store.putBucket('helloworld').then(result => {
-  // use it by default
-  store.useBucket('helloworld');
-});
-Create a bucket name helloworld location on HongKong StorageClass Archive
-await store.putBucket('helloworld', { StorageClass: 'Archive' });
-// use it by default
-store.useBucket('helloworld');
-.deleteBucket(name[, options])
-Delete an empty bucket.
-
-parameters:
-
-name {String} bucket name If bucket is not empty, will throw BucketNotEmptyError. If bucket is not exists, will throw NoSuchBucketError.
-[options] {Object} optional parameters
-[timeout] {Number} the operation timeout
-Success will return:
-
-res {Object} response info, including
-status {Number} response status
-headers {Object} response headers
-size {Number} response size
-rt {Number} request total use time (ms)
-example:
-
-Delete the exists 'helloworld' bucket on 'oss-cn-hongkong'
-store.deleteBucket('helloworld').then(result => {});
-.useBucket(name)
-Use the bucket.
-
-parameters:
-
-name {String} bucket name
-example:
-
-Use helloworld as the default bucket
-store.useBucket('helloworld');
-.getBucketInfo(name)
-Get bucket information,include CreationDate、ExtranetEndpoint、IntranetEndpoint、Location、Name、StorageClass、 Owner、AccessControlList、Versioning
-
-parameters:
-
-name {String} bucket name
-example:
-
-Use helloworld as the default bucket
-store.getBucketInfo('helloworld').then(res => {
-  console.log(res.bucket);
-});
-.getBucketStat(name)
-Call the GetBucketStat interface to get the storage capacity of the specified storage space (Bucket) and the number of files (Object).
-
-Calling this interface requires the oss:GetBucketStat permission. The data obtained by calling this interface is not real-time data and may be delayed for more than an hour. The point in time of the stored information obtained by calling this interface is not guaranteed to be up-to-date, i.e. the LastModifiedTime field returned by a later call to this interface may be smaller than the LastModifiedTime field returned by a previous call to this interface.
-
-parameters:
-
-name {String} bucket name
-Success will return:
-
-stat {Object} container for the BucketStat structure:
-
-Storage {String} the total storage capacity of the Bucket, in bytes.
-ObjectCount {String} total number of Objects in the Bucket。
-MultipartUploadCount {String} the number of Multipart Uploads in the Bucket that have been initialized but not yet completed (Complete) or not yet aborted (Abort).
-LiveChannelCount {String} the number of Live Channels in the Bucket.
-LastModifiedTime {String} the point in time, in timestamps, when the storage information was retrieved.
-StandardStorage {String} the amount of storage of the standard storage type, in bytes.
-StandardObjectCount {String} the number of objects of the standard storage type.
-InfrequentAccessStorage {String} the amount of billed storage for the low-frequency storage type, in bytes.
-InfrequentAccessRealStorage {String} the actual storage amount of the low-frequency storage type, in bytes.
-InfrequentAccessObjectCount {String} the number of Objects of the low-frequency storage type.
-ArchiveStorage {String} the amount of billed storage for the archive storage type, in bytes.
-ArchiveRealStorage {String} the actual storage amount of the archive storage type, in bytes.
-ArchiveObjectCount {String} the number of objects of the archive storage type.
-ColdArchiveStorage {String} the amount of billed storage for the cold archive storage type, in bytes.
-ColdArchiveRealStorage {String} the actual storage amount in bytes for the cold archive storage type.
-ColdArchiveObjectCount {String} the number of objects of the cold archive storage type.
-res {Object} response info, including
-
-status {Number} response status
-headers {Object} response headers
-size {Number} response size
-rt {Number} request total use time (ms)
-example:
-
-If you don't fill in the name, the default is the bucket defined during initialization.
-store.getBucketStat().then(res => console.log(res));
-.getBucketLocation(name)
-Get bucket location
-
-parameters:
-
-name {String} bucket name
-example:
-
-Use helloworld as the default bucket
-store.getBucketLocation('helloworld').then(res => {
-  console.log(res.location);
-});
-.putBucketACL(name, acl[, options])
-Update the bucket ACL.
-
-parameters:
-
-name {String} bucket name
-acl {String} access control list, current available: public-read-write, public-read and private
-[options] {Object} optional parameters
-[timeout] {Number} the operation timeout
-Success will return:
-
-res {Object} response info, including
-status {Number} response status
-headers {Object} response headers
-size {Number} response size
-rt {Number} request total use time (ms)
-example:
-
-Set bucket helloworld to public-read-write
-store.putBucketACL('helloworld', 'public-read-write').then(result => {});
-.getBucketACL(name[, options])
-Get the bucket ACL.
-
-parameters:
-
-name {String} bucket name
-[options] {Object} optional parameters
-[timeout] {Number} the operation timeout
-Success will return:
-
-acl {String} acl settiongs string
-res {Object} response info, including
-status {Number} response status
-headers {Object} response headers
-size {Number} response size
-rt {Number} request total use time (ms)
-example:
-
-Get bucket helloworld
-store.getBucketACL('helloworld').then(result => {
-  console.log(result.acl);
-});
-.putBucketLogging(name, prefix[, options])
-Update the bucket logging settings. Log file will create every one hour and name format: <prefix><bucket>-YYYY-mm-DD-HH-MM-SS-UniqueString.
-
-parameters:
-
-name {String} bucket name
-[prefix] {String} prefix path name to store the log files
-[options] {Object} optional parameters
-[timeout] {Number} the operation timeout
-Success will return:
-
-res {Object} response info, including
-status {Number} response status
-headers {Object} response headers
-size {Number} response size
-rt {Number} request total use time (ms)
-example:
-
-Enable bucket helloworld logging and save with prefix logs/
-store.putBucketLogging('helloworld', 'logs/').then(result => {});
-.getBucketLogging(name[, options])
-Get the bucket logging settings.
-
-parameters:
-
-name {String} bucket name
-[options] {Object} optional parameters
-[timeout] {Number} the operation timeout
-Success will return:
-
-enable {Boolean} enable logging or not
-prefix {String} prefix path name to store the log files, maybe null
-res {Object} response info, including
-status {Number} response status
-headers {Object} response headers
-size {Number} response size
-rt {Number} request total use time (ms)
-example:
-
-Get bucket helloworld logging settings
-store.getBucketLogging('helloworld').then(result => {
-  console.log(result.enable, result.prefix);
-});
-.deleteBucketLogging(name[, options])
-Delete the bucket logging settings.
-
-parameters:
-
-name {String} bucket name
-[options] {Object} optional parameters
-[timeout] {Number} the operation timeout
-Success will return:
-
-res {Object} response info, including
-status {Number} response status
-headers {Object} response headers
-size {Number} response size
-rt {Number} request total use time (ms)
-.putBucketWebsite(name, config[, options])
-Set the bucket as a static website.
-
-parameters:
-
-name {String} bucket name
-config {Object} website config, contains blow properties:
-index {String} default page, e.g.: index.html
-[error] {String} error page, e.g.: 'error.html'
-[supportSubDir] {String} default vaule false
-[type] {String} default value 0
-[routingRules] {Array} RoutingRules
-[options] {Object} optional parameters
-[timeout] {Number} the operation timeout
-Success will return:
-
-res {Object} response info, including
-status {Number} response status
-headers {Object} response headers
-size {Number} response size
-rt {Number} request total use time (ms)
-example:
-
-store
-  .putBucketWebsite('hello', {
-    index: 'index.html'
-  })
-  .then(result => {});
-.getBucketWebsite(name[, options])
-Get the bucket website config.
-
-parameters:
-
-name {String} bucket name
-[options] {Object} optional parameters
-[timeout] {Number} the operation timeout
-Success will return:
-
-index {String} index page
-error {String} error page, maybe null
-supportSubDir {String}
-type {String}
-routingRules {Array}
-res {Object} response info, including
-status {Number} response status
-headers {Object} response headers
-size {Number} response size
-rt {Number} request total use time (ms)
-.deleteBucketWebsite(name[, options])
-Delete the bucket website config.
-
-parameters:
-
-name {String} bucket name
-[options] {Object} optional parameters
-[timeout] {Number} the operation timeout
-Success will return:
-
-res {Object} response info, including
-status {Number} response status
-headers {Object} response headers
-size {Number} response size
-rt {Number} request total use time (ms)
-.putBucketReferer(name, allowEmpty, referers[, options])
-Set the bucket request Referer white list.
-
-parameters:
-
-name {String} bucket name
-allowEmpty {Boolean} allow empty request referer or not
-referers {Array} Referer white list, e.g.:
-['https://npm.taobao.org', 'http://cnpmjs.org'];
-[options] {Object} optional parameters
-[timeout] {Number} the operation timeout
-Success will return:
-
-res {Object} response info, including
-status {Number} response status
-headers {Object} response headers
-size {Number} response size
-rt {Number} request total use time (ms)
-example:
-
-store.putBucketReferer('hello', false, ['https://npm.taobao.org', 'http://cnpmjs.org']).then(result => {});
-.getBucketReferer(name[, options])
-Get the bucket request Referer white list.
-
-parameters:
-
-name {String} bucket name
-[options] {Object} optional parameters
-[timeout] {Number} the operation timeout
-Success will return:
-
-allowEmpty {Boolean} allow empty request referer or not
-referers {Array} Referer white list
-res {Object} response info, including
-status {Number} response status
-headers {Object} response headers
-size {Number} response size
-rt {Number} request total use time (ms)
-.deleteBucketReferer(name[, options])
-Delete the bucket request Referer white list.
-
-parameters:
-
-name {String} bucket name
-[options] {Object} optional parameters
-[timeout] {Number} the operation timeout
-Success will return:
-
-res {Object} response info, including
-status {Number} response status
-headers {Object} response headers
-size {Number} response size
-rt {Number} request total use time (ms)
-.putBucketLifecycle(name, rules[, options])
-Set the bucket object lifecycle.
-
-parameters:
-
-name {String} bucket name
-rules {Array} rule config list, each Rule will contains blow properties:
-[id] {String} rule id, if not set, OSS will auto create it with random string.
-prefix {String} store prefix
-status {String} rule status, allow values: Enabled or Disabled
-[expiration] {Object} specifies the expiration attribute of the lifecycle rules for the object.
-[days] {Number|String} expire after the days
-[createdBeforeDate] {String} expire date, e.g.: 2022-10-11T00:00:00.000Z
-[expiredObjectDeleteMarker] {String} value true createdBeforeDate and days and expiredObjectDeleteMarker must have one.
-[abortMultipartUpload] {Object} Specifies the expiration attribute of the multipart upload tasks that are not complete.
-[days] {Number|String} expire after the days
-[createdBeforeDate] {String} expire date, e.g.: 2022-10-11T00:00:00.000Z createdBeforeDate and days must have one.
-[transition] {Object} Specifies the time when an object is converted to the IA or archive storage class during a valid life cycle.
-storageClass {String} Specifies the storage class that objects that conform to the rule are converted into. allow values: IA or Archive or ColdArchive or DeepColdArchive
-[days] {Number|String} expire after the days
-[createdBeforeDate] {String} expire date, e.g.: 2022-10-11T00:00:00.000Z createdBeforeDate and days must have one.
-[noncurrentVersionTransition] {Object} Specifies the time when an object is converted to the IA or archive storage class during a valid life cycle.
-storageClass {String} Specifies the storage class that history objects that conform to the rule are converted into. allow values: IA or Archive or ColdArchive or DeepColdArchive
-noncurrentDays {String} expire after the noncurrentDays expiration、 abortMultipartUpload、 transition、 noncurrentVersionTransition must have one.
-[noncurrentVersionExpiration] {Object} specifies the expiration attribute of the lifecycle rules for the history object.
-noncurrentDays {String} expire after the noncurrentDays
-[tag] {Object} Specifies the object tag applicable to a rule. Multiple tags are supported.
-key {String} Indicates the tag key.
-value {String} Indicates the tag value. tag cannot be used with abortMultipartUpload
-[options] {Object} optional parameters
-[timeout] {Number} the operation timeout
-Success will return:
-
-res {Object} response info, including
-status {Number} response status
-headers {Object} response headers
-size {Number} response size
-rt {Number} request total use time (ms)
-example:
-
-store
-  .putBucketLifecycle('hello', [
-    {
-      id: 'delete after one day',
-      prefix: 'logs/',
-      status: 'Enabled',
-      days: 1
-    },
-    {
-      prefix: 'logs2/',
-      status: 'Disabled',
-      date: '2022-10-11T00:00:00.000Z'
-    }
-  ])
-  .then(result => {});
-example: for history with noncurrentVersionExpiration
-
-const result = await store.putBucketLifecycle(bucket, [
-  {
-    id: 'expiration1',
-    prefix: 'logs/',
-    status: 'Enabled',
-    expiration: {
-      days: '1'
-    },
-    noncurrentVersionExpiration: {
-      noncurrentDays: '1'
-    }
-  }
-]);
-console.log(result);
-example: for history with expiredObjectDeleteMarker
-
-const result = await store.putBucketLifecycle(bucket, [
-  {
-    id: 'expiration1',
-    prefix: 'logs/',
-    status: 'Enabled',
-    expiration: {
-      expiredObjectDeleteMarker: 'true'
-    },
-    noncurrentVersionExpiration: {
-      noncurrentDays: '1'
-    }
-  }
-]);
-console.log(result);
-example: for history with noncurrentVersionTransition
-
-const result = await store.putBucketLifecycle(bucket, [
-  {
-    id: 'expiration1',
-    prefix: 'logs/',
-    status: 'Enabled',
-    noncurrentVersionTransition: {
-      noncurrentDays: '10',
-      storageClass: 'IA'
-    }
-  }
-]);
-console.log(result);
-.getBucketLifecycle(name[, options])
-Get the bucket object lifecycle.
-
-parameters:
-
-name {String} bucket name
-[options] {Object} optional parameters
-[timeout] {Number} the operation timeout
-Success will return:
-
-rules {Array} the lifecycle rule list
-res {Object} response info, including
-status {Number} response status
-headers {Object} response headers
-size {Number} response size
-rt {Number} request total use time (ms)
-.deleteBucketLifecycle(name[, options])
-Delete the bucket object lifecycle.
-
-parameters:
-
-name {String} bucket name
-[options] {Object} optional parameters
-[timeout] {Number} the operation timeout
-Success will return:
-
-res {Object} response info, including
-status {Number} response status
-headers {Object} response headers
-size {Number} response size
-rt {Number} request total use time (ms)
-.putBucketCORS(name, rules[, options])
-Set CORS rules of the bucket object
-
-parameters:
-
-name {String} bucket name
-rules {Array} rule config list, each Rule will contains below properties:
-allowedOrigin {String/Array} configure for Access-Control-Allow-Origin header
-allowedMethod {String/Array} configure for Access-Control-Allow-Methods header
-[allowedHeader] {String/Array} configure for Access-Control-Allow-Headers header
-[exposeHeader] {String/Array} configure for Access-Control-Expose-Headers header
-[maxAgeSeconds] {String} configure for Access-Control-Max-Age header
-[options] {Object} optional parameters
-[timeout] {Number} the operation timeout
-Success will return:
-
-res {Object} response info, including
-status {Number} response status
-headers {Object} response headers
-size {Number} response size
-rt {Number} request total use time (ms)
-example:
-
-store
-  .putBucketCORS('hello', [
-    {
-      allowedOrigin: '*',
-      allowedMethod: ['GET', 'HEAD']
-    }
-  ])
-  .then(result => {});
-.getBucketCORS(name[, options])
-Get CORS rules of the bucket object.
-
-parameters:
-
-name {String} bucket name
-[options] {Object} optional parameters
-[timeout] {Number} the operation timeout
-Success will return:
-
-rules {Array} the CORS rule list
-res {Object} response info, including
-status {Number} response status
-headers {Object} response headers
-size {Number} response size
-rt {Number} request total use time (ms)
-.deleteBucketCORS(name[, options])
-Delete CORS rules of the bucket object.
-
-parameters:
-
-name {String} bucket name
-[options] {Object} optional parameters
-[timeout] {Number} the operation timeout
-Success will return:
-
-res {Object} response info, including
-status {Number} response status
-headers {Object} response headers
-size {Number} response size
-rt {Number} request total use time (ms)
-.getBucketRequestPayment(bucketName[, options])
-get RequestPayment value of the bucket object.
-
-parameters:
-
-bucketName {String} bucket name
-[options] {Object} optional parameters
-Success will return:
-
-status {Number} response status
-payer {String} payer, BucketOwner or Requester
-res {Object} response info, including
-data {Buffer} xml
-.putBucketRequestPayment(bucketName, payer[, options])
-put RequestPayment value of the bucket object.
-
-parameters:
-
-bucketName {String}
-payer {String} payer
-[options] {Object} optional parameters
-Success will return:
-
-status {Number} response status
-res {Object} response info
-.putBucketEncryption(name, rules)
-put BucketEncryption value of the bucket object.
-
-parameters:
-
-name {String} bucket name
-[rules] {Object} parameters
-SSEAlgorithm {String} encryption type, expect AES256 or KMS
-{KMSMasterKeyID} {String} needed when encryption type is KMS
-Success will return:
-
-status {Number} response status
-res {Object} response info
-.getBucketEncryption(name)
-get BucketEncryption rule value of the bucket object.
-
-parameters:
-
-name {String} bucket name
-Success will return:
-
-status {Number} response status
-res {Object} response info
-encryption {Object} rules
-SSEAlgorithm {String} encryption type, AES256 or KMS
-{KMSMasterKeyID} {String} will be return when encryption type is KMS
-.deleteBucketEncryption(name)
-delete BucketEncryption rule value of the bucket object.
-
-parameters:
-
-name {String} bucket name
-Success will return:
-
-status {Number} response status
-res {Object} response info
-.putBucketTags(name, tag[, options])
-Adds tags for a bucket or modify the tags for a bucket.
-
-parameters:
-
-name {String} the object name
-tag {Object} tag, eg. {var1: value1,var2:value2}
-[options] {Object} optional args
-Success will return:
-
-status {Number} response status
-res {Object} response info
-.getBucketTags(name[, options])
-Obtains the tags for a bucket.
-
-parameters:
-
-name {String} the object name
-[options] {Object} optional args
-Success will return:
-
-tag {Object} the tag of object
-res {Object} response info
-.deleteBucketTags(name[, options])
-Deletes the tags added for a bucket.
-
-parameters:
-
-name {String} the object name
-[options] {Object} optional args
-Success will return:
-
-status {Number} response status
-res {Object} response info
-.putBucketPolicy(name, policy[, options])
-Adds or modify policy for a bucket.
-
-parameters:
-
-name {String} the bucket name
-policy {Object} bucket policy
-[options] {Object} optional args
-Success will return:
-
-status {Number} response status
-res {Object} response info
-example:
-
-const policy = {
-  Version: '1',
-  Statement: [
-    {
-      Action: ['oss:PutObject', 'oss:GetObject'],
-      Effect: 'Deny',
-      Principal: ['1234567890'],
-      Resource: ['acs:oss:*:1234567890:*/*']
-    }
-  ]
-};
-const result = await store.putBucketPolicy(bucket, policy);
-console.log(result);
-.getBucketPolicy(name[, options])
-Obtains the policy for a bucket.
-
-parameters:
-
-name {String} the bucket name
-[options] {Object} optional args
-Success will return:
-
-policy {Object} the policy of bucket, if not exist, the value is null
-res {Object} response info
-status {Number} response status
-.deleteBucketPolicy(name[, options])
-Deletes the policy added for a bucket.
-
-parameters:
-
-name {String} the bucket name
-[options] {Object} optional args
-Success will return:
-
-status {Number} response status
-res {Object} response info
-.getBucketVersioning(name[, options])
-Obtains the version status of an object
-
-parameters:
-
-name {String} the bucket name
-[options] {Object} optional args
-Success will return:
-
-status {Number} response status
-versionStatus {String | undefined} version status, Suspended or Enabled. default value: undefined
-res {Object} response info
-.putBucketVersioning(name, status[, options])
-set the version status of an object
-
-parameters:
-
-name {String} the bucket name
-status {String} version status, allow values: Enabled or Suspended
-[options] {Object} optional args
-Success will return:
-
-status {Number} response status
-res {Object} response info
-.getBucketInventory(name, inventoryId[, options])
-get bucket inventory by inventory-id
-
-parameters:
-
-name {String} the bucket name
-inventoryId {String} inventory-id
-[options] {Object} optional args
-Success will return:
-
-inventory {Inventory}
-status {Number} response status
-res {Object} response info
-async function getBucketInventoryById() {
-  try {
-    const result = await store.getBucketInventory('bucket', 'inventoryid');
-    console.log(result.inventory);
-  } catch (err) {
-    console.log(err);
-  }
-}
-
-getBucketInventoryById();
-putBucketInventory(name, inventory[, options])
-set bucket inventory
-
-parameters:
-
-name {String} the bucket name
-inventory {Inventory} inventory config
-[options] {Object} optional args
-Success will return:
-
-status {Number} response status
-res {Object} response info
-type Field =
-  'Size | LastModifiedDate | ETag | StorageClass | IsMultipartUploaded | EncryptionStatus | ObjectAcl | TaggingCount | ObjectType | Crc64';
-interface Inventory {
-  id: string;
-  isEnabled: true | false;
-  prefix?: string;
-  OSSBucketDestination: {
-    format: 'CSV';
-    accountId: string;
-    rolename: string;
-    bucket: string;
-    prefix?: string;
-    encryption?:
-      | { 'SSE-OSS': '' }
-      | {
-          'SSE-KMS': {
-            keyId: string;
-          };
-        };
-  };
-  frequency: 'Daily' | 'Weekly';
-  includedObjectVersions: 'Current' | 'All';
-  optionalFields?: {
-    field?: Field[];
-  };
-}
-const inventory = {
-  id: 'default',
-  isEnabled: false, // `true` | `false`
-  prefix: 'ttt', // filter prefix
-  OSSBucketDestination: {
-    format: 'CSV',
-    accountId: '1817184078010220',
-    rolename: 'AliyunOSSRole',
-    bucket: 'your bucket',
-    prefix: 'test'
-    //encryption: {'SSE-OSS': ''},
-    /*
-      encryption: {
-      'SSE-KMS': {
-        keyId: 'test-kms-id';
-      };,
-    */
-  },
-  frequency: 'Daily', // `WEEKLY` | `Daily`
-  includedObjectVersions: 'All', // `All` | `Current`
-  optionalFields: {
-    field: [
-      'Size',
-      'LastModifiedDate',
-      'ETag',
-      'StorageClass',
-      'IsMultipartUploaded',
-      'EncryptionStatus',
-      'ObjectAcl',
-      'TaggingCount',
-      'ObjectType',
-      'Crc64'
-    ]
-  }
-};
-
-async function putInventory() {
-  const bucket = 'Your Bucket Name';
-  try {
-    await store.putBucketInventory(bucket, inventory);
-  } catch (err) {
-    console.log(err);
-  }
-}
-
-putInventory();
-deleteBucketInventory(name, inventoryId[, options])
-delete bucket inventory by inventory-id
-
-parameters:
-
-name {String} the bucket name
-inventoryId {String} inventory-id
-[options] {Object} optional args
-Success will return:
-
-status {Number} response status
-res {Object} response info
-listBucketInventory(name[, options])
-list bucket inventory
-
-parameters:
-
-name {String} the bucket name
-[options] {Object} optional args
-continuationToken used by search next page
-Success will return:
-
-status {Number} response status
-res {Object} response info
-example:
-
-async function listBucketInventory() {
-  const bucket = 'Your Bucket Name';
-  let nextContinuationToken;
-  // list all inventory of the bucket
-  do {
-    const result = await store.listBucketInventory(bucket, nextContinuationToken);
-    console.log(result.inventoryList);
-    nextContinuationToken = result.nextContinuationToken;
-  } while (nextContinuationToken);
-}
-
-listBucketInventory();
-.abortBucketWorm(name[, options])
-used to delete an unlocked retention policy.
-
-parameters:
-
-name {String} the bucket name
-[options] {Object} optional args
-Success will return:
-
-status {Number} response status
-res {Object} response info
-.completeBucketWorm(name, wormId[, options])
-used to lock a retention policy.
-
-parameters:
-
-name {String} the bucket name
-wormId {String} worm id
-[options] {Object} optional args
-Success will return:
-
-status {Number} response status
-res {Object} response info
-.extendBucketWorm(name, wormId, days[, options])
-used to extend the retention period of objects in a bucket whose retention policy is locked.
-
-parameters:
-
-name {String} the bucket name
-wormId {String} worm id
-days {String | Number} retention days
-[options] {Object} optional args
-Success will return:
-
-status {Number} response status
-res {Object} response info
-.getBucketWorm(name[, options])
-used to query the retention policy information of the specified bucket.
-
-parameters:
-
-name {String} the bucket name
-[options] {Object} optional args
-Success will return:
-
-wormId {String} worm id
-state {String} Locked or InProgress
-days {String} retention days
-creationDate {String}
-status {Number} response status
-res {Object} response info
-.initiateBucketWorm(name, days[, options])
-create a retention policy.
-
-parameters:
-
-name {String} the bucket name
-days {String | Number}} set retention days
-[options] {Object} optional args
-Success will return:
-
-wormId {String} worm id
-status {Number} response status
-res {Object} response info
-Object Operations
-All operations function return Promise, except signatureUrl.
-
-.put(name, file[, options])
-Add an object to the bucket.
-
-parameters:
-
-name {String} object name store on OSS
-file {String|Buffer|ReadStream|File(only support Browser)|Blob(only support Browser)} object local path, content buffer or ReadStream content instance use in Node, Blob and html5 File
-[options] {Object} optional parameters
-[timeout] {Number} the operation timeout (ms)
-[mime] {String} custom mime, will send with Content-Type entity header
-[meta] {Object} user meta, will send with x-oss-meta- prefix string e.g.: { uid: 123, pid: 110 }
-[callback] {Object} The callback parameter is composed of a JSON string encoded in Base64,detail see
-url {String} After a file is uploaded successfully, the OSS sends a callback request to this URL.
-[host] {String} The host header value for initiating callback requests.
-body {String} The value of the request body when a callback is initiated, for example, key=${key}&etag=${etag}&my_var=${x:my_var}.
-[contentType] {String} The Content-Type of the callback requests initiatiated, It supports application/x-www-form-urlencoded and application/json, and the former is the default value.
-[callbackSNI] {Boolean} Specifies whether OSS sends Server Name Indication (SNI) to the origin address specified by callbackUrl when a callback request is initiated from the client.
-[customValue] {Object} Custom parameters are a map of key-values
-e.g.:
-var customValue = { var1: 'value1', var2: 'value2' };
-[headers] {Object} extra headers
-'Cache-Control' cache control for download, e.g.: Cache-Control: public, no-cache
-'Content-Disposition' object name for download, e.g.: Content-Disposition: somename
-'Content-Encoding' object content encoding for download, e.g.: Content-Encoding: gzip
-'Expires' expires time for download, an absolute date and time. e.g.: Tue, 08 Dec 2020 13:49:43 GMT
-See more: PutObject
-[disabledMD5] {Boolean} default true, it just work in Browser. if false,it means that MD5 is automatically calculated for uploaded files. NOTE: Synchronous computing tasks will block the main process
-Success will return the object information.
-
-object:
-
-name {String} object name
-data {Object} callback server response data, sdk use JSON.parse() return
-res {Object} response info, including
-status {Number} response status
-headers {Object} response headers
-size {Number} response size
-rt {Number} request total use time (ms)
-example:
-
-Add an object through local file path
-const filepath = '/home/ossdemo/demo.txt';
-store.put('ossdemo/demo.txt', filepath).then((result) => {
-  console.log(result);
-});
-
-// {
-//   name: 'ossdemo/demo.txt',
-//   res: {
-//     status: 200,
-//     headers: {
-//       date: 'Tue, 17 Feb 2015 13:28:17 GMT',
-//       'content-length': '0',
-//       connection: 'close',
-//       etag: '"BF7A03DA01440845BC5D487B369BC168"',
-//       server: 'AliyunOSS',
-//       'x-oss-request-id': '54E341F1707AA0275E829244'
-//     },
-//     size: 0,
-//     rt: 92
-//   }
-// }
-Add an object through content buffer
-store.put('ossdemo/buffer', Buffer.from('foo content')).then((result) => {
-  console.log(result);
-});
-
-// {
-//   name: 'ossdemo/buffer',
-//   url: 'http://demo.oss-cn-hangzhou.aliyuncs.com/ossdemo/buffer',
-//   res: {
-//     status: 200,
-//     headers: {
-//       date: 'Tue, 17 Feb 2015 13:28:17 GMT',
-//       'content-length': '0',
-//       connection: 'close',
-//       etag: '"xxx"',
-//       server: 'AliyunOSS',
-//       'x-oss-request-id': '54E341F1707AA0275E829243'
-//     },
-//     size: 0,
-//     rt: 92
-//   }
-// }
-Add an object through readstream
-const filepath = '/home/ossdemo/demo.txt';
-store.put('ossdemo/readstream.txt', fs.createReadStream(filepath)).then((result) => {
-  console.log(result);
-});
-
-// {
-//   name: 'ossdemo/readstream.txt',
-//   url: 'http://demo.oss-cn-hangzhou.aliyuncs.com/ossdemo/readstream.txt',
-//   res: {
-//     status: 200,
-//     headers: {
-//       date: 'Tue, 17 Feb 2015 13:28:17 GMT',
-//       'content-length': '0',
-//       connection: 'close',
-//       etag: '"BF7A03DA01440845BC5D487B369BC168"',
-//       server: 'AliyunOSS',
-//       'x-oss-request-id': '54E341F1707AA0275E829242'
-//     },
-//     size: 0,
-//     rt: 92
-//   }
-// }
-.putStream(name, stream[, options])
-Add a stream object to the bucket.
-
-parameters:
-
-name {String} object name store on OSS
-stream {ReadStream} object ReadStream content instance
-[options] {Object} optional parameters
-[contentLength] {Number} the stream length, chunked encoding will be used if absent
-[timeout] {Number} the operation timeout
-[mime] {String} custom mime, will send with Content-Type entity header
-[meta] {Object} user meta, will send with x-oss-meta- prefix string e.g.: { uid: 123, pid: 110 }
-[callback] {Object} The callback parameter is composed of a JSON string encoded in Base64,detail see
-url {String} After a file is uploaded successfully, the OSS sends a callback request to this URL.
-[host] {String} The host header value for initiating callback requests.
-body {String} The value of the request body when a callback is initiated, for example, key=${key}&etag=${etag}&my_var=${x:my_var}.
-[contentType] {String} The Content-Type of the callback requests initiatiated, It supports application/x-www-form-urlencoded and application/json, and the former is the default value.
-[callbackSNI] {Boolean} Specifies whether OSS sends Server Name Indication (SNI) to the origin address specified by callbackUrl when a callback request is initiated from the client.
-[customValue] {Object} Custom parameters are a map of key-values
-e.g.:
-var customValue = { var1: 'value1', var2: 'value2' };
-[headers] {Object} extra headers, detail see RFC 2616
-'Cache-Control' cache control for download, e.g.: Cache-Control: public, no-cache
-'Content-Disposition' object name for download, e.g.: Content-Disposition: somename
-'Content-Encoding' object content encoding for download, e.g.: Content-Encoding: gzip
-'Expires' expires time for download, an absolute date and time. e.g.: Tue, 08 Dec 2020 13:49:43 GMT
-Success will return the object information.
-
-object:
-
-name {String} object name
-res {Object} response info, including
-status {Number} response status
-headers {Object} response headers
-size {Number} response size
-rt {Number} request total use time (ms)
-example:
-
-Add an object through readstream
-const filepath = '/home/ossdemo/demo.txt';
-store.putStream('ossdemo/readstream.txt', fs.createReadStream(filepath)).then((result) => {
-  console.log(result);
-});
-
-// {
-//   name: 'ossdemo/readstream.txt',
-//   url: 'http://demo.oss-cn-hangzhou.aliyuncs.com/ossdemo/readstream.txt',
-//   res: {
-//     status: 200,
-//     headers: {
-//       date: 'Tue, 17 Feb 2015 13:28:17 GMT',
-//       'content-length': '0',
-//       connection: 'close',
-//       etag: '"BF7A03DA01440845BC5D487B369BC168"',
-//       server: 'AliyunOSS',
-//       'x-oss-request-id': '54E341F1707AA0275E829242'
-//     },
-//     size: 0,
-//     rt: 92
-//   }
-// }
-.append(name, file[, options])
-Append an object to the bucket, it's almost same as put, but it can add content to existing object rather than override it.
-
-All parameters are same as put except for options.position
-
-name {String} object name store on OSS
-file {String|Buffer|ReadStream} object local path, content buffer or ReadStream content instance
-[options] {Object} optional parameters
-[position] {String} specify the position which is the content length of the latest object
-[timeout] {Number} the operation timeout
-[mime] {String} custom mime, will send with Content-Type entity header
-[meta] {Object} user meta, will send with x-oss-meta- prefix string e.g.: { uid: 123, pid: 110 }
-[headers] {Object} extra headers, detail see RFC 2616
-'Cache-Control' cache control for download, e.g.: Cache-Control: public, no-cache
-'Content-Disposition' object name for download, e.g.: Content-Disposition: somename
-'Content-Encoding' object content encoding for download, e.g.: Content-Encoding: gzip
-'Expires' expires time for download, an absolute date and time. e.g.: Tue, 08 Dec 2020 13:49:43 GMT
-object:
-
-name {String} object name
-url {String} the url of oss
-res {Object} response info, including
-status {Number} response status
-headers {Object} response headers
-size {Number} response size
-rt {Number} request total use time (ms)
-nextAppendPosition {String} the next position（The browser needs to set cross domain and expose the x-oss-next-append-position header）
-example:
-
-let object = await store.append('ossdemo/buffer', Buffer.from('foo'));
-
-// append content to the existing object
-object = await store.append('ossdemo/buffer', Buffer.from('bar'), {
-  position: object.nextAppendPosition
-});
-.getObjectUrl(name[, baseUrl])
-Get the Object url. If provide baseUrl, will use baseUrl instead the default endpoint.
-
-e.g.:
-
-const cdnUrl = store.getObjectUrl('foo/bar.jpg', 'https://mycdn.domian.com');
-// cdnUrl should be `https://mycdn.domian.com/foo/bar.jpg`
-.generateObjectUrl(name[, baseUrl])
-Get the Object url. If provide baseUrl, will use baseUrl instead the default bucket and endpoint . Suggest use generateObjectUrl instead of getObjectUrl.
-
-e.g.:
-
-const url = store.generateObjectUrl('foo/bar.jpg');
-// cdnUrl should be `https://${bucketname}.${endpotint}foo/bar.jpg`
-
-const cdnUrl = store.generateObjectUrl('foo/bar.jpg', 'https://mycdn.domian.com');
-// cdnUrl should be `https://mycdn.domian.com/foo/bar.jpg`
-.head(name[, options])
-Head an object and get the meta info.
-
-parameters:
-
-name {String} object name store on OSS
-[options] {Object} optional parameters
-[timeout] {Number} the operation timeout
-[versionId] {String} the version id of history object
-[headers] {Object} extra headers, detail see RFC 2616
-'If-Modified-Since' object modified after this time will return 200 and object meta, otherwise return 304 not modified
-'If-Unmodified-Since' object modified before this time will return 200 and object meta, otherwise throw PreconditionFailedError
-'If-Match' object etag equal this will return 200 and object meta, otherwise throw PreconditionFailedError
-'If-None-Match' object etag not equal this will return 200 and object meta, otherwise return 304 not modified
-Success will return the object's meta information.
-
-object:
-
-status {Number} response status, maybe 200 or 304
-meta {Object} object user meta, if not set on put(), will return null. If return status 304, meta will be null too
-res {Object} response info, including
-status {Number} response status
-headers {Object} response headers
-[x-oss-version-id] return in multiversion
-size {Number} response size
-rt {Number} request total use time (ms)
-example:
-
-Head an exists object and get user meta
-await this.store.put('ossdemo/head-meta', Buffer.from('foo'), {
-  meta: {
-    uid: 1,
-    path: 'foo/demo.txt'
-  }
-});
-const object = await this.store.head('ossdemo/head-meta');
-console.log(object);
-
-// {
-//   status: 200,
-//   meta: {
-//     uid: '1',
-//     path: 'foo/demo.txt'
-//   },
-//   res: { ... }
-// }
-Head a not exists object
-const object = await this.store.head('ossdemo/head-meta');
-// will throw NoSuchKeyError
-.getObjectMeta(name[, options])
-Get an object meta info include ETag、Size、LastModified and so on, not return object content.
-
-parameters:
-
-name {String} object name store on OSS
-[options] {Object} optional parameters
-[timeout] {Number} the operation timeout
-[versionId] {String} the version id of history object
-Success will return the object's meta information.
-
-object:
-
-status {Number} response status
-res {Object} response info, including
-headers {Object} response headers
-example:
-
-Head an exists object and get object meta info
-await this.store.put('ossdemo/object-meta', Buffer.from('foo'));
-const object = await this.store.getObjectMeta('ossdemo/object-meta');
-console.log(object);
-
-// {
-//   status: 200,
-//   res: { ... }
-// }
-.get(name[, file, options])
-Get an object from the bucket.
-
-parameters:
-
-name {String} object name store on OSS
-[file] {String|WriteStream|Object} file path or WriteStream instance to store the content If file is null or ignore this parameter, function will return info contains content property. If file is Object, it will be treated as options.
-[options] {Object} optional parameters
-[versionId] {String} the version id of history object
-[timeout] {Number} the operation timeout
-[process] {String} image process params, will send with x-oss-process e.g.: {process: 'image/resize,w_200'}
-[responseCacheControl] {String} default no-cache, (only support Browser). response-cache-control, will response with HTTP Header Cache-Control
-[headers] {Object} extra headers, detail see RFC 2616
-'Range' get specifying range bytes content, e.g.: Range: bytes=0-9
-'If-Modified-Since' object modified after this time will return 200 and object meta, otherwise return 304 not modified
-'If-Unmodified-Since' object modified before this time will return 200 and object meta, otherwise throw PreconditionFailedError
-'If-Match' object etag equal this will return 200 and object meta, otherwise throw PreconditionFailedError
-'If-None-Match' object etag not equal this will return 200 and object meta, otherwise return 304 not modified
-Success will return the info contains response.
-
-object:
-
-[content] {Buffer} file content buffer if file parameter is null or ignore
-res {Object} response info, including
-status {Number} response status
-headers {Object} response headers
-size {Number} response size
-rt {Number} request total use time (ms)
-If object not exists, will throw NoSuchKeyError.
-
-example:
-
-Get an exists object and store it to the local file
-const filepath = '/home/ossdemo/demo.txt';
-await store.get('ossdemo/demo.txt', filepath);
-_ Store object to a writestream
-
-await store.get('ossdemo/demo.txt', somestream);
-Get an object content buffer
-const result = await store.get('ossdemo/demo.txt');
-console.log(Buffer.isBuffer(result.content));
-Get a processed image and store it to the local file
-const filepath = '/home/ossdemo/demo.png';
-await store.get('ossdemo/demo.png', filepath, { process: 'image/resize,w_200' });
-Get a not exists object
-const filepath = '/home/ossdemo/demo.txt';
-await store.get('ossdemo/not-exists-demo.txt', filepath);
-// will throw NoSuchKeyError
-Get a historic version object
-const filepath = '/home/ossdemo/demo.txt';
-const versionId = 'versionId string';
-await store.get('ossdemo/not-exists-demo.txt', filepath, {
-  versionId
-});
-If file is Object, it will be treated as options.
-const versionId = 'versionId string';
-await store.get('ossdemo/not-exists-demo.txt', { versionId });
-.getStream(name[, options])
-Get an object read stream.
-
-parameters:
-
-name {String} object name store on OSS
-[options] {Object} optional parameters
-[timeout] {Number} the operation timeout
-[process] {String} image process params, will send with x-oss-process
-[headers] {Object} extra headers
-'If-Modified-Since' object modified after this time will return 200 and object meta, otherwise return 304 not modified
-'If-Unmodified-Since' object modified before this time will return 200 and object meta, otherwise throw PreconditionFailedError
-'If-Match' object etag equal this will return 200 and object meta, otherwise throw PreconditionFailedError
-'If-None-Match' object etag not equal this will return 200 and object meta, otherwise return 304 not modified
-Success will return the stream instance and response info.
-
-object:
-
-stream {ReadStream} readable stream instance. If response status is not 200, stream will be null.
-res {Object} response info, including
-status {Number} response status
-headers {Object} response headers
-size {Number} response size
-rt {Number} request total use time (ms)
-If object not exists, will throw NoSuchKeyError.
-
-example:
-
-Get an exists object stream
-const result = await store.getStream('ossdemo/demo.txt');
-result.stream.pipe(fs.createWriteStream('some file.txt'));
-.delete(name[, options])
-Delete an object from the bucket.
-
-parameters:
-
-name {String} object name store on OSS
-[options] {Object} optional parameters
-[timeout] {Number} the operation timeout
-[versionId] {String} the version id of history object
-Success will return the info contains response.
-
-object:
-
-res {Object} response info, including
-status {Number} response status
-headers {Object} response headers
-size {Number} response size
-rt {Number} request total use time (ms)
-If delete object not exists, will also delete success.
-
-example:
-
-Delete an exists object
-await store.delete('ossdemo/someobject');
-Delete a not exists object
-await store.delete('ossdemo/some-not-exists-object');
-Delete a history object or deleteMarker
-const versionId = 'versionId';
-await store.delete('ossdemo/some-not-exists-object', { versionId });
-.copy(name, sourceName[, sourceBucket, options])
-Copy an object from sourceName to name.
-
-parameters:
-
-name {String} object name store on OSS
-sourceName {String} source object name
-[sourceBucket] {String} source Bucket. if doesn't exist，sourceBucket is same bucket.
-[options] {Object} optional parameters
-[versionId] {String} the version id of history object
-[timeout] {Number} the operation timeout
-[meta] {Object} user meta, will send with x-oss-meta- prefix string e.g.: { uid: 123, pid: 110 } If the meta set, will override the source object meta.
-[headers] {Object} extra headers
-'If-Match' do copy if source object etag equal this, otherwise throw PreconditionFailedError
-'If-None-Match' do copy if source object etag not equal this, otherwise throw PreconditionFailedError
-'If-Modified-Since' do copy if source object modified after this time, otherwise throw PreconditionFailedError
-'If-Unmodified-Since' do copy if source object modified before this time, otherwise throw PreconditionFailedError
-See more: CopyObject
-Success will return the copy result in data property.
-
-object:
-
-data {Object} copy result
-lastModified {String} object last modified GMT string
-etag {String} object etag contains ", e.g.: "5B3C1A2E053D763E1B002CC607C5A0FE"
-res {Object} response info, including
-status {Number} response status
-headers {Object} response headers
-size {Number} response size
-rt {Number} request total use time (ms)
-If source object not exists, will throw NoSuchKeyError.
-
-example:
-
-Copy same bucket object
-store.copy('newName', 'oldName').then(result => {
-  console.log(result);
-});
-Copy other bucket object
-store.copy('logo.png', 'logo.png', 'other-bucket').then(result => {
-  console.log(result);
-});
-Copy historic object
-const versionId = 'your verisonId';
-store.copy('logo.png', 'logo.png', 'other-bucket', { versionId }).then(result => {
-  console.log(result);
-});
-.putMeta(name, meta[, options])
-Set an exists object meta.
-
-parameters:
-
-name {String} object name store on OSS
-meta {Object} user meta, will send with x-oss-meta- prefix string e.g.: { uid: 123, pid: 110 } If meta: null, will clean up the exists meta
-[options] {Object} optional parameters
-[timeout] {Number} the operation timeout
-Success will return the putMeta result in data property.
-
-data {Object} copy result
-lastModified {String} object last modified GMT date, e.g.: 2015-02-19T08:39:44.000Z
-etag {String} object etag contains ", e.g.: "5B3C1A2E053D763E1B002CC607C5A0FE"
-res {Object} response info, including
-status {Number} response status
-headers {Object} response headers
-size {Number} response size
-rt {Number} request total use time (ms)
-If object not exists, will throw NoSuchKeyError.
-
-example:
-
-Update exists object meta
-const result = await store.putMeta('ossdemo.txt', {
-  uid: 1,
-  pid: 'p123'
-});
-console.log(result);
-Clean up object meta
-await store.putMeta('ossdemo.txt', null);
-.deleteMulti(names[, options])
-Delete multi objects in one request.
-
-parameters:
-
-names {Array} object names, max 1000 objects in once.
-key {String} object name
-[versionId] {String} the version id of history object or deleteMarker
-[options] {Object} optional parameters
-[quiet] {Boolean} quiet mode or verbose mode, default is false, verbose mode quiet mode: if all objects delete succes, return emtpy response. otherwise return delete error object results. verbose mode: return all object delete results.
-[timeout] {Number} the operation timeout
-Success will return delete success objects in deleted property.
-
-[deleted] {Array} deleted object or deleteMarker info list
-[Key] {String} object name
-[VersionId] {String} object versionId
-[DeleteMarker] {String} generate or delete marker
-[DeleteMarkerVersionId] {String} marker versionId
-res {Object} response info, including
-status {Number} response status
-headers {Object} response headers
-size {Number} response size
-rt {Number} request total use time (ms)
-example:
-
-Delete multi objects in quiet mode
-const result = await store.deleteMulti(['obj1', 'obj2', 'obj3'], {
-  quiet: true
-});
-Delete multi objects in verbose mode
-const result = await store.deleteMulti(['obj1', 'obj2', 'obj3']);
-Delete multi objects in multiversion
-const obj1 = {
-  key: 'key1',
-  versionId: 'versionId1'
-};
-const obj2 = {
-  key: 'key2',
-  versionId: 'versionId2'
-};
-const result = await store.deleteMulti([obj1, obj2]);
-.list(query[, options])
-List objects in the bucket.
-
-parameters:
-
-[query] {Object} query parameters, default is null
-[prefix] {String} search object using prefix key
-[marker] {String} search start from marker, including marker key
-[delimiter] {String} delimiter search scope e.g. / only search current dir, not including subdir
-[max-keys] {String|Number} max objects, default is 100, limit to 1000
-[options] {Object} optional parameters
-[timeout] {Number} the operation timeout
-Success will return objects list on objects properties.
-
-objects {Array} object meta info list Each ObjectMeta will contains blow properties:
-name {String} object name on oss
-lastModified {String} object last modified GMT date, e.g.: 2015-02-19T08:39:44.000Z
-etag {String} object etag contains ", e.g.: "5B3C1A2E053D763E1B002CC607C5A0FE"
-type {String} object type, e.g.: Normal
-size {Number} object size, e.g.: 344606
-storageClass {String} storage class type, e.g.: Standard
-owner {Object} object owner, including id and displayName
-restoreInfo {Object|undefined} The restoration status of the object
-ongoingRequest {Boolean} Whether the restoration is ongoing
-expireDate {Date|undefined} The time before which the restored object can be read
-prefixes {Array} prefix list
-isTruncated {Boolean} truncate or not
-nextMarker {String} next marker string
-res {Object} response info, including
-status {Number} response status
-headers {Object} response headers
-size {Number} response size
-rt {Number} request total use time (ms)
-example:
-
-List top 10 objects
-const result = await store.list();
-console.log(result.objects);
-List fun/ dir including subdirs objects
-const result = await store.list({
-  prefix: 'fun/'
-});
-console.log(result.objects);
-List fun/ dir objects, not including subdirs
-const result = await store.list({
-  prefix: 'fun/',
-  delimiter: '/'
-});
-console.log(result.objects);
-.listV2(query[, options])
-List objects in the bucket.(recommended)
-
-parameters:
-
-[query] {Object} query parameters, default is null
-[prefix] {String} search object using prefix key
-[continuation-token] (continuationToken) {String} search start from continuationToken, including continuationToken key
-[delimiter] {String} delimiter search scope e.g. / only search current dir, not including subdir
-[max-keys] {String|Number} max objects, default is 100, limit to 1000
-[start-after] {String} specifies the Start-after value from which to start the list. The names of objects are returned in alphabetical order.
-[fetch-owner] {Boolean} specifies whether to include the owner information in the response.
-[options] {Object} optional parameters
-[timeout] {Number} the operation timeout
-Success will return objects list on objects properties.
-
-objects {Array} object meta info list Each ObjectMeta will contains blow properties:
-
-name {String} object name on oss
-url {String} resource url
-lastModified {String} object last modified GMT date, e.g.: 2015-02-19T08:39:44.000Z
-etag {String} object etag contains ", e.g.: "5B3C1A2E053D763E1B002CC607C5A0FE"
-type {String} object type, e.g.: Normal
-size {Number} object size, e.g.: 344606
-storageClass {String} storage class type, e.g.: Standard
-owner {Object|null} object owner, including id and displayName
-restoreInfo {Object|undefined} The restoration status of the object
-ongoingRequest {Boolean} Whether the restoration is ongoing
-expireDate {Date|undefined} The time before which the restored object can be read
-prefixes {Array} prefix list
-
-isTruncated {Boolean} truncate or not
-
-nextContinuationToken {String} next continuation-token string
-
-keyCount {Number} The number of keys returned for this request. If Delimiter is specified, KeyCount is the sum of the elements in Key and CommonPrefixes.
-
-res {Object} response info, including
-
-status {Number} response status
-headers {Object} response headers
-size {Number} response size
-rt {Number} request total use time (ms)
-List top 10 objects
-
-const result = await store.listV2({
-  'max-keys': 10
-});
-console.log(result.objects);
-List fun/ dir including subdirs objects
-const result = await store.listV2({
-  prefix: 'fun/'
-});
-console.log(result.objects);
-List fun/ dir objects, not including subdirs
-const result = await store.listV2({
-  prefix: 'fun/',
-  delimiter: '/'
-});
-console.log(result.objects);
-List a/ dir objects, after a/b and not include a/b
-const result = await store.listV2({
-  delimiter: '/',
-  prefix: 'a/',
-  'start-after': 'a/b'
-});
-console.log(result.objects);
-.getBucketVersions(query[, options])
-List the version information of all objects in the bucket, including the delete marker (Delete Marker).
-
-parameters:
-
-[query] {Object} query parameters, default is null
-[prefix] {String} search object using prefix key
-[versionIdMarker] {String} set the result to return from the version ID marker of the key marker object and sort by the versions
-[keyMarker] {String} search start from keyMarker, including keyMarker key
-[encodingType] {String} specifies that the returned content is encoded, and specifies the type of encoding
-[delimiter] {String} delimiter search scope e.g. / only search current dir, not including subdir
-[maxKeys] {String|Number} max objects, default is 100, limit to 1000
-[options] {Object} optional parameters
-[timeout] {Number} the operation timeout
-Success will return objects list on objects properties.
-
-objects {Array} object meta info list Each ObjectMeta will contains blow properties:
-name {String} object name on oss
-lastModified {String} object last modified GMT date, e.g.: 2015-02-19T08:39:44.000Z
-etag {String} object etag contains ", e.g.: "5B3C1A2E053D763E1B002CC607C5A0FE"
-type {String} object type, e.g.: Normal
-size {Number} object size, e.g.: 344606
-isLatest {Boolean}
-versionId {String} object versionId
-storageClass {String} storage class type, e.g.: Standard
-owner {Object} object owner, including id and displayName
-restoreInfo {Object|undefined} The restoration status of the object
-ongoingRequest {Boolean} Whether the restoration is ongoing
-expireDate {Date|undefined} The time before which the restored object can be read
-deleteMarker {Array} object delete marker info list Each ObjectDeleteMarker
-name {String} object name on oss
-lastModified {String} object last modified GMT date, e.g.: 2015-02-19T08:39:44.000Z
-versionId {String} object versionId
-isTruncated {Boolean} truncate or not
-nextKeyMarker (nextMarker) {String} next marker string
-nextVersionIdMarker (NextVersionIdMarker) {String} next version ID marker string
-res {Object} response info, including
-status {Number} response status
-headers {Object} response headers
-size {Number} response size
-rt {Number} request total use time (ms)
-example:
-
-View all versions of objects and deleteMarker of bucket
-const result = await store.getBucketVersions();
-console.log(result.objects);
-console.log(result.deleteMarker);
-List from key-marker
-const result = await store.getBucketVersions({
-  keyMarker: 'keyMarker'
-});
-console.log(result.objects);
-List from the version-id-marker of key-marker
-const result = await store.getBucketVersions({
-  versionIdMarker: 'versionIdMarker',
-  keyMarker: 'keyMarker'
-});
-console.log(result.objects);
-console.log(result.deleteMarker);
-.signatureUrl(name[, options, strictObjectNameValidation])
-Create a signature url for download or upload object. When you put object with signatureUrl ,you need to pass Content-Type.Please look at the example.
-
-parameters:
-
-name {String} object name store on OSS
-[options] {Object} optional parameters
-[expires] {Number} after expires seconds, the url will become invalid, default is 1800
-[method] {String} the HTTP method, default is 'GET'
-[Content-Type] {String} set the request content type
-[process] {String} image process params, will send with x-oss-process e.g.: {process: 'image/resize,w_200'}
-[trafficLimit] {Number} traffic limit, range: 819200~838860800.
-[subResource] {Object} additional signature parameters in url.
-[response] {Object} set the response headers for download
-[content-type] {String} set the response content type
-[content-disposition] {String} set the response content disposition
-[cache-control] {String} set the response cache control
-See more: https://help.aliyun.com/document_detail/31980.html
-[callback] {Object} set the callback for the operation
-url {String} set the url for callback
-[host] {String} set the host for callback
-body {String} set the body for callback
-[contentType] {String} set the type for body
-[callbackSNI] {Boolean} Specifies whether OSS sends Server Name Indication (SNI) to the origin address specified by callbackUrl when a callback request is initiated from the client
-[customValue] {Object} set the custom value for callback,eg. {var1: value1,var2:value2}
-[strictObjectNameValidation] {boolean} the flag of verifying object name strictly, default is true
-Success will return signature url.
-
-example:
-
-Get signature url for object
-const url = store.signatureUrl('ossdemo.txt');
-console.log(url);
-// --------------------------------------------------
-const url = store.signatureUrl('ossdemo.txt', {
-  expires: 3600,
-  method: 'PUT'
-});
-console.log(url);
-
-//  put object with signatureUrl
-// -------------------------------------------------
-
-const url = store.signatureUrl('ossdemo.txt', {
-  expires: 3600,
-  method: 'PUT',
-  'Content-Type': 'text/plain; charset=UTF-8'
-});
-console.log(url);
-
-// --------------------------------------------------
-const url = store.signatureUrl(
-  'ossdemo.txt',
-  {
-    expires: 3600,
-    response: {
-      'content-type': 'text/custom',
-      'content-disposition': 'attachment'
-    }
-  },
-  false
-);
-console.log(url);
-
-// put operation
-Get a signature url for a processed image
-const url = store.signatureUrl('ossdemo.png', {
-  process: 'image/resize,w_200'
-});
-console.log(url);
-// --------------------------------------------------
-const url = store.signatureUrl('ossdemo.png', {
-  expires: 3600,
-  process: 'image/resize,w_200'
-});
-console.log(url);
-.asyncSignatureUrl(name[, options, strictObjectNameValidation])
-Basically the same as signatureUrl, if refreshSTSToken is configured asyncSignatureUrl will refresh stsToken
-
-parameters:
-
-name {String} object name store on OSS
-[options] {Object} optional parameters
-[expires] {Number} after expires seconds, the url will become invalid, default is 1800
-[method] {String} the HTTP method, default is 'GET'
-[Content-Type] {String} set the request content type
-[process] {String} image process params, will send with x-oss-process e.g.: {process: 'image/resize,w_200'}
-[trafficLimit] {Number} traffic limit, range: 819200~838860800.
-[subResource] {Object} additional signature parameters in url.
-[response] {Object} set the response headers for download
-[content-type] {String} set the response content type
-[content-disposition] {String} set the response content disposition
-[cache-control] {String} set the response cache control
-See more: https://help.aliyun.com/document_detail/31980.html
-[callback] {Object} set the callback for the operation
-url {String} set the url for callback
-[host] {String} set the host for callback
-body {String} set the body for callback
-[contentType] {String} set the type for body
-[callbackSNI] {Boolean} Specifies whether OSS sends Server Name Indication (SNI) to the origin address specified by callbackUrl when a callback request is initiated from the client
-[customValue] {Object} set the custom value for callback,eg. {var1: value1,var2:value2}
-[strictObjectNameValidation] {boolean} the flag of verifying object name strictly, default is true
-Success will return signature url.
-
-example:
-
-Get signature url for object
-const url = await store.asyncSignatureUrl('ossdemo.txt');
-console.log(url);
-// --------------------------------------------------
-const url = await store.asyncSignatureUrl('ossdemo.txt', {
-  expires: 3600,
-  method: 'PUT'
-});
-console.log(url);
-//  put object with signatureUrl
-// -------------------------------------------------
-const url = await store.asyncSignatureUrl('ossdemo.txt', {
-  expires: 3600,
-  method: 'PUT',
-  'Content-Type': 'text/plain; charset=UTF-8'
-});
-console.log(url);
-// --------------------------------------------------
-const url = await store.asyncSignatureUrl(
-  'ossdemo.txt',
-  {
-    expires: 3600,
-    response: {
-      'content-type': 'text/custom',
-      'content-disposition': 'attachment'
-    }
-  },
-  false
-);
-console.log(url);
-// put operation
-Get a signature url for a processed image
-const url = await store.asyncSignatureUrl('ossdemo.png', {
-  process: 'image/resize,w_200'
-});
-console.log(url);
-// --------------------------------------------------
-const url = await store.asyncSignatureUrl('ossdemo.png', {
-  expires: 3600,
-  process: 'image/resize,w_200'
-});
-console.log(url);
-.signatureUrlV4(method, expires[, request, objectName, additionalHeaders])
-Generate a signed URL for V4 of an OSS resource and share the URL to allow authorized third-party users to access the resource.
-
-parameters:
-
-method {string} the HTTP method
-expires {number} the signed URL will expire after the set number of seconds
-[request] {Object} optional request parameters
-[headers] {Object} headers of http requests, please make sure these request headers are set during the actual request
-[queries] {Object} queries of the signed URL, please ensure that if the query only has key, the value is set to null
-[objectName] {string} object name
-[additionalHeaders] {string[]} the keys of the request headers that need to be calculated into the V4 signature, please ensure that these additional headers are included in the request headers
-Success will return signature url.
-
-example:
-
-//  GetObject
-const getObjectUrl = await store.signatureUrlV4('GET', 60, undefined, 'your obejct name');
-console.log(getObjectUrl);
-// --------------------------------------------------
-const getObjectUrl = await store.signatureUrlV4(
-  'GET',
-  60,
-  {
-    headers: {
-      'Cache-Control': 'no-cache'
-    },
-    queries: {
-      versionId: 'version ID of your object'
-    }
-  },
-  'your obejct name',
-  ['Cache-Control']
-);
-console.log(getObjectUrl);
-
-// -------------------------------------------------
-//  PutObject
-const putObejctUrl = await store.signatureUrlV4('PUT', 60, undefined, 'your obejct name');
-console.log(putObejctUrl);
-// --------------------------------------------------
-const putObejctUrl = await store.signatureUrlV4(
-  'PUT',
-  60,
-  {
-    headers: {
-      'Content-Type': 'text/plain',
-      'Content-MD5': 'xxx',
-      'Content-Length': 1
-    }
-  },
-  'your obejct name',
-  ['Content-Length']
-);
-console.log(putObejctUrl);
-.putACL(name, acl[, options])
-Set object's ACL.
-
-parameters:
-
-name {String} object name
-acl {String} acl (private/public-read/public-read-write)
-[options] {Object} optional parameters
-[timeout] {Number} the operation timeout
-[versionId] {String} the version id of history object
-Success will return:
-
-res {Object} response info, including
-status {Number} response status
-headers {Object} response headers
-size {Number} response size
-rt {Number} request total use time (ms)
-example:
-
-Set an object's ACL
-await store.putACL('ossdemo.txt', 'public-read');
-Set an history object's ACL
-const versionId = 'object versionId';
-await store.putACL('ossdemo.txt', 'public-read', {
-  versionId
-});
-.getACL(name[, options])
-Get object's ACL.
-
-parameters:
-
-name {String} object name
-[options] {Object} optional parameters
-[timeout] {Number} the operation timeout
-[versionId] {String} the version id of history object
-Success will return:
-
-acl {String} acl settiongs string
-res {Object} response info, including
-status {Number} response status
-headers {Object} response headers
-size {Number} response size
-rt {Number} request total use time (ms)
-example:
-
-Get an object's ACL
-const result = await store.getACL('ossdemo.txt');
-console.log(result.acl);
-Get an history object's ACL
-const versionId = 'object versionId';
-const result = await store.getACL('ossdemo.txt', { versionId });
-console.log(result.acl);
-.restore(name[, options])
-Restore Object.
-
-parameters:
-
-name {String} object name
-[options] {Object} optional parameters
-[timeout] {Number} the operation timeout
-[versionId] {String} the version id of history object
-[type] {String} the default type is Archive
-[Days] {number} The duration within which the object remains in the restored state. The default value is 2.
-[JobParameters] {string} The container that stores the restoration priority. This parameter is valid only when you restore Cold Archive or Deep Cold Archive objects. The default value is Standard.
-Success will return:
-
-res {Object} response info, including
-status {Number} response status
-headers {Object} response headers
-size {Number} response size
-rt {Number} request total use time (ms)
-example:
-
-Restore an Archive object
-const result = await store.restore('ossdemo.txt');
-console.log(result.status);
-Restore a Cold Archive object
-const result = await store.restore('ossdemo.txt', { type: 'ColdArchive' });
-console.log(result.status);
-Restore a Cold Archive object with Days
-const result = await store.restore('ossdemo.txt', { type: 'ColdArchive', Days: 2 });
-console.log(result.status);
-Restore a Cold Archive object with Days and JobParameters
-const result = await store.restore('ossdemo.txt', { type: 'ColdArchive', Days: 2, JobParameters: 'Standard' });
-console.log(result.status);
-Restore a Deep Cold Archive object
-const result = await store.restore('ossdemo.txt', { type: 'DeepColdArchive' });
-console.log(result.status);
-Restore a Deep Cold Archive object with Days
-const result = await store.restore('ossdemo.txt', { type: 'DeepColdArchive', Days: 2 });
-console.log(result.status);
-Restore a Deep Cold Archive object with Days and JobParameters
-const result = await store.restore('ossdemo.txt', { type: 'DeepColdArchive', Days: 2, JobParameters: 'Standard' });
-console.log(result.status);
-Restore an history object
-const versionId = 'object versionId';
-const result = await store.restore('ossdemo.txt', { versionId });
-console.log(result.status);
-.putSymlink(name, targetName[, options])
-PutSymlink
-
-parameters:
-
-name {String} object name
-
-targetName {String} target object name
-
-[options] {Object} optional parameters
-
-[storageClass] {String} the storage type include (Standard,IA,Archive)
-[meta] {Object} user meta, will send with x-oss-meta- prefix string
-[headers] {Object} extra headers, detail see PutSymlink
-res {Object} response info, including
-
-status {Number} response status
-headers {Object} response headers
-size {Number} response size
-rt {Number} request total use time (ms)
-example:
-
-const options = {
-  storageClass: 'IA',
-  meta: {
-    uid: '1',
-    slus: 'test.html'
-  }
-};
-const result = await store.putSymlink('ossdemo.txt', 'targetName', options);
-console.log(result.res);
-putSymlink multiversion
-
-const options = {
-  storageClass: 'IA',
-  meta: {
-    uid: '1',
-    slus: 'test.html'
-  }
-};
-const result = await store.putSymlink('ossdemo.txt', 'targetName', options);
-console.log(result.res.headers['x-oss-version-id']);
-.getSymlink(name[, options])
-GetSymlink
-
-parameters:
-
-name {String} object name
-[options] {Object} optional parameters
-[versionId] {String} the version id of history object
-Success will return
-
-targetName {String} target object name
-res {Object} response info, including
-status {Number} response status
-headers {Object} response headers
-size {Number} response size
-rt {Number} request total use time (ms)
-example:
-
-const result = await store.getSymlink('ossdemo.txt');
-console.log(result.targetName);
-for history object
-
-const versionId = 'object versionId';
-const result = await store.getSymlink('ossdemo.txt', { versionId });
-console.log(result.targetName);
-.initMultipartUpload(name[, options])
-Before transmitting data in the Multipart Upload mode, you must call the Initiate Multipart Upload interface to notify the OSS to initiate a Multipart Upload event. The Initiate Multipart Upload interface returns a globally unique Upload ID created by the OSS server to identify this Multipart Upload event.
-
-parameters:
-
-name {String} object name
-[options] {Object} optional parameters
-[timeout] {Number} the operation timeout
-[mime] Mime file type e.g.: application/octet-stream
-[meta] {Object} user meta, will send with x-oss-meta- prefix string
-[headers] {Object} extra headers
-'Cache-Control' cache control for download, e.g.: Cache-Control: public, no-cache
-'Content-Disposition' object name for download, e.g.: Content-Disposition: somename
-'Content-Encoding' object content encoding for download, e.g.: Content-Encoding: gzip
-'Expires' expires time for download, an absolute date and time. e.g.: Tue, 08 Dec 2020 13:49:43 GMT
-[x-oss-server-side-encryption] Specify the server-side encryption algorithm used to upload each part of this object,Type: string, Valid value: AES256 x-oss-server-side-encryption: AES256
-if use in browser you should be set cors expose header x-oss-server-side-encryption
-See more: InitiateMultipartUpload
-Success will return:
-
-res {Object} response info, including
-status {Number} response status
-headers {Object} response headers
-[x-oss-server-side-encryption] if set request header x-oss-server-side-encryption, will return
-size {Number} response size
-rt {Number} request total use time (ms)
-bucket {String} bucket name
-name {String} object name store on OSS
-uploadId {String} upload id, use for uploadPart, completeMultipart
-example:
-
-const result = await store.initMultipartUpload('object');
-console.log(result);
-.uploadPart(name, uploadId, partNo, file, start, end[, options])
-After initiating a Multipart Upload event, you can upload data in parts based on the specified object name and Upload ID.
-
-parameters:
-
-name {String} object name
-uploadId {String} get by initMultipartUpload api
-partNo {Number} range is 1-10000, If this range is exceeded, OSS returns the InvalidArgument's error code.
-file {File|String} is File or FileName, the whole file
-Multipart Upload requires that the size of any Part other than the last Part is greater than 100KB.
-In Node you can use File or FileName, but in browser you only can use File.
-start {Number} part start bytes e.g: 102400
-end {Number} part end bytes e.g: 204800
-[options] {Object} optional parameters
-[timeout] {Number} the operation timeout
-Success will return:
-
-res {Object} response info, including
-status {Number} response status
-headers {Object} response headers
-size {Number} response size
-rt {Number} request total use time (ms)
-name {String} object name store on OSS
-etag {String} object etag contains ", e.g.: "5B3C1A2E053D763E1B002CC607C5A0FE"
-example:
-
-  const name = 'object';
-  const result = await store.initMultipartUpload(name);
-  const uploadId = result.uploadId;
-  const file; //the data you want to upload, is a File or FileName(only in node)
-  //if file part is 10
-  const partSize = 100 * 1024;
-  const fileSize = 10 * partSize;//you need to calculate
-  const dones = [];
-  for (let i = 1; i <= 10; i++) {
-    const start = partSize * (i -1);
-    const end = Math.min(start + partSize, fileSize);
-    const part = await store.uploadPart(name, uploadId, i, file, start, end);
-    dones.push({
-      number: i,
-      etag: part.etag
-    });
-    console.log(part);
-  }
-
-  //end need to call completeMultipartUpload api
-.uploadPartCopy(name, uploadId, partNo, range, sourceData[, options])
-Using Upload Part Copy, you can copy data from an existing object and upload a part of the data. When copying a file larger than 1 GB, you must use the Upload Part Copy method. If you want to copy a file smaller than 1 GB, see Copy Object.
-
-parameters:
-
-name {String} object name
-uploadId {String} get by initMultipartUpload api
-partNo {Number} range is 1-10000, If this range is exceeded, OSS returns the InvalidArgument's error code.
-range {String} Multipart Upload requires that the size of any Part other than the last Part is greater than 100KB, range value like 0-102400
-sourceData {Object}
-sourceKey {String} the source object name
-sourceBucketName {String} the source bucket name
-[options] {Object} optional parameters
-[timeout] {Number} the operation timeout
-[versionId] {String} the version id of history object
-[headers] {Object} The following request header is used for the source objects specified by x-oss-copy-source.
-[x-oss-copy-source-if-match] default none
-If the ETAG value of the source object is equal to the ETAG value provided by the user, the system performs the Copy Object operation; otherwise, the system returns the 412 Precondition Failed message.
-[x-oss-copy-source-if-none-match] default none
-If the source object has not been modified since the time specified by the user, the system performs the Copy Object operation; otherwise, the system returns the 412 Precondition Failed message.
-[x-oss-copy-source-if-unmodified-since] default none
-If the time specified by the received parameter is the same as or later than the modification time of the file, the system transfers the file normally, and returns 200 OK; otherwise, the system returns 412 Precondition Failed.
-[x-oss-copy-source-if-modified-since] default none
-If the source object has been modified since the time specified by the user, the system performs the Copy Object operation; otherwise, the system returns the 412 Precondition Failed message.
-Success will return:
-
-res {Object} response info, including
-status {Number} response status
-headers {Object} response headers
-size {Number} response size
-rt {Number} request total use time (ms)
-name {String} object name store on OSS
-etag {String} object etag contains ", e.g.: "5B3C1A2E053D763E1B002CC607C5A0FE"
-example:
-
-const name = 'object';
-const result = await store.initMultipartUpload(name);
-
-const partSize = 100 * 1024; //100kb
-//if file part is 10
-for (let i = 1; i <= 10; i++) {
-  const start = partSize * (i - 1);
-  const end = Math.min(start + partSize, fileSize);
-  const range = start + '-' + (end - 1);
-  const part = await store.uploadPartCopy(name, result.uploadId, i, range, {
-    sourceKey: 'sourceKey',
-    sourceBucketName: 'sourceBucketName'
-  });
-  console.log(part);
-}
-
-//end need complete api
-use history object to uploadPartCopy
-const versionId = 'object versionId';
-const name = 'object';
-const result = await store.initMultipartUpload(name);
-const partSize = 100 * 1024; //100kb
-//if file part is 10
-for (let i = 1; i <= 10; i++) {
-  const start = partSize * (i - 1);
-  const end = Math.min(start + partSize, fileSize);
-  const range = start + '-' + (end - 1);
-  const part = await store.uploadPartCopy(
-    name,
-    result.uploadId,
-    i,
-    range,
-    {
-      sourceKey: 'sourceKey',
-      sourceBucketName: 'sourceBucketName'
-    },
-    {
-      versionId
-    }
-  );
-  console.log(part);
-}
-
-//end need complete api
-.completeMultipartUpload(name, uploadId, parts[, options])
-After uploading all data parts, you must call the Complete Multipart Upload API to complete Multipart Upload for the entire file.
-
-parameters:
-
-name {String} object name
-uploadId {String} get by initMultipartUpload api
-parts {Array} more part {Object} from uploadPartCopy, , each in the structure:
-number {Number} partNo
-etag {String} object etag contains ", e.g.: "5B3C1A2E053D763E1B002CC607C5A0FE"
-[options] {Object} optional parameters
-[timeout] {Number} the operation timeout
-[callback] {Object} The callback parameter is composed of a JSON string encoded in Base64,detail see
-url {String} After a file is uploaded successfully, the OSS sends a callback request to this URL.
-[host] {String} The host header value for initiating callback requests.
-body {String} The value of the request body when a callback is initiated, for example, key=${key}&etag=${etag}&my_var=${x:my_var}.
-[contentType] {String} The Content-Type of the callback requests initiatiated, It supports application/x-www-form-urlencoded and application/json, and the former is the default value.
-[callbackSNI] {Boolean} Specifies whether OSS sends Server Name Indication (SNI) to the origin address specified by callbackUrl when a callback request is initiated from the client.
-[customValue] {Object} Custom parameters are a map of key-values
-e.g.:
-var customValue = { var1: 'value1', var2: 'value2' };
-[headers] {Object} extra headers, detail see CompleteMultipartUpload
-Success will return:
-
-res {Object} response info, including
-status {Number} response status
-headers {Object} response headers
-size {Number} response size
-rt {Number} request total use time (ms)
-bucket {String} bucket name
-name {String} object name store on OSS
-etag {String} object etag contains ", e.g.: "5B3C1A2E053D763E1B002CC607C5A0FE"
-data {Object} callback server response data , sdk use JSON.parse() return
-example:
-
-  //init multipart
-  const name = 'object';
-  const result = await store.initMultipartUpload(name);
-
-  //upload part
-  const file; //the data you want to upload, this example size is 10 * 100 * 1024
-  const fileSize;//you need to calculate
-  const partSize = 100 * 1024;//100kb
-  const done = [];
-  //if file part is 10
-  for (let i = 1; i <= 10; i++) {
-    const start = partSize * (i -1);
-    const end = Math.min(start + partSize, fileSize);
-    const data = file.slice(start, end);
-    const part = store.uploadPart(name, result.uploadId, i, data, 0, data.length);
-    console.log(part);
-    done.push({
-          number: i,
-          etag: part.res.headers.etag
-        });
-  }
-
-  //complete
-  const completeData = await store.completeMultipartUpload(name, result.uploadId, done);
-  console.log(completeData);
-.multipartUpload(name, file[, options])
-Upload file with OSS multipart.
-this function contains initMultipartUpload, uploadPart, completeMultipartUpload. When you use multipartUpload api，if you encounter problems with ConnectionTimeoutError, you should handle ConnectionTimeoutError in your business code. How to resolve ConnectionTimeoutError, you can decrease partSize size 、 Increase timeout 、Retry request , or give tips in your business code;
-
-parameters:
-
-name {String} object name
-file {String|File(only support Browser)|Blob(only support Browser)|Buffer} file path or HTML5 Web File or web Blob or content buffer
-[options] {Object} optional args
-[parallel] {Number} the number of parts to be uploaded in parallel
-[partSize] {Number} the suggested size for each part, default 1024 * 1024(1MB), minimum 100 * 1024(100KB)
-[progress] {Function} function | async | Promise, the progress callback called after each successful upload of one part, it will be given three parameters: (percentage {Number}, checkpoint {Object}, res {Object})
-[checkpoint] {Object} the checkpoint to resume upload, if this is provided, it will continue the upload from where interrupted, otherwise a new multipart upload will be created.
-file {File} The file object selected by the user, if the browser is restarted, it needs the user to manually trigger the settings
-name {String} object key
-fileSize {Number} file size
-partSize {Number} part size
-uploadId {String} upload id
-doneParts {Array} An array of pieces that have been completed, including the object structure as follows
-number {Number} part number
-etag {String} part etag
-[meta] {Object} user meta, will send with x-oss-meta- prefix string
-[mime] {String} custom mime , will send with Content-Type entity header
-[callback] {Object} The callback parameter is composed of a JSON string encoded in Base64,detail see
-url {String} After a file is uploaded successfully, the OSS sends a callback request to this URL.
-[host] {String} The host header value for initiating callback requests.
-body {String} The value of the request body when a callback is initiated, for example, key=${key}&etag=${etag}&my_var=${x:my_var}.
-[contentType] {String} The Content-Type of the callback requests initiatiated, It supports application/x-www-form-urlencoded and application/json, and the former is the default value.
-[callbackSNI] {Boolean} Specifies whether OSS sends Server Name Indication (SNI) to the origin address specified by callbackUrl when a callback request is initiated from the client.
-[customValue] {Object} Custom parameters are a map of key-values
-e.g.:
-var customValue = { var1: 'value1', var2: 'value2' };
-[headers] {Object} extra headers, detail see RFC 2616
-'Cache-Control' cache control for download, e.g.: Cache-Control: public, no-cache
-'Content-Disposition' object name for download, e.g.: Content-Disposition: somename
-'Content-Encoding' object content encoding for download, e.g.: Content-Encoding: gzip
-'Expires' expires time for download, an absolute date and time. e.g.: Tue, 08 Dec 2020 13:49:43 GMT
-NOTE: Some headers are disabled in browser
-[timeout] {Number} Milliseconds before a request is considered to be timed out
-[disabledMD5] {Boolean} default true, it just work in Browser. if false,it means that MD5 is automatically calculated for uploaded files. NOTE: Synchronous computing tasks will block the main process
-Success will return:
-
-res {Object} response info, including
-status {Number} response status
-headers {Object} response headers
-size {Number} response size
-rt {Number} request total use time (ms)
-bucket {String} bucket name
-name name {String} object name store on OSS
-etag {String} object etag contains ", e.g.: "5B3C1A2E053D763E1B002CC607C5A0FE"
-data {Object} callback server response data, sdk use JSON.parse() return
-example:
-
-Upload using multipart
-const result = await store.multipartUpload('object', '/tmp/file');
-let savedCpt;
-console.log(result);
-
-const result = await store.multipartUpload('object', '/tmp/file', {
-  parallel: 4,
-  partSize: 1024 * 1024,
-  progress: function (p, cpt, res) {
-    console.log(p);
-    savedCpt = cpt;
-    console.log(cpt);
-    console.log(res.headers['x-oss-request-id']);
-  }
-});
-
-const result = await store.multipartUpload('object', '/tmp/file', {
-  checkpoint: savedCpt,
-  progress: function (p, cpt, res) {
-    //progress is generator
-    console.log(p);
-    console.log(cpt);
-    console.log(res.headers['x-oss-request-id']);
-  }
-});
-multipartUpload progress example
-//async function
-async function asyncProgress(p, cpt, res) {
-  console.log(p);
-  console.log(cpt);
-  console.log(res.headers['x-oss-request-id']);
-}
-
-const result1 = await store.multipartUpload('object', '/tmp/file', {
-  progress: asyncProgress
-});
-
-//function
-function progress(p, cpt, res) {
-  console.log(p);
-  console.log(cpt);
-  console.log(res.headers['x-oss-request-id']);
-}
-
-const result2 = await store.multipartUpload('object', '/tmp/file', {
-  progress: progress
-});
-multipartUpload with abort
-tips: abort multipartUpload support on node and browser
-
-//start upload
-let abortCheckpoint;
-store.multipartUpload('object', '/tmp/file', {
-  progress: function (p, cpt, res) {
-    abortCheckpoint = cpt;
-  }
-}).then(res => {
-  // do something
-}).catch(err => {
-   //if abort will catch abort event
-  if (err.name === 'abort') {
-    // handle abort
-    console.log('error: ', err.message)
-  }
-});
-
-// abort
-store.abortMultipartUpload(abortCheckpoint.name, abortCheckpoint.uploadId);
-multipartUpload with cancel
-tips: cancel multipartUpload support on node and browser
-
-//start upload
-try {
-  const result = await store.multipartUpload('object', '/tmp/file', {
-    checkpoint: savedCpt,
-    progress: function (p, cpt, res) {
-      console.log(p);
-      console.log(cpt);
-      console.log(res.headers['x-oss-request-id']);
-    }
-  });
-} catch (err) {
-  //if cancel will catch cancel event
-  if (store.isCancel()) {
-    //do something
-  }
-}
-
-//the other event to cancel, for example: click event
-//to cancel upload must use the same client instance
-store.cancel();
-multipartUpload with capture ConnectionTimeoutError error
-//start upload
-try {
-  const result = await store.multipartUpload('object', '/tmp/file', {
-    checkpoint: savedCpt,
-    progress: function (p, cpt, res) {
-      console.log(p);
-      console.log(cpt);
-      console.log(res.headers['x-oss-request-id']);
-    }
-  });
-} catch (err) {
-  if (err.code === 'ConnectionTimeoutError') {
-    console.log('Woops,Woops ,timeout error!!!');
-    // do ConnectionTimeoutError operation
-  }
-}
-.multipartUploadCopy(name, sourceData[, options])
-Copy file with OSS multipart.
-this function contains head, initMultipartUpload, uploadPartCopy, completeMultipartUpload.
-When copying a file larger than 1 GB, you should use the Upload Part Copy method. If you want to copy a file smaller than 1 GB, see Copy Object.
-
-parameters:
-
-name {String} object name
-file {String|File} file path or HTML5 Web File
-[options] {Object} optional args
-[timeout] {Number} Milliseconds before a request is considered to be timed out
-[parallel] {Number} the number of parts to be uploaded in parallel
-[partSize] {Number} the suggested size for each part, defalut 1024 * 1024(1MB), minimum 100 * 1024(100KB)
-[versionId] {String} the version id of history object
-[progress] {Function} function | async | Promise, the progress callback called after each successful upload of one part, it will be given three parameters: (percentage {Number}, checkpoint {Object}, res {Object})
-[checkpoint] {Object} the checkpoint to resume upload, if this is provided, it will continue the upload from where interrupted, otherwise a new multipart upload will be created.
-[headers] {Object} extra headers, detail see RFC 2616
-'Cache-Control' cache control for download, e.g.: Cache-Control: public, no-cache
-'Content-Disposition' object name for download, e.g.: Content-Disposition: somename
-'Content-Encoding' object content encoding for download, e.g.: Content-Encoding: gzip
-'Expires' expires time for download, an absolute date and time. e.g.: Tue, 08 Dec 2020 13:49:43 GMT
-NOTE: Some headers are disabled in browser
-[copyheaders] {Object} only uploadPartCopy api used, detail see
-[x-oss-copy-source-if-match] only uploadPartCopy api used, default none
-If the ETAG value of the source object is equal to the ETAG value provided by the user, the system performs the Copy Object operation; otherwise, the system returns the 412 Precondition Failed message.
-[x-oss-copy-source-if-none-match] only uploadPartCopy api used, default none
-If the source object has not been modified since the time specified by the user, the system performs the Copy Object operation; otherwise, the system returns the 412 Precondition Failed message.
-[x-oss-copy-source-if-unmodified-since] only uploadPartCopy api used, default none
-If the time specified by the received parameter is the same as or later than the modification time of the file, the system transfers the file normally, and returns 200 OK; otherwise, the system returns 412 Precondition Failed.
-[x-oss-copy-source-if-modified-since] only uploadPartCopy api used, default none
-If the source object has been modified since the time specified by the user, the system performs the Copy Object operation; otherwise, the system returns the 412 Precondition Failed message.
-Success will return:
-
-res {Object} response info, including
-status {Number} response status
-headers {Object} response headers
-size {Number} response size
-rt {Number} request total use time (ms)
-bucket {String} bucket name
-name name {String} object name store on OSS
-etag {String} object etag contains ", e.g.: "5B3C1A2E053D763E1B002CC607C5A0FE"
-example:
-
-Copy using multipart
-const result = await store.multipartUploadCopy('object', {
-  sourceKey: 'sourceKey',
-  sourceBucketName: 'sourceBucketName'
-});
-let savedCpt;
-console.log(result);
-
-const result = await store.multipartUploadCopy(
-  'object',
-  {
-    sourceKey: 'sourceKey',
-    sourceBucketName: 'sourceBucketName'
-  },
-  {
-    parallel: 4,
-    partSize: 1024 * 1024,
-    progress: function (p, cpt, res) {
-      console.log(p);
-      savedCpt = cpt;
-      console.log(cpt);
-      console.log(res.headers['x-oss-request-id']);
-    }
-  }
-);
-
-console.log(result);
-
-const result = await store.multipartUploadCopy(
-  'object',
-  {
-    sourceKey: 'sourceKey',
-    sourceBucketName: 'sourceBucketName'
-  },
-  {
-    checkpoint: savedCpt,
-    progress: function (p, cpt, res) {
-      console.log(p);
-      console.log(cpt);
-      console.log(res.headers['x-oss-request-id']);
-    }
-  }
-);
-
-console.log(result);
-multipartUploadCopy with abort
-// start upload
-let abortCheckpoint;
-store.multipartUploadCopy('object', {
-    sourceKey: 'sourceKey',
-    sourceBucketName: 'sourceBucketName'
-  }, {
-  progress: function (p, cpt, res) {
-    abortCheckpoint = cpt;
-  }
-}).then(res => {
-  // do something
-}).catch(err => {
-   //if abort will catch abort event
-  if (err.name === 'abort') {
-    // handle abort
-    console.log('error: ', err.message)
-  }
-});
-
-// the other event to abort, for example: click event
-// to abort upload must use the same client instance
-store.abortMultipartUpload(abortCheckpoint.name, abortCheckpoint.uploadId);
-multipartUploadCopy with cancel
-//start upload
-try {
-  const result = await store.multipartUploadCopy(
-    'object',
-    {
-      sourceKey: 'sourceKey',
-      sourceBucketName: 'sourceBucketName'
-    },
-    {
-      checkpoint: savedCpt,
-      progress: function (p, cpt, res) {
-        console.log(p);
-        console.log(cpt);
-        console.log(res.headers['x-oss-request-id']);
-      }
-    }
-  );
-} catch (err) {
-  //if cancel will catch cancel event
-  if (store.isCancel()) {
-    //do something
-  }
-}
-
-//the other event to cancel, for example: click event
-//to cancel upload must use the same client instance
-store.cancel();
-multipartUploadCopy with versionId
-const versionId = 'object versionId';
-//start upload
-const result = await store.multipartUploadCopy(
-  'object',
-  {
-    sourceKey: 'sourceKey',
-    sourceBucketName: 'sourceBucketName'
-  },
-  {
-    checkpoint: savedCpt,
-    progress: function (p, cpt, res) {
-      console.log(p);
-      console.log(cpt);
-      console.log(res.headers['x-oss-request-id']);
-    },
-    versionId
-  }
-);
-.listParts(name, uploadId[, query, options])
-The ListParts command can be used to list all successfully uploaded parts mapped to a specific upload ID, i.e.: those not completed and not aborted.
-
-parameters:
-
-name {String} object key
-uploadId {String} upload ID from initMultipartUpload api
-[query] {Object} query parameters
-[max-parts] {Number} The maximum part number in the response of the OSS. default value: 1000.
-[part-number-marker] {Number} Starting position of a specific list. A part is listed only when the part number is greater than the value of this parameter.
-[encoding-type] {String} Specify the encoding of the returned content and the encoding type. Optional value: url
-[options] {Object} optional args
-[timeout] {Number} the operation timeout
-Success will return:
-
-res {Object} response info, including
-status {Number} response status
-headers {Object} response headers
-size {Number} response size
-rt {Number} request total use time (ms)
-uploadId {String} upload ID
-bucket {String} Specify the bucket name.
-name {String} object name
-PartNumberMarker {Number} Starting position of the part numbers in the listing result.
-nextPartNumberMarker {Number} If not all results are returned this time, the response request includes the NextPartNumberMarker element to indicate the value of PartNumberMarker in the next request.
-maxParts {Number} upload ID
-isTruncated {Boolean} Whether the returned result list for List Parts is truncated. The “true” indicates that not all results are returned; “false” indicates that all results are returned.
-parts {Array} The container that saves part information, each in the structure:
-PartNumber {Number} Part number.
-LastModified {Date} Time when a part is uploaded.
-ETag {String} ETag value in the content of the uploaded part.
-Size {Number} Size of the uploaded part.
-example:
-
-List uploaded part
-const result = await store.listParts('objcet', 'uploadId', {
-  'max-parts': 1000
-});
-console.log(result);
-.listUploads(query[, options])
-List on-going multipart uploads, i.e.: those not completed and not aborted.
-
-parameters:
-
-query {Object} query parameters
-[prefix] {String} the object key prefix
-[max-uploads] {Number} the max uploads to return
-[key-marker] {String} the object key marker, if upload-id-marker is not provided, return uploads with key > marker, otherwise return uploads with key >= marker && uploadId > id-marker
-[upload-id-marker] {String} the upload id marker, must be used WITH key-marker
-[options] {Object} optional args
-[timeout] {Number} the operation timeout
-example:
-
-List on-going multipart uploads
-const result = await store.listUploads({
-  'max-uploads': 100,
-  'key-marker': 'my-object',
-  'upload-id-marker': 'upload-id'
-});
-console.log(result);
-.abortMultipartUpload(name, uploadId[, options])
-Abort a multipart upload for object.
-
-parameters:
-
-name {String} the object name
-uploadId {String} the upload id
-[options] {Object} optional args
-[timeout] {Number} the operation timeout
-example:
-
-Abort a multipart upload
-const result = await store.abortMultipartUpload('object', 'upload-id');
-console.log(result);
-.calculatePostSignature(policy)
-get postObject params
-
-parameters:
-
-policy {JSON or Object} policy must contain expiration and conditions.
-Success will return postObject Api params.
-
-Object:
-
-OSSAccessKeyId {String}
-Signature {String}
-policy {Object} response info
-.signPostObjectPolicyV4(policy, date)
-Get a V4 signature of the PostObject request.
-
-parameters:
-
-policy {string | Object} The policy form field in a PostObject request is used to specify the expiration time and conditions of the PostObject request that you initiate to upload an object by using an HTML form. The value of the policy form field is a JSON string or an object.
-date {Date} The time when the request was initiated.
-Success will return a V4 signature of the PostObject request.
-
-example:
-
-const axios = require('axios');
-const dateFormat = require('dateformat');
-const FormData = require('form-data');
-const { getCredential } = require('ali-oss/lib/common/signUtils');
-const { getStandardRegion } = require('ali-oss/lib/common/utils/getStandardRegion');
-const { policy2Str } = require('ali-oss/lib/common/utils/policy2Str');
-const OSS = require('ali-oss');
-
-const client = new OSS({
-  accessKeyId: 'yourAccessKeyId',
-  accessKeySecret: 'yourAccessKeySecret',
-  stsToken: 'yourSecurityToken',
-  bucket: 'yourBucket',
-  region: 'oss-cn-hangzhou'
-});
-const name = 'yourObjectName';
-const formData = new FormData();
-formData.append('key', name);
-formData.append('Content-Type', 'yourObjectContentType');
-// your object cache control
-formData.append('Cache-Control', 'max-age=30');
-const url = client.generateObjectUrl(name).replace(name, '');
-const date = new Date();
-// The expiration parameter specifies the expiration time of the request.
-const expirationDate = new Date(date);
-expirationDate.setMinutes(date.getMinutes() + 1);
-// The time must follow the ISO 8601 standard
-const formattedDate = dateFormat(date, "UTC:yyyymmdd'T'HHMMss'Z'");
-const credential = getCredential(formattedDate.split('T')[0], getStandardRegion(client.options.region), client.options.accessKeyId);
-formData.append('x-oss-date', formattedDate);
-formData.append('x-oss-credential', credential);
-formData.append('x-oss-signature-version', 'OSS4-HMAC-SHA256');
-const policy = {
-  expiration: expirationDate.toISOString(),
-  conditions: [
-    { bucket: client.options.bucket },
-    {'x-oss-credential': credential},
-    {'x-oss-date': formattedDate},
-    {'x-oss-signature-version': 'OSS4-HMAC-SHA256'},
-    ['content-length-range', 1, 10],
-    ['eq', '$success_action_status', '200'],
-    ['starts-with', '$key', 'yourObjectName'],
-    ['in', '$content-type', ['image/jpg', 'text/plain']],
-    ['not-in', '$cache-control', ['no-cache']]
-  ]
-};
-
-if (client.options.stsToken) {
-  policy.conditions.push({'x-oss-security-token': client.options.stsToken});
-  formData.append('x-oss-security-token', client.options.stsToken);
-}
-
-const signature = client.signPostObjectPolicyV4(policy, date);
-formData.append('policy', Buffer.from(policy2Str(policy), 'utf8').toString('base64'));
-formData.append('x-oss-signature', signature);
-formData.append('success_action_status', '200');
-formData.append('file', 'yourFileContent');
-
-axios.post(url, formData, {
-  headers: {
-    'Content-Type': 'multipart/form-data'
-  }
-}).then((result) => {
-  console.log(result.status);
-}).catch((e) => {
-  console.log(e);
-});
-.getObjectTagging(name[, options])
-Obtains the tags of an object.
-
-parameters:
-
-name {String} the object name
-[options] {Object} optional args
-[versionId] {String} the version id of history object
-Success will return the channel information.
-
-object:
-
-tag {Object} the tag of object
-res {Object} response info
-.putObjectTagging(name, tag[, options])
-Configures or updates the tags of an object.
-
-parameters:
-
-name {String} the object name
-tag {Object} tag, eg. {var1: value1,var2:value2}
-[options] {Object} optional args
-[versionId] {String} the version id of history object
-Success will return the channel information.
-
-object:
-
-status {Number} response status
-res {Object} response info
-.deleteObjectTagging(name[, options])
-Deletes the tag of a specified object.
-
-parameters:
-
-name {String} the object name
-tag {Object} tag, eg. {var1: value1,var2:value2}
-[options] {Object} optional args
-[versionId] {String} the version id of history object
-Success will return the channel information.
-
-object:
-
-status {Number} response status
-res {Object} response info
-.processObjectSave(sourceObject, targetObject, process[, targetBucket])
-Persistency indicates that images are asynchronously stored in the specified Bucket
-
-parameters:
-
-sourceObject {String} source object name
-targetObject {String} target object name
-process {String} process string
-[targetBucket] {String} target bucket
-Success will return the channel information.
-
-object:
-
-status {Number} response status
-res {Object} response info
-const sourceObject = 'a.png';
-const targetObject = 'b.png';
-const process = 'image/watermark,text_aGVsbG8g5Zu+54mH5pyN5Yqh77yB,color_ff6a00';
-
-await this.store.processObjectSave(sourceObject, targetObject, process);
-RTMP Operations
-All operations function is [async], except getRtmpUrl.
-
-async function format: async functionName(...).
-
-.putChannel(id, conf[, options])
-Create a live channel.
-
-parameters:
-
-id {String} the channel id
-conf {Object} the channel config
-[Description] {String} the channel description
-[Status] {String} the channel status: 'enabled' or 'disabled'
-[Target] {Object}
-[Type] {String} the data type for the channel, only 'HLS' is supported now
-[FragDuration] {Number} duration of a 'ts' segment
-[FragCount] {Number} the number of 'ts' segments in a 'm3u8'
-[PlaylistName] {String} the 'm3u8' name
-[options] {Object} optional parameters
-[timeout] {Number} the operation timeout
-Success will return the channel information.
-
-object:
-
-publishUrls {Array} the publish urls
-playUrls {Array} the play urls
-res {Object} response info
-example:
-
-Create a live channel
-const cid = 'my-channel';
-const conf = {
-  Description: 'this is channel 1',
-  Status: 'enabled',
-  Target: {
-    Type: 'HLS',
-    FragDuration: '10',
-    FragCount: '5',
-    PlaylistName: 'playlist.m3u8'
-  }
-};
-
-const r = await this.store.putChannel(cid, conf);
-console.log(r);
-.getChannel(id[, options])
-Get live channel info.
-
-parameters:
-
-id {String} the channel id
-[options] {Object} optional parameters
-[timeout] {Number} the operation timeout
-Success will return the channel information.
-
-object:
-
-data {Object} channel info, same as conf in .putChannel
-res {Object} response info
-example:
-
-Get live channel info
-const cid = 'my-channel';
-
-const r = await this.store.getChannel(cid);
-console.log(r);
-.deleteChannel(id[, options])
-Delete a live channel.
-
-parameters:
-
-id {String} the channel id
-[options] {Object} optional parameters
-[timeout] {Number} the operation timeout
-Success will return the response infomation.
-
-object:
-
-res {Object} response info
-example:
-
-Delete a live channel
-const cid = 'my-channel';
-
-const r = await this.store.deleteChannel(cid);
-console.log(r);
-.putChannelStatus(id, status[, options])
-Change the live channel status.
-
-parameters:
-
-id {String} the channel id
-status {String} the status: 'enabled' or 'disabled'
-[options] {Object} optional parameters
-[timeout] {Number} the operation timeout
-Success will return the response information.
-
-object:
-
-res {Object} response info
-example:
-
-Disable a live channel
-const cid = 'my-channel';
-
-const r = await this.store.putChannelStatus(cid, 'disabled');
-console.log(r);
-.getChannelStatus(id[, options])
-Get the live channel status.
-
-parameters:
-
-id {String} the channel id
-[options] {Object} optional parameters
-[timeout] {Number} the operation timeout
-Success will return the channel status information.
-
-object:
-
-data {Object}
-Status {String} the channel status: 'Live' or 'Idle'
-[ConnectedTime] {String} the connected time of rtmp pushing
-[RemoteAddr] {String} the remote addr of rtmp pushing
-[Video] {Object} the video parameters (Width/Height/FrameRate/Bandwidth/Codec)
-[Audio] {Object} the audio parameters (Bandwidth/SampleRate/Codec)
-res {Object} response info
-example:
-
-Get a live channel status
-const cid = 'my-channel';
-
-const r = await this.store.getChannelStatus(cid);
-console.log(r);
-
-// { Status: 'Live',
-//   ConnectedTime: '2016-04-12T11:51:03.000Z',
-//   RemoteAddr: '42.120.74.98:53931',
-//   Video:
-//   { Width: '672',
-//     Height: '378',
-//     FrameRate: '29',
-//     Bandwidth: '60951',
-//     Codec: 'H264' },
-//   Audio: { Bandwidth: '5959', SampleRate: '22050', Codec: 'AAC' }
-// }
-.listChannels(query[, options])
-List channels.
-
-parameters:
-
-query {Object} parameters for list
-prefix {String}: the channel id prefix (returns channels with this prefix)
-marker {String}: the channle id marker (returns channels after this id)
-max-keys {Number}: max number of channels to return
-[options] {Object} optional parameters
-[timeout] {Number} the operation timeout
-Success will return the channel list.
-
-object:
-
-channels {Array} the channels, each in the structure:
-Name {String} the channel id
-Description {String} the channel description
-Status {String} the channel status
-LastModified {String} the last modification time of the channel
-PublishUrls {Array} the publish urls for the channel
-PlayUrls {Array} the play urls for the channel
-nextMarker: result.data.NextMarker || null,
-isTruncated: result.data.IsTruncated === 'true'
-res {Object} response info
-example:
-
-List live channels
-const r = await this.store.listChannels({
-  prefix: 'my-channel',
-  'max-keys': 3
-});
-console.log(r);
-.getChannelHistory(id[, options])
-Get the live channel history.
-
-parameters:
-
-id {String} the channel id
-[options] {Object} optional parameters
-[timeout] {Number} the operation timeout
-Success will return the history information.
-
-object:
-
-records {Object} the pushing records, each in the structure:
-StartTime {String} the start time
-EndTime {String} the end time
-RemoteAddr {String} the remote addr
-res {Object} response info
-example:
-
-Get the live channel history
-const cid = 'my-channel';
-
-const r = await this.store.getChannelHistory(cid);
-console.log(r);
-.createVod(id, name, time[, options])
-Create a VOD playlist for the channel.
-
-parameters:
-
-id {String} the channel id
-name {String} the playlist name
-time {Object} the duration time
-startTime {Number} the start time in epoch seconds
-endTime {Number} the end time in epoch seconds
-[options] {Object} optional parameters
-[timeout] {Number} the operation timeout
-Success will return the response information.
-
-object:
-
-res {Object} response info
-example:
-
-Create a vod playlist of a live channel
-const cid = 'my-channel';
-
-const r = await this.store.createVod(cid, 're-play', {
-  startTime: 1460464870,
-  endTime: 1460465877
-});
-console.log(r);
-.getRtmpUrl(channelId[, options])
-Get signatured rtmp url for publishing.
-
-parameters:
-
-channelId {String} the channel id
-[options] {Object} optional parameters
-[expires] {Number} the expire time in seconds of the url
-[params] {Object} the additional paramters for url, e.g.: {playlistName: 'play.m3u8'}
-[timeout] {Number} the operation timeout
-Success will return the rtmp url.
-
-example:
-
-Get a rtmp url.
-const cid = 'my-channel';
-
-const url = this.store.getRtmpUrl(this.cid, {
-  params: {
-    playlistName: 'play.m3u8'
-  },
-  expires: 3600
-});
-console.log(url);
-// rtmp://ossliveshow.oss-cn-hangzhou.aliyuncs.com/live/tl-channel?OSSAccessKeyId=T0cqQWBk2ThfRS6m&Expires=1460466188&Signature=%2BnzTtpyxUWDuQn924jdS6b51vT8%3D
-Create A Image Service Instance
-Each Image Service instance required accessKeyId, accessKeySecret, bucket and imageHost.
-
-oss.ImageClient(options)
-Create a Image service instance.
-
-options:
-
-imageHost {String} your image service domain that binding to a OSS bucket
-accessKeyId {String} access key you create on aliyun console website
-accessKeySecret {String} access secret you create
-bucket {String} the default bucket you want to access If you don't have any bucket, please use putBucket() create one first.
-[region] {String} the bucket data region location, please see Data Regions, default is oss-cn-hangzhou Current available: oss-cn-hangzhou, oss-cn-qingdao, oss-cn-beijing, oss-cn-hongkong and oss-cn-shenzhen
-[internal] {Boolean} access OSS with aliyun internal network or not, default is false If your servers are running on aliyun too, you can set true to save lot of money.
-[timeout] {String|Number} instance level timeout for all operations, default is 60s
-example:
-
-const oss = require('ali-oss');
-
-const imgClient = oss.ImageClient({
-  accessKeyId: 'your access key',
-  accessKeySecret: 'your access secret',
-  bucket: 'my_image_bucket',
-  imageHost: 'thumbnail.myimageservice.com'
-});
-Image Operations
-All operations function is [async], except imgClient.signatureUrl.
-
-async function format: async functionName(...).
-
-imgClient.get(name, file[, options])
-Get an image from the image channel.
-
-parameters:
-
-name {String} image object name with operation style store on OSS
-[file] {String|WriteStream} file path or WriteStream instance to store the image If file is null or ignore this parameter, function will return info contains content property.
-[options] {Object} optional parameters
-[timeout] {Number} the operation timeout
-[headers] {Object} extra headers, detail see RFC 2616
-'If-Modified-Since' object modified after this time will return 200 and object meta, otherwise return 304 not modified
-'If-Unmodified-Since' object modified before this time will return 200 and object meta, otherwise throw PreconditionFailedError
-'If-Match' object etag equal this will return 200 and object meta, otherwise throw PreconditionFailedError
-'If-None-Match' object etag not equal this will return 200 and object meta, otherwise return 304 not modified
-Success will return the info contains response.
-
-object:
-
-[content] {Buffer} file content buffer if file parameter is null or ignore
-res {Object} response info, including
-status {Number} response status
-headers {Object} response headers
-size {Number} response size
-rt {Number} request total use time (ms)
-If object not exists, will throw NoSuchKeyError.
-
-example:
-
-Get an exists image with a style and store it to the local file
-const imagepath = '/home/ossdemo/demo.jpg';
-await imgClient.get('ossdemo/demo.jpg@200w_200h', filepath);
-_ Store image to a writestream
-
-await imgClient.get('ossdemo/demo.jpg@200w_200h', somestream);
-Get an image content buffer
-const result = await imgClient.get('ossdemo/demo.jpg@200w_200h');
-console.log(Buffer.isBuffer(result.content));
-Get a not exists object or a not image object
-const imagepath = '/home/ossdemo/demo.jpg';
-await imgClient.get('ossdemo/not-exists-demo.jpg@200w_200h', filepath);
-// will throw NoSuchKeyError
-imgClient.getStream(name[, options])
-Get an image read stream.
-
-parameters:
-
-name {String} image object name with operation style store on OSS
-[options] {Object} optional parameters
-[timeout] {Number} the operation timeout
-[headers] {Object} extra headers
-'If-Modified-Since' object modified after this time will return 200 and object meta, otherwise return 304 not modified
-'If-Unmodified-Since' object modified before this time will return 200 and object meta, otherwise throw PreconditionFailedError
-'If-Match' object etag equal this will return 200 and object meta, otherwise throw PreconditionFailedError
-'If-None-Match' object etag not equal this will return 200 and object meta, otherwise return 304 not modified
-Success will return the stream instance and response info.
-
-object:
-
-stream {ReadStream} readable stream instance. If response status is not 200, stream will be null.
-res {Object} response info, including
-status {Number} response status
-headers {Object} response headers
-size {Number} response size
-rt {Number} request total use time (ms)
-If object not exists, will throw NoSuchKeyError.
-
-example:
-
-Get an exists image object stream
-const result = await imgClient.getStream('ossdemo/demo.jpg@200w_200h');
-result.stream.pipe(fs.createWriteStream('some demo.jpg'));
-imgClient.getExif(name[, options])
-Get a image exif info by image object name from the image channel.
-
-parameters:
-
-name {String} image object name
-[options] {Object} optional parameters
-[timeout] {Number} the operation timeout
-Success will return the info contains response.
-
-object:
-
-res {Object} response info, including
-status {Number} response status
-headers {Object} response headers
-size {Number} response size
-rt {Number} request total use time (ms)
-data {Object} image exif object
-If object don't have exif, will throw 400 BadRequest.
-
-example:
-
-const result = await imgClient.getExif('demo.jpg');
-// resut:
-// {
-//   res: {
-//     status: 200,
-//     statusCode: 200,
-//     headers: {
-//       server: "Tengine",
-//       content - type: "application/json",
-//       content - length: "148",
-//       connection: "keep-alive",
-//       date: "Tue, 31 Mar 2015 11:06:32 GMT",
-//       "last-modified": "Mon, 30 Mar 2015 10:46:35 GMT"
-//     },
-//     size: 148,
-//     aborted: false,
-//     rt: 461,
-//     keepAliveSocket: false
-//   },
-//   data: {
-//     FileSize: 343683,
-//     ImageHeight: 1200,
-//     ImageWidth: 1600,
-//     Orientation: 1
-//   }
-// }
-imgClient.getInfo(name[, options])
-Get a image info and exif info by image object name from the image channel.
-
-parameters:
-
-name {String} image object name
-[options] {Object} optional parameters
-[timeout] {Number} the operation timeout
-Success will return the info contains response.
-
-object:
-
-res {Object} response info, including
-status {Number} response status
-headers {Object} response headers
-size {Number} response size
-rt {Number} request total use time (ms)
-data {Object} image exif object
-example:
-
-const result = await imgClient.getInfo('demo.jpg');
-// resut:
-// {
-//   res: {
-//     status: 200,
-//     statusCode: 200,
-//     headers: {
-//       server: "Tengine",
-//       content - type: "application/json",
-//       content - length: "148",
-//       connection: "keep-alive",
-//       date: "Tue, 31 Mar 2015 11:06:32 GMT",
-//       "last-modified": "Mon, 30 Mar 2015 10:46:35 GMT"
-//     },
-//     size: 148,
-//     aborted: false,
-//     rt: 461,
-//     keepAliveSocket: false
-//   },
-//   data: {
-//     FileSize: 343683,
-//     Format: "jpg",
-//     ImageHeight: 1200,
-//     ImageWidth: 1600,
-//     Orientation: 1
-//   }
-// }
-imgClient.putStyle(name, style[, options])
-// TODO
-
-imgClient.getStyle(name[, options])
-Get a style by name from the image channel.
-
-parameters:
-
-name {String} image style name
-[options] {Object} optional parameters
-[timeout] {Number} the operation timeout
-Success will return the info contains response.
-
-object:
-
-res {Object} response info, including
-status {Number} response status
-headers {Object} response headers
-size {Number} response size
-rt {Number} request total use time (ms)
-data {Object} styles object
-Name {String} style name
-Content {String} style content
-CreateTime {String} style create time
-LastModifyTime {String} style last modify time
-example:
-
-const result = await imgClient.getStyle('400');
-// resut:
-// {
-//   res: {
-//     status: 200,
-//     statusCode: 200,
-//     headers: {
-//       server: "Tengine",
-//       content - type: "application/xml",
-//       content - length: "234",
-//       connection: "keep-alive",
-//       date: "Tue, 31 Mar 2015 10:58:20 GMT"
-//     },
-//     size: 234,
-//     aborted: false,
-//     rt: 398,
-//     keepAliveSocket: false
-//   },
-//   data: {
-//     Name: "400",
-//     Content: "400w_90Q_1x.jpg",
-//     CreateTime: "Thu, 19 Mar 2015 08:34:21 GMT",
-//     LastModifyTime: "Thu, 19 Mar 2015 08:34:21 GMT"
-//   }
-// }
-imgClient.listStyle([options])
-Get all styles from the image channel.
-
-parameters:
-
-[options] {Object} optional parameters
-[timeout] {Number} the operation timeout
-Success will return the info contains response.
-
-object:
-
-res {Object} response info, including
-status {Number} response status
-headers {Object} response headers
-size {Number} response size
-rt {Number} request total use time (ms)
-data {Array} styles array, a style object:
-Name {String} style name
-Content {String} style content
-CreateTime {String} style create time
-LastModifyTime {String} style last modify time
-example:
-
-const result = await imgClient.listStyle();
-// resut:
-// {
-//   res: {
-//     status: 200,
-//     statusCode: 200,
-//     headers: {
-//       server: "Tengine",
-//       content - type: "application/xml",
-//       content - length: "913",
-//       connection: "keep-alive",
-//       date: "Tue, 31 Mar 2015 10:47:32 GMT"
-//     },
-//     size: 913,
-//     aborted: false,
-//     rt: 1911,
-//     keepAliveSocket: false
-//   },
-//   data: [{
-//     Name: "200-200",
-//     Content: "0e_200w_200h_0c_0i_0o_90Q_1x.jpg",
-//     CreateTime: "Thu, 19 Mar 2015 08:28:08 GMT",
-//     LastModifyTime: "Thu, 19 Mar 2015 08:28:08 GMT"
-//   }, {
-//     Name: "800",
-//     Content: "800w_90Q_1x.jpg",
-//     CreateTime: "Thu, 19 Mar 2015 08:29:15 GMT",
-//     LastModifyTime: "Thu, 19 Mar 2015 08:29:15 GMT"
-//   }, {
-//     Name: "400",
-//     Content: "400w_90Q_1x.jpg",
-//     CreateTime: "Thu, 19 Mar 2015 08:34:21 GMT",
-//     LastModifyTime: "Thu, 19 Mar 2015 08:34:21 GMT"
-//   }, {
-//     Name: "600",
-//     Content: "600w_90Q_1x.jpg",
-//     CreateTime: "Thu, 19 Mar 2015 08:35:02 GMT",
-//     LastModifyTime: "Thu, 19 Mar 2015 08:35:02 GMT"
-//   }]
-// }
-imgClient.deleteStyle(name[, options])
-// TODO
-
-imgClient.signatureUrl(name)
-Create a signature url for directly download.
-
-parameters:
-
-name {String} image object name with operation style store on OSS
-[options] {Object} optional parameters
-[expires] {Number} after expires seconds, the url will become invalid, default is 1800
-[timeout] {Number} the operation timeout
-Success will return full signature url.
-
-example:
-
-const url = imgClient.signatureUrl('name');
-Cluster Mode
-Cluster mode now only support object operations.
-
-const Cluster = require('ali-oss').ClusterClient;
-
-const client = Cluster({
-  cluster: [
-    {
-      host: 'host1',
-      accessKeyId: 'id1',
-      accessKeySecret: 'secret1'
-    },
-    {
-      host: 'host2',
-      accessKeyId: 'id2',
-      accessKeySecret: 'secret2'
-    }
-  ],
-  schedule: 'masterSlave' //default is `roundRobin`
-});
-
-// listen error event to logging error
-client.on('error', function (err) {
-  console.error(err.stack);
-});
-
-// client init ready
-client.ready(function () {
-  console.log('cluster client init ready, go ahead!');
-});
-Get Methods
-Will choose an alive client by schedule(masterSlave or roundRobin).
-
-client.get()
-client.head()
-client.getStream()
-client.list()
-client.signatureUrl()
-client.chooseAvailable() - choose an available client by schedule.
-client.getACL()
-Put Methods
-Will put to all clients.
-
-client.put()
-client.putStream()
-client.delete()
-client.deleteMulti()
-client.copy()
-client.putMeta()
-client.putACL()
-client.restore()
-Known Errors
-Each error return by OSS server will contains these properties:
-
-name {String} error name
-message {String} error message
-requestId {String} uuid for this request, if you meet some unhandled problem, you can send this request id to OSS engineer to find out what's happend.
-hostId {String} OSS cluster name for this request
-ResponseTimeoutError
-The default timeout is 60 seconds. Please set the timeout as needed. The timeout unit is milliseconds.
-
-client.get('example.txt', { timeout: 60000 * 2 });
-
-client.get('example.txt', { headers: { Range: `bytes=0-${1024 * 1024 * 100}` } }); // Download the first 100MB
-ConnectionTimeoutError
-The network link timed out. Please check the network status. If there is no problem with the network, please reduce the partSize or increase the timeout.
-
-const client = new OSS({ ak, sk, retryMax: 10 });
-
-client.multipartUpload('example.txt', { timeout: 60000 * 2 });
-
-client.multipartUpload('example.txt', { partSize: 1024 * 512 }); // partSize 512KB
-The following table lists the OSS error codes:
-More code info
-
-name	code	status	message	message in Chinese
-AccessDeniedError	AccessDenied	403	Access Denied	拒绝访问
-BucketAlreadyExistsError	BucketAlreadyExists	409	Bucket already exists	Bucket 已经存在
-BucketNotEmptyError	BucketNotEmpty	409	Bucket is not empty	Bucket 不为空
-RestoreAlreadyInProgressError	RestoreAlreadyInProgress	409	The restore operation is in progress.	restore 操作正在进行中
-OperationNotSupportedError	OperationNotSupported	400	The operation is not supported for this resource	该资源暂不支持restore操作
-EntityTooLargeError	EntityTooLarge	400	Entity too large	实体过大
-EntityTooSmallError	EntityTooSmall	400	Entity too small	实体过小
-FileGroupTooLargeError	FileGroupTooLarge	400	File group too large	文件组过大
-InvalidLinkNameError	InvalidLinkName	400	Link name can't be the same as the object name	Object Link 与指向的 Object 同名
-LinkPartNotExistError	LinkPartNotExist	400	Can't link to not exists object	Object Link 中指向的 Object 不存在
-ObjectLinkTooLargeError	ObjectLinkTooLarge	400	Too many links to this object	Object Link 中 Object 个数过多
-FieldItemTooLongError	FieldItemTooLong	400	Post form fields items too large	Post 请求中表单域过大
-FilePartInterityError	FilePartInterity	400	File part has changed	文件 Part 已改变
-FilePartNotExistError	FilePartNotExist	400	File part not exists	文件 Part 不存在
-FilePartStaleError	FilePartStale	400	File part stale	文件 Part 过时
-IncorrectNumberOfFilesInPOSTRequestError	IncorrectNumberOfFilesInPOSTRequest	400	Post request contains invalid number of files	Post 请求中文件个数非法
-InvalidArgumentError	InvalidArgument	400	Invalid format argument	参数格式错误
-InvalidAccessKeyIdError	InvalidAccessKeyId	400	Access key id not exists	Access Key ID 不存在
-InvalidBucketNameError	InvalidBucketName	400	Invalid bucket name	无效的 Bucket 名字
-InvalidDigestError	InvalidDigest	400	Invalid digest	无效的摘要
-InvalidEncryptionAlgorithmError	InvalidEncryptionAlgorithm	400	Invalid encryption algorithm	指定的熵编码加密算法错误
-InvalidObjectNameError	InvalidObjectName	400	Invalid object name	无效的 Object 名字
-InvalidPartError	InvalidPart	400	Invalid part	无效的 Part
-InvalidPartOrderError	InvalidPartOrder	400	Invalid part order	无效的 part 顺序
-InvalidPolicyDocumentError	InvalidPolicyDocument	400	Invalid policy document	无效的 Policy 文档
-InvalidTargetBucketForLoggingError	InvalidTargetBucketForLogging	400	Invalid bucket on logging operation	Logging 操作中有无效的目标 bucket
-InternalError	Internal	500	OSS server internal error	OSS 内部发生错误
-MalformedXMLError	MalformedXML	400	Malformed XML format	XML 格式非法
-MalformedPOSTRequestError	MalformedPOSTRequest	400	Invalid post body format	Post 请求的 body 格式非法
-MaxPOSTPreDataLengthExceededError	MaxPOSTPreDataLengthExceeded	400	Post extra data too large	Post 请求上传文件内容之外的 body 过大
-MethodNotAllowedError	MethodNotAllowed	405	Not allowed method	不支持的方法
-MissingArgumentError	MissingArgument	411	Missing argument	缺少参数
-MissingContentLengthError	MissingContentLength	411	Missing Content-Length header	缺少内容长度
-NoSuchBucketError	NoSuchBucket	404	Bucket not exists	Bucket 不存在
-NoSuchKeyError	NoSuchKey	404	Object not exists	文件不存在
-NoSuchUploadError	NoSuchUpload	404	Multipart upload id not exists	Multipart Upload ID 不存在
-NotImplementedError	NotImplemented	501	Not implemented	无法处理的方法
-PreconditionFailedError	PreconditionFailed	412	Pre condition failed	预处理错误
-RequestTimeTooSkewedError	RequestTimeTooSkewed	403	Request time exceeds 15 minutes to server time	发起请求的时间和服务器时间超出 15 分钟
-RequestTimeoutError	RequestTimeout	400	Request timeout	请求超时
-RequestIsNotMultiPartContentError	RequestIsNotMultiPartContent	400	Invalid post content-type	Post 请求 content-type 非法
-SignatureDoesNotMatchError	SignatureDoesNotMatch	403	Invalid signature	签名错误
-TooManyBucketsError	TooManyBuckets	400	Too many buckets on this user	用户的 Bucket 数目超过限制
-RequestError	RequestError	-1	network error	网络出现中断或异常
-ConnectionTimeoutError	ConnectionTimeoutError	-2	request connect timeout	请求连接超时
-SecurityTokenExpiredError	SecurityTokenExpired	403	sts Security Token Expired	sts Security Token 超时失效
-About
-Aliyun OSS(Object Storage Service) JavaScript SDK for the Browser and Node.js
-
-www.alibabacloud.com/help/doc-detail/52834.htm
-Topics
-javascript oss sdk aliyun-oss aliyun alibabacloud
-Resources
- Readme
-License
- MIT license
-Security policy
- Security policy
- Activity
- Custom properties
-Stars
- 2k stars
-Watchers
- 47 watching
-Forks
- 576 forks
-Report repository
-Releases 13
-v6.22.0
-Latest
-on Dec 3, 2024
-+ 12 releases
-Packages
-No packages published
-Used by 11.9k
-@entropyx-org
-@karry-yang
-@Rfym21
-@karry-yang
-@baozaolaoxie
-@ZARD0520
-@markyezx
-@taoqianbao
-+ 11,877
-Contributors
-45
-@PeterRao
-@rockuw
-@dead-horse
-@fengmk2
-@taotao7
-@weiyie
-@binghaiwang
-@beajer
-@greenkeeperio-bot
-@luozhang002
-@YunZZY
-@shungang
-@mars-coder
-@duan007a
-+ 31 contributors
-Deployments
-500+
- ali_oss_AK 9 hours ago
-+ more deployments
-Languages
-JavaScript
-76.8%
- 
-HTML
-19.6%
- 
-TypeScript
-3.6%
-Footer
-© 2025 GitHub, Inc.
-Footer navigation
-Terms
-Privacy
-Security
-Status
-Docs
-Contact
-Manage cookies
-Do not share my personal information
diff --git a/docs/architecture.drawio b/docs/architecture.drawio
deleted file mode 100644
index e69de29..0000000
diff --git a/docs/architecture.md b/docs/architecture.md
deleted file mode 100644
index fa8bec6..0000000
--- a/docs/architecture.md
+++ /dev/null
@@ -1,117 +0,0 @@
-# 智审大师系统架构
-
-## 系统架构图
-
-```mermaid
-graph TB
-    %% 主要层级
-    subgraph Client["客户端"]
-        FE_COMPONENTS["UI组件 (Components)"]
-        PAGES["页面 (Pages)"]
-    end
-    
-    subgraph ServerLayer["服务器层"]
-        subgraph NextFramework["Next.js框架"]
-            SERVER_COMPONENTS["服务端组件"]
-            SERVER_ACTIONS["Server Actions"]
-            API_ROUTES["API路由"]
-        end
-        
-        subgraph AiLayer["AI处理层"]
-            AI_MODELS["DeepSeek模型集成"]
-            DEEPSEEK_V3["DeepSeek-V3\n(671B参数基础模型)"]
-            DEEPSEEK_R1["DeepSeek-R1\n(推理增强模型)"]
-        end
-    end
-    
-    subgraph PersistenceLayer["持久化层"]
-        DB["PostgreSQL数据库"]
-        FILE_STORAGE["文件存储"]
-    end
-    
-    %% 连接关系
-    PAGES --> FE_COMPONENTS
-    PAGES --> SERVER_COMPONENTS
-    PAGES --> SERVER_ACTIONS
-    SERVER_COMPONENTS --> API_ROUTES
-    SERVER_COMPONENTS --> DB
-    SERVER_ACTIONS --> AiLayer
-    SERVER_ACTIONS --> DB
-    API_ROUTES --> AiLayer
-    API_ROUTES --> DB
-    AI_MODELS --> DEEPSEEK_V3
-    AI_MODELS --> DEEPSEEK_R1
-    SERVER_ACTIONS --> FILE_STORAGE
-    AI_MODELS --> FILE_STORAGE
-    
-    %% 客户端细分
-    subgraph "前端组件结构"
-        UI["UI组件库"]
-        THEME["主题系统"]
-        PROVIDERS["Provider组件"]
-        LAYOUT["布局组件"]
-        FORMS["表单组件"]
-        HOOKS["自定义Hooks"]
-    end
-    
-    %% AI处理细分
-    subgraph "AI功能模块"
-        TEXT_EXTRACT["文本信息提取"]
-        COMPLIANCE["合规性检查"]
-        QA["智能问答"]
-        REASONING["复杂推理"]
-    end
-    
-    %% 数据库模型细分
-    subgraph "数据模型"
-        AUTH_MODELS["认证模型\n(Users, Teams)"]
-        ORG_MODELS["组织模型\n(Organizations)"]
-        DOC_MODELS["文档模型\n(Documents, Files)"]
-        AUDIT_MODELS["审计模型\n(ComplianceRules, Checks)"]
-        ANALYSIS_MODELS["分析结果模型\n(AnalysisResults)"]
-    end
-```
-
-## 架构说明
-
-### 1. 客户端层
-
-客户端层采用Next.js框架的客户端组件，负责用户界面渲染和交互。
-
-- **页面 (Pages)**: 遵循Next.js的应用路由结构，包含核心页面、登录页面和管理页面
-- **UI组件 (Components)**: 包含可复用的UI组件，如按钮、表单、导航栏等
-
-### 2. 服务器层
-
-服务器层包含Next.js框架的服务端能力和AI处理模块。
-
-- **Next.js框架**:
-  - **服务端组件**: 负责数据预取和服务端渲染
-  - **Server Actions**: 处理表单提交和数据修改等操作
-  - **API路由**: 提供客户端API接口
-
-- **AI处理层**:
-  - **DeepSeek-V3**: 基础大模型，用于文本理解和生成
-  - **DeepSeek-R1**: 推理增强模型，用于复杂审计任务和信息提取
-
-### 3. 持久化层
-
-持久化层负责数据的存储和检索。
-
-- **PostgreSQL数据库**: 存储用户数据、组织信息、文档元数据和审计结果
-- **文件存储**: 存储上传的文档文件
-
-### 4. 主要功能模块
-
-- **文本信息提取**: 从会议纪要和合同中提取关键信息
-- **合规性检查**: 根据规则检查文档的合规性
-- **智能问答**: 基于文档内容回答问题
-- **复杂推理**: 进行决策分析和逻辑推理
-
-### 5. 数据流
-
-1. 用户通过客户端上传文档或发起请求
-2. 请求通过Server Actions或API路由传递到服务器
-3. 服务器根据请求类型调用相应的AI处理模块
-4. AI模块处理请求并返回结果
-5. 结果存储到数据库并返回给客户端
diff --git a/docs/deepseek/first-call.md b/docs/deepseek/first-call.md
deleted file mode 100644
index 719c318..0000000
--- a/docs/deepseek/first-call.md
+++ /dev/null
@@ -1,87 +0,0 @@
-Skip to main content
-DeepSeek API Docs Logo
-DeepSeek API Docs
-English
-DeepSeek Platform
-
-Quick Start
-Your First API Call
-Models & Pricing
-The Temperature Parameter
-Token & Token Usage
-Rate Limit
-Error Codes
-News
-DeepSeek-R1 Release 2025/01/20
-DeepSeek APP 2025/01/15
-Introducing DeepSeek-V3 2024/12/26
-DeepSeek-V2.5-1210 Release 2024/12/10
-DeepSeek-R1-Lite Release 2024/11/20
-DeepSeek-V2.5 Release 2024/09/05
-Context Caching is Available 2024/08/02
-New API Features 2024/07/25
-API Reference
-API Guides
-Reasoning Model (deepseek-reasoner)
-Multi-round Conversation
-Chat Prefix Completion (Beta)
-FIM Completion (Beta)
-JSON Output
-Function Calling
-Context Caching
-Other Resources
-Integrations
-API Status Page
-FAQ
-Change Log
-Quick StartYour First API Call
-Your First API Call
-The DeepSeek API uses an API format compatible with OpenAI. By modifying the configuration, you can use the OpenAI SDK or softwares compatible with the OpenAI API to access the DeepSeek API.
-
-PARAM	VALUE
-base_url *       	https://api.deepseek.com
-api_key	apply for an API key
-* To be compatible with OpenAI, you can also use https://api.deepseek.com/v1 as the base_url. But note that the v1 here has NO relationship with the model's version.
-
-* The deepseek-chat model has been upgraded to DeepSeek-V3. The API remains unchanged. You can invoke DeepSeek-V3 by specifying model='deepseek-chat'.
-
-* deepseek-reasoner is the latest reasoning model, DeepSeek-R1, released by DeepSeek. You can invoke DeepSeek-R1 by specifying model='deepseek-reasoner'.
-
-Invoke The Chat API
-Once you have obtained an API key, you can access the DeepSeek API using the following example scripts. This is a non-stream example, you can set the stream parameter to true to get stream response.
-
-curl
-python
-nodejs
-// Please install OpenAI SDK first: `npm install openai`
-
-import OpenAI from "openai";
-
-const openai = new OpenAI({
-        baseURL: 'https://api.deepseek.com',
-        apiKey: '<DeepSeek API Key>'
-});
-
-async function main() {
-  const completion = await openai.chat.completions.create({
-    messages: [{ role: "system", content: "You are a helpful assistant." }],
-    model: "deepseek-chat",
-  });
-
-  console.log(completion.choices[0].message.content);
-}
-
-main();
-
-Next
-Models & Pricing
-Invoke The Chat API
-WeChat Official Account
-WeChat QRcode
-Community
-Email
-Discord
-Twitter
-More
-GitHub
-Copyright © 2025 DeepSeek, Inc.
\ No newline at end of file
diff --git a/docs/deepseek/reasoning.md b/docs/deepseek/reasoning.md
deleted file mode 100644
index 2c8ddad..0000000
--- a/docs/deepseek/reasoning.md
+++ /dev/null
@@ -1,117 +0,0 @@
-Skip to main content
-DeepSeek API Docs Logo
-DeepSeek API Docs
-English
-DeepSeek Platform
-
-Quick Start
-Your First API Call
-Models & Pricing
-The Temperature Parameter
-Token & Token Usage
-Rate Limit
-Error Codes
-News
-API Reference
-Introduction
-Chat
-Completions
-Create FIM Completion (Beta)
-Models
-Lists Models
-Others
-Get User Balance
-API Guides
-Reasoning Model (deepseek-reasoner)
-Multi-round Conversation
-Chat Prefix Completion (Beta)
-FIM Completion (Beta)
-JSON Output
-Function Calling
-Context Caching
-Other Resources
-Integrations
-API Status Page
-FAQ
-Change Log
-API GuidesReasoning Model (deepseek-reasoner)
-Reasoning Model (deepseek-reasoner)
-deepseek-reasoner is a reasoning model developed by DeepSeek. Before delivering the final answer, the model first generates a Chain of Thought (CoT) to enhance the accuracy of its responses. Our API provides users with access to the CoT content generated by deepseek-reasoner, enabling them to view, display, and distill it.
-
-When using deepseek-reasoner, please upgrade the OpenAI SDK first to support the new parameters.
-
-pip3 install -U openai
-
-API Parameters
-Input：
-
-max_tokens：The maximum length of the final response after the CoT output is completed, defaulting to 4K, with a maximum of 8K. Note that the CoT output can reach up to 32K tokens, and the parameter to control the CoT length (reasoning_effort) will be available soon.
-Output：
-
-reasoning_content：The content of the CoT，which is at the same level as content in the output structure. See API Example for details
-contentThe content of the final answer
-Context Length：The API supports a maximum context length of 64K, and the length of the output reasoning_content is not counted within the 64K context length.
-
-Supported Features：Chat Completion、Chat Prefix Completion (Beta)
-
-Not Supported Features：Function Call、Json Output、FIM (Beta)
-
-Not Supported Parameters：temperature、top_p、presence_penalty、frequency_penalty、logprobs、top_logprobs. Please note that to ensure compatibility with existing software, setting temperature、top_p、presence_penalty、frequency_penalty will not trigger an error but will also have no effect. Setting logprobs、top_logprobs will trigger an error.
-
-Multi-round Conversation
-In each round of the conversation, the model outputs the CoT (reasoning_content) and the final answer (content). In the next round of the conversation, the CoT from previous rounds is not concatenated into the context, as illustrated in the following diagram:
-
-
-Please note that if the reasoning_content field is included in the sequence of input messages, the API will return a 400 error. Therefore, you should remove the reasoning_content field from the API response before making the API request, as demonstrated in the API example.
-
-API Example
-The following code, using Python as an example, demonstrates how to access the CoT and the final answer, as well as how to conduct multi-round conversations:
-
-NoStreaming
-Streaming
-from openai import OpenAI
-client = OpenAI(api_key="<DeepSeek API Key>", base_url="https://api.deepseek.com")
-
-# Round 1
-messages = [{"role": "user", "content": "9.11 and 9.8, which is greater?"}]
-response = client.chat.completions.create(
-    model="deepseek-reasoner",
-    messages=messages,
-    stream=True
-)
-
-reasoning_content = ""
-content = ""
-
-for chunk in response:
-    if chunk.choices[0].delta.reasoning_content:
-        reasoning_content += chunk.choices[0].delta.reasoning_content
-    else:
-        content += chunk.choices[0].delta.content
-
-# Round 2
-messages.append({"role": "assistant", "content": content})
-messages.append({'role': 'user', 'content': "How many Rs are there in the word 'strawberry'?"})
-response = client.chat.completions.create(
-    model="deepseek-reasoner",
-    messages=messages,
-    stream=True
-)
-# ...
-
-Previous
-Get User Balance
-Next
-Multi-round Conversation
-API Parameters
-Multi-round Conversation
-API Example
-WeChat Official Account
-WeChat QRcode
-Community
-Email
-Discord
-Twitter
-More
-GitHub
-Copyright © 2025 DeepSeek, Inc.
\ No newline at end of file
diff --git a/docs/oss.md b/docs/oss.md
deleted file mode 100644
index dc7a795..0000000
--- a/docs/oss.md
+++ /dev/null
@@ -1,68 +0,0 @@
-# 阿里云 OSS 文件存储配置指南
-
-本项目使用阿里云 OSS（对象存储服务）来存储被审计单位上传的文件。这种方式比本地文件存储更安全、更可靠，并且提供了更好的扩展性和访问性能。
-
-## 配置步骤
-
-### 1. 创建阿里云 OSS Bucket
-
-1. 登录[阿里云控制台](https://home.console.aliyun.com/)
-2. 进入 OSS 管理界面
-3. 创建一个新的 Bucket，记下以下信息：
-   - Bucket 名称
-   - 所在地域（Region）
-   - 访问域名（Endpoint）
-
-### 2. 创建 AccessKey
-
-1. 在阿里云控制台中找到 "AccessKey 管理"
-2. 创建一个新的 AccessKey（推荐使用 RAM 用户的 AccessKey，而非主账号）
-3. 记录 AccessKey ID 和 AccessKey Secret
-
-### 3. 配置环境变量
-
-在项目的 `.env` 文件中添加以下配置：
-
-```
-# 阿里云OSS配置
-STORAGE_PROVIDER=aliyun_oss
-ALIYUN_OSS_REGION=oss-cn-hangzhou  # 替换为您的地域
-ALIYUN_OSS_ACCESS_KEY_ID=your-access-key-id  # 替换为您的 AccessKey ID
-ALIYUN_OSS_ACCESS_KEY_SECRET=your-access-key-secret  # 替换为您的 AccessKey Secret
-ALIYUN_OSS_BUCKET=llamaudit-files  # 替换为您的 Bucket 名称
-ALIYUN_OSS_ENDPOINT=https://oss-cn-hangzhou.aliyuncs.com  # 替换为您的访问域名
-```
-
-## 文件存储机制
-
-本系统支持两种文件存储模式：
-
-1. 本地存储（默认）：文件保存在服务器的本地文件系统中
-2. 阿里云 OSS 存储：文件保存在阿里云 OSS 中
-
-通过设置 `STORAGE_PROVIDER` 环境变量可以切换存储模式：
-- `STORAGE_PROVIDER=local`：使用本地存储
-- `STORAGE_PROVIDER=aliyun_oss`：使用阿里云 OSS 存储
-
-## 工作原理
-
-1. 当用户上传文件时，文件会根据配置的存储提供商进行处理
-2. 如果使用阿里云 OSS，文件会直接上传到 OSS，并在数据库中记录文件的元数据和访问路径
-3. 访问文件时，系统会返回文件的 URL（OSS文件的公共访问URL）
-4. 删除文件时，系统会同时删除 OSS 中的文件和数据库中的记录
-
-## 文件安全
-
-为了确保文件安全，建议配置以下 OSS 安全设置：
-
-1. 设置合理的 Bucket 访问权限（推荐私有读写）
-2. 配置 STS（Security Token Service）实现临时授权访问
-3. 配置防盗链设置，限制文件被非法引用
-4. 开启服务器端加密功能
-5. 定期审计访问日志
-
-## 相关代码文件
-
-- `lib/file-storage.ts`：文件存储的核心实现
-- `lib/actions/file-actions.ts`：处理文件上传和删除的 Server Actions
-- `.env`：存储提供商配置 
\ No newline at end of file
diff --git "a/docs/\346\231\272\345\256\241\345\244\247\345\270\210\344\275\277\347\224\250\350\257\264\346\230\216\344\271\246 v0.2.1.md" "b/docs/\346\231\272\345\256\241\345\244\247\345\270\210\344\275\277\347\224\250\350\257\264\346\230\216\344\271\246 v0.2.1.md"
deleted file mode 100644
index c52c697..0000000
--- "a/docs/\346\231\272\345\256\241\345\244\247\345\270\210\344\275\277\347\224\250\350\257\264\346\230\216\344\271\246 v0.2.1.md"	
+++ /dev/null
@@ -1,324 +0,0 @@
-
-
-```ad-tip
-
-前端程序升级指令
-
-	```
-	git add . && git stash && git pull
-
-	pnpm i && pnpm build && pnpm start
-	```
-```
-
-## 系统概述
-
-智审大师是一款AI驱动的审计辅助系统，支持文件管理、信息抽取、合规性检查等功能。系统采用微服务架构，由以下几个主要组件构成：
-
-1. **前端应用** - 基于Next.js框架开发的Web应用
-2. **PostgreSQL数据库** - 存储系统所有业务数据
-3. **Ollama服务** - 本地化大模型推理引擎
-4. **Dify平台** - AI应用开发与管理平台
-
-## 系统架构图
-
-```
-┌─────────────────┐    ┌─────────────────┐    ┌─────────────────┐
-│                 │    │                 │    │                 │
-│  前端应用        │───▶│  PostgreSQL     │◀───│  Dify平台       │
-│  (Next.js)      │    │  数据库         │    │                 │
-│                 │    │                 │    │                 │
-└────────┬────────┘    └─────────────────┘    └────────┬────────┘
-         │                                             │
-         │                                             │
-         │                                             │
-         │            ┌─────────────────┐              │
-         └──────────▶│                 │◀──────────────┘
-                     │  Ollama服务      │
-                     │  (大模型推理)    │
-                     │                 │
-                     └─────────────────┘
-```
-
-## 部署环境要求
-
-- 操作系统: Linux (推荐Ubuntu 22.04或更高版本)
-- 内存: 最小16GB，推荐32GB或更高
-- CPU: 最小8核，推荐16核或更高
-- 硬盘空间: 最小100GB，推荐500GB或更高
-- 网络: 内网环境，建议千兆网络
-- 软件依赖:
-  - Docker 24.0或更高
-  - sudo docker compose v2.0或更高
-  - Node.js 20.0或更高
-  - pnpm 8.0或更高
-
-## 部署目录结构
-
-系统所有组件均部署在服务器的`~/nau`目录下，主要包含以下子目录：
-
-```
-~/nau/
-├── 2025-03-15_llamaudit/    # 智审大师前端及API服务
-│   ├── docker-compose.yml   # PostgreSQL数据库配置
-│   └── ...                  # 其他项目文件
-├── ollama/                  # Ollama服务目录
-│   ├── docker-compose.yml   # Ollama服务配置
-│   └── ...                  # 其他配置文件
-└── dify/                    # Dify平台目录
-    ├── docker-compose.yml   # Dify服务配置
-    └── ...                  # 其他配置文件
-```
-
-## 系统启动流程
-
-![](https://poketto.oss-cn-hangzhou.aliyuncs.com/202505122215085.png?x-oss-process=image/resize,w_800/rotate,0)
-
-
-### 1. 启动PostgreSQL数据库
-
-```bash
-cd ~/nau/2025-03-15_llamaudit && sudo docker compose up -d
-```
-
-启动后验证：
-```bash
-docker ps | grep postgres
-```
-应看到类似以下输出，表明数据库服务正常运行：
-```
-CONTAINER ID   IMAGE                  COMMAND                  CREATED       STATUS       PORTS                     NAMES
-abc123def456   postgres:16.4-alpine   "docker-entrypoint.s…"   2 hours ago   Up 2 hours   0.0.0.0:54322->5432/tcp   next_saas_starter_postgres
-```
-
-### 2. 启动Ollama服务
-
-```bash
-cd ~/nau/ollama && sudo docker compose up -d
-```
-
-启动后验证：
-```bash
-docker ps | grep ollama
-```
-应看到Ollama容器正在运行。
-
-### 3. 启动Dify平台
-
-```bash
-cd ~/nau/dify && sudo docker compose up -d
-```
-
-启动后验证：
-```bash
-docker ps | grep dify
-```
-应看到多个Dify相关容器正在运行。
-
-### 4. 启动前端应用
-
-```bash
-cd ~/nau/2025-03-15_llamaudit
-pnpm dev
-```
-
-启动成功后，会显示类似以下信息：
-```
-- Local:        http://localhost:3000
-```
-
-## 访问系统
-
-启动所有服务后，可通过浏览器访问以下地址：
-
-- **智审大师前端**：http://localhost:3000
-- **Dify管理平台**：http://localhost:5001 (默认凭据见系统管理员)
-
-## 系统使用指南
-
-### 首次登录
-
-1. 在浏览器中访问 http://localhost:3000
-2. **使用任意账号注册登录（暂时还没开设管理员账号）**
-
-## 界面展示
-
-### 首页
-
-![](https://poketto.oss-cn-hangzhou.aliyuncs.com/202505122218086.png?x-oss-process=image/resize,w_800/rotate,0)
-
-
-### 注册登录界面
-
-![](https://poketto.oss-cn-hangzhou.aliyuncs.com/202505122218494.png?x-oss-process=image/resize,w_800/rotate,0)
-
-### 被审计单位列表页
-
-![](https://poketto.oss-cn-hangzhou.aliyuncs.com/202505122218544.png?x-oss-process=image/resize,w_800/rotate,0)
-
-## 被审计单位文件列表页
-
-![](https://poketto.oss-cn-hangzhou.aliyuncs.com/202505130128239.png?x-oss-process=image/resize,w_800/rotate,0)
-
-
-## 分析结果数据导出
-
-![](https://poketto.oss-cn-hangzhou.aliyuncs.com/202505130129928.png?x-oss-process=image/resize,w_800/rotate,0)
-
-
-
-
-
-### 主要功能
-
-1. **被审计单位管理**
-   - 路径：侧边栏 → 单位管理
-   - 功能：添加、编辑、删除被审计单位信息
-
-2. **文件管理**
-   - 路径：侧边栏 → 文件管理
-   - 功能：上传Word/PDF文档，按单位和类型分类管理
-
-3. **信息抽取**
-   - 路径：侧边栏 → 信息抽取
-   - 功能：从会议纪要、合同等文件中自动提取关键信息
-
-4. **智能问答**
-   - 路径：侧边栏 → 智能问答
-   - 功能：基于导入文档内容进行智能问答
-
-5. **合规检查**
-   - 路径：侧边栏 → 合规检查
-   - 功能：配置合规规则，检查文件是否符合规定
-
-6. **审计底稿导出**
-   - 路径：各功能页面 → 导出按钮
-   - 功能：将系统中的数据导出为Excel或Word格式
-
-## 系统维护
-
-### 数据备份
-
-建议每周进行一次全量数据备份：
-
-```bash
-# 备份PostgreSQL数据
-cd ~/nau
-mkdir -p backups/$(date +%Y%m%d)
-docker exec next_saas_starter_postgres pg_dump -U postgres postgres > backups/$(date +%Y%m%d)/db_backup.sql
-```
-
-### 日志查看
-
-查看各服务日志：
-
-```bash
-# 查看PostgreSQL日志
-docker logs next_saas_starter_postgres
-
-# 查看Ollama日志
-cd ~/nau/ollama
-sudo docker compose logs
-
-# 查看Dify日志
-cd ~/nau/dify
-sudo docker compose logs
-```
-
-### 系统重启
-
-如需完全重启系统，请按以下顺序操作：
-
-1. 停止前端应用：在运行前端的终端窗口按 `Ctrl+C`
-2. 停止并重启所有Docker服务：
-
-```bash
-# 停止所有服务
-cd ~/nau/2025-03-15_llamaudit && sudo docker compose down
-cd ~/nau/ollama && sudo docker compose down
-cd ~/nau/dify && sudo docker compose down
-
-# 按顺序重启服务
-cd ~/nau/2025-03-15_llamaudit && sudo docker compose up -d
-cd ~/nau/ollama && sudo docker compose up -d
-cd ~/nau/dify && sudo docker compose up -d
-
-# 启动前端
-cd ~/nau/2025-03-15_llamaudit
-pnpm dev
-```
-
-## 常见问题与解决方案
-
-### 1. 系统无法访问
-
-**问题**: 浏览器访问http://localhost:3000显示"无法访问此网站"。
-
-**解决方案**:
-- 检查前端应用是否正在运行
-- 确认终端中是否有错误信息
-- 尝试重启前端应用：
-  ```bash
-  cd ~/nau/2025-03-15_llamaudit
-  pnpm dev
-  ```
-
-### 2. 数据库连接失败
-
-**问题**: 前端应用启动后显示数据库连接错误。
-
-**解决方案**:
-- 确认PostgreSQL容器是否正在运行：
-  ```bash
-  docker ps | grep postgres
-  ```
-- 如未运行，重新启动数据库：
-  ```bash
-  cd ~/nau/2025-03-15_llamaudit
-  sudo docker compose up -d
-  ```
-
-### 3. AI功能不可用
-
-**问题**: 系统中的AI功能（如信息抽取、智能问答）无响应或报错。
-
-**解决方案**:
-- 检查Ollama服务状态：
-  ```bash
-  docker ps | grep ollama
-  ```
-- 检查Dify服务状态：
-  ```bash
-  docker ps | grep dify
-  ```
-- 如有服务未运行，按前述步骤重启相应服务
-
-### 4. 系统运行缓慢
-
-**问题**: 系统整体响应速度慢，特别是AI相关功能。
-
-**解决方案**:
-- 检查服务器资源使用情况：
-  ```bash
-  top
-  ```
-- 可能需要增加服务器内存或CPU资源
-- 对于大型文件处理，建议分批上传
-
-## 联系与支持
-
-如遇到本文档未覆盖的技术问题，请联系系统管理员或技术支持团队：
-
-- 技术支持邮箱：support@cs-magic.com
-- 技术支持电话：17766091857
-- 技术支持负责人：南川
-
-## 文档更新历史
-
-| 版本号    | 更新日期       | 更新内容 | 更新人  |
-| ------ | ---------- | ---- | ---- |
-| v0.1.0 | 2025-05-12 | 初始版本 | 技术团队 |
-
----
-
-© 2025 智审大师 技术团队 版权所有
diff --git a/lib/export-utils.ts b/lib/export-utils.ts
index 50a98de..764ac40 100644
--- a/lib/export-utils.ts
+++ b/lib/export-utils.ts
@@ -37,7 +37,7 @@ function convertMeetingsToTableData(meetings: IMeeting[]): Record<string, any>[]
         '会议结论': meeting.conclusion || '-',
         '内容摘要': meeting.summary || '-',
         '文件名称': meeting.documentName || '-',
-        '三重一大会议': meeting.isTripleOneMeeting ? '是' : '否',
+        '三重一大会议': meeting.isTiobMeeting ? '是' : '否',
         '事项类别': '-',
         '事项详情': '-',
         '涉及金额': '-',
@@ -67,7 +67,7 @@ function convertMeetingsToTableData(meetings: IMeeting[]): Record<string, any>[]
         '会议结论': meeting.conclusion || '-',
         '内容摘要': meeting.summary || '-',
         '文件名称': meeting.documentName || '-',
-        '三重一大会议': meeting.isTripleOneMeeting ? '是' : '否',
+        '三重一大会议': meeting.isTiobMeeting ? '是' : '否',
         '事项类别': categoryName,
         '事项详情': item.details || '-',
         '涉及金额': item.amount || '-',
diff --git a/lib/format-file-size.tsx b/lib/format-file-size.tsx
new file mode 100644
index 0000000..b5660f5
--- /dev/null
+++ b/lib/format-file-size.tsx
@@ -0,0 +1,9 @@
+/**
+ * 格式化文件大小
+ */
+export function formatFileSize(bytes: number): string {
+    if (bytes < 1024) return bytes + ' B';
+    if (bytes < 1024 * 1024) return (bytes / 1024).toFixed(2) + ' KB';
+    if (bytes < 1024 * 1024 * 1024) return (bytes / (1024 * 1024)).toFixed(2) + ' MB';
+    return (bytes / (1024 * 1024 * 1024)).toFixed(2) + ' GB';
+}
\ No newline at end of file
diff --git a/lib/get-file-icon-color.tsx b/lib/get-file-icon-color.tsx
new file mode 100644
index 0000000..473c262
--- /dev/null
+++ b/lib/get-file-icon-color.tsx
@@ -0,0 +1,11 @@
+/**
+ * 获取文件图标颜色
+ */
+export function getFileIconColor(fileType: string): string {
+    if (fileType.includes('pdf')) return 'text-red-500';
+    if (fileType.includes('word') || fileType.includes('doc')) return 'text-blue-500';
+    if (fileType.includes('excel') || fileType.includes('sheet') || fileType.includes('csv')) return 'text-green-500';
+    if (fileType.includes('powerpoint') || fileType.includes('presentation')) return 'text-orange-500';
+    if (fileType.includes('image')) return 'text-purple-500';
+    return 'text-gray-500';
+}
\ No newline at end of file
diff --git a/package.json b/package.json
index f5d20c4..5813302 100644
--- a/package.json
+++ b/package.json
@@ -1,5 +1,6 @@
 {
   "private": true,
+  "version": "0.2.4",
   "scripts": {
     "dev": "next dev",
     "dev:turbo": "next dev --turbopack",
@@ -30,6 +31,7 @@
     "@radix-ui/react-slot": "^1.1.2",
     "@radix-ui/react-tabs": "^1.1.3",
     "@radix-ui/react-toast": "^1.2.13",
+    "@streamparser/json": "^0.0.22",
     "@tailwindcss/postcss": "4.0.12",
     "@types/bcryptjs": "^2.4.6",
     "@types/nanoid": "^3.0.0",
@@ -47,6 +49,8 @@
     "drizzle-orm": "^0.42.0",
     "file-saver": "^2.0.5",
     "jose": "^6.0.8",
+    "jotai": "^2.12.4",
+    "jsonrepair": "^3.12.0",
     "lucide-react": "^0.479.0",
     "nanoid": "^5.1.3",
     "next": "15.2.2-canary.3",
diff --git a/pnpm-lock.yaml b/pnpm-lock.yaml
index caf3990..7a145a3 100644
--- a/pnpm-lock.yaml
+++ b/pnpm-lock.yaml
@@ -62,6 +62,9 @@ importers:
       '@radix-ui/react-toast':
         specifier: ^1.2.13
         version: 1.2.13(@types/react-dom@19.0.4(@types/react@19.0.10))(@types/react@19.0.10)(react-dom@19.0.0(react@19.0.0))(react@19.0.0)
+      '@streamparser/json':
+        specifier: ^0.0.22
+        version: 0.0.22
       '@tailwindcss/postcss':
         specifier: 4.0.12
         version: 4.0.12
@@ -113,6 +116,12 @@ importers:
       jose:
         specifier: ^6.0.8
         version: 6.0.8
+      jotai:
+        specifier: ^2.12.4
+        version: 2.12.4(@types/react@19.0.10)(react@19.0.0)
+      jsonrepair:
+        specifier: ^3.12.0
+        version: 3.12.0
       lucide-react:
         specifier: ^0.479.0
         version: 0.479.0(react@19.0.0)
@@ -582,79 +591,67 @@ packages:
     resolution: {integrity: sha512-9B+taZ8DlyyqzZQnoeIvDVR/2F4EbMepXMc/NdVbkzsJbzkUjhXv/70GQJ7tdLA4YJgNP25zukcxpX2/SueNrA==}
     cpu: [arm64]
     os: [linux]
-    libc: [glibc]
 
   '@img/sharp-libvips-linux-arm@1.0.5':
     resolution: {integrity: sha512-gvcC4ACAOPRNATg/ov8/MnbxFDJqf/pDePbBnuBDcjsI8PssmjoKMAz4LtLaVi+OnSb5FK/yIOamqDwGmXW32g==}
     cpu: [arm]
     os: [linux]
-    libc: [glibc]
 
   '@img/sharp-libvips-linux-s390x@1.0.4':
     resolution: {integrity: sha512-u7Wz6ntiSSgGSGcjZ55im6uvTrOxSIS8/dgoVMoiGE9I6JAfU50yH5BoDlYA1tcuGS7g/QNtetJnxA6QEsCVTA==}
     cpu: [s390x]
     os: [linux]
-    libc: [glibc]
 
   '@img/sharp-libvips-linux-x64@1.0.4':
     resolution: {integrity: sha512-MmWmQ3iPFZr0Iev+BAgVMb3ZyC4KeFc3jFxnNbEPas60e1cIfevbtuyf9nDGIzOaW9PdnDciJm+wFFaTlj5xYw==}
     cpu: [x64]
     os: [linux]
-    libc: [glibc]
 
   '@img/sharp-libvips-linuxmusl-arm64@1.0.4':
     resolution: {integrity: sha512-9Ti+BbTYDcsbp4wfYib8Ctm1ilkugkA/uscUn6UXK1ldpC1JjiXbLfFZtRlBhjPZ5o1NCLiDbg8fhUPKStHoTA==}
     cpu: [arm64]
     os: [linux]
-    libc: [musl]
 
   '@img/sharp-libvips-linuxmusl-x64@1.0.4':
     resolution: {integrity: sha512-viYN1KX9m+/hGkJtvYYp+CCLgnJXwiQB39damAO7WMdKWlIhmYTfHjwSbQeUK/20vY154mwezd9HflVFM1wVSw==}
     cpu: [x64]
     os: [linux]
-    libc: [musl]
 
   '@img/sharp-linux-arm64@0.33.5':
     resolution: {integrity: sha512-JMVv+AMRyGOHtO1RFBiJy/MBsgz0x4AWrT6QoEVVTyh1E39TrCUpTRI7mx9VksGX4awWASxqCYLCV4wBZHAYxA==}
     engines: {node: ^18.17.0 || ^20.3.0 || >=21.0.0}
     cpu: [arm64]
     os: [linux]
-    libc: [glibc]
 
   '@img/sharp-linux-arm@0.33.5':
     resolution: {integrity: sha512-JTS1eldqZbJxjvKaAkxhZmBqPRGmxgu+qFKSInv8moZ2AmT5Yib3EQ1c6gp493HvrvV8QgdOXdyaIBrhvFhBMQ==}
     engines: {node: ^18.17.0 || ^20.3.0 || >=21.0.0}
     cpu: [arm]
     os: [linux]
-    libc: [glibc]
 
   '@img/sharp-linux-s390x@0.33.5':
     resolution: {integrity: sha512-y/5PCd+mP4CA/sPDKl2961b+C9d+vPAveS33s6Z3zfASk2j5upL6fXVPZi7ztePZ5CuH+1kW8JtvxgbuXHRa4Q==}
     engines: {node: ^18.17.0 || ^20.3.0 || >=21.0.0}
     cpu: [s390x]
     os: [linux]
-    libc: [glibc]
 
   '@img/sharp-linux-x64@0.33.5':
     resolution: {integrity: sha512-opC+Ok5pRNAzuvq1AG0ar+1owsu842/Ab+4qvU879ippJBHvyY5n2mxF1izXqkPYlGuP/M556uh53jRLJmzTWA==}
     engines: {node: ^18.17.0 || ^20.3.0 || >=21.0.0}
     cpu: [x64]
     os: [linux]
-    libc: [glibc]
 
   '@img/sharp-linuxmusl-arm64@0.33.5':
     resolution: {integrity: sha512-XrHMZwGQGvJg2V/oRSUfSAfjfPxO+4DkiRh6p2AFjLQztWUuY/o8Mq0eMQVIY7HJ1CDQUJlxGGZRw1a5bqmd1g==}
     engines: {node: ^18.17.0 || ^20.3.0 || >=21.0.0}
     cpu: [arm64]
     os: [linux]
-    libc: [musl]
 
   '@img/sharp-linuxmusl-x64@0.33.5':
     resolution: {integrity: sha512-WT+d/cgqKkkKySYmqoZ8y3pxx7lx9vVejxW/W4DOFMYVSkErR+w7mf2u8m/y4+xHe7yY9DAXQMWQhpnMuFfScw==}
     engines: {node: ^18.17.0 || ^20.3.0 || >=21.0.0}
     cpu: [x64]
     os: [linux]
-    libc: [musl]
 
   '@img/sharp-wasm32@0.33.5':
     resolution: {integrity: sha512-ykUW4LVGaMcU9lu9thv85CbRMAwfeadCJHRsg2GmeRa/cJxsVY9Rbd57JcMxBkKHag5U/x7TSBpScF4U8ElVzg==}
@@ -703,28 +700,24 @@ packages:
     engines: {node: '>= 10'}
     cpu: [arm64]
     os: [linux]
-    libc: [glibc]
 
   '@next/swc-linux-arm64-musl@15.2.2-canary.3':
     resolution: {integrity: sha512-tWh4LTrj091SrTdJV0bfLm+DO4F8esINqXhtIRsEiq9Ck2Lzf30N6jsgt26dyR3Jl/f359jXlr9zf7qvtaR5eQ==}
     engines: {node: '>= 10'}
     cpu: [arm64]
     os: [linux]
-    libc: [musl]
 
   '@next/swc-linux-x64-gnu@15.2.2-canary.3':
     resolution: {integrity: sha512-0kwYBkYluIu9QTp91AgdKZHVjIZmCFwLegaG0g9A2j1qaSM0qdkzYwKVG38PsZL2za/+F3U2pCoI+StS2rHanw==}
     engines: {node: '>= 10'}
     cpu: [x64]
     os: [linux]
-    libc: [glibc]
 
   '@next/swc-linux-x64-musl@15.2.2-canary.3':
     resolution: {integrity: sha512-9gPdS2o1mLUnazUkMNYxrrMKwggkcu2uETeZQbAqh8BgAeilOtbHYKDXTs1boXTJnXaOPuLHDbJ1b5jfKgrGLw==}
     engines: {node: '>= 10'}
     cpu: [x64]
     os: [linux]
-    libc: [musl]
 
   '@next/swc-win32-arm64-msvc@15.2.2-canary.3':
     resolution: {integrity: sha512-lUL2B4PildB+UYBrW8wM0Wg9DqySetfv1KQjzoBm7JMRrQIqv4yi8tMPe/vR6BW4Ho9bD7rncgcQ4TkwiME/Eg==}
@@ -1521,6 +1514,9 @@ packages:
   '@radix-ui/rect@1.1.0':
     resolution: {integrity: sha512-A9+lCBZoaMJlVKcRBz2YByCG+Cp2t6nAnMnNba+XiWxnj6r4JUFqfsgwocMBZU9LPtdxC6wB56ySYpc7LQIoJg==}
 
+  '@streamparser/json@0.0.22':
+    resolution: {integrity: sha512-b6gTSBjJ8G8SuO3Gbbj+zXbVx8NSs1EbpbMKpzGLWMdkR+98McH9bEjSz3+0mPJf68c5nxa3CrJHp5EQNXM6zQ==}
+
   '@swc/counter@0.1.3':
     resolution: {integrity: sha512-e2BR4lsJkkRlKZ/qCHPw9ZaSxc0MVUd7gtbtaB7aMvHeJVYe8sOB8DBZkP2DtISHGSku9sCK6T6cnY0CtXrOCQ==}
 
@@ -1565,28 +1561,24 @@ packages:
     engines: {node: '>= 10'}
     cpu: [arm64]
     os: [linux]
-    libc: [glibc]
 
   '@tailwindcss/oxide-linux-arm64-musl@4.0.12':
     resolution: {integrity: sha512-LmOdshJBfAGIBG0DdBWhI0n5LTMurnGGJCHcsm9F//ISfsHtCnnYIKgYQui5oOz1SUCkqsMGfkAzWyNKZqbGNw==}
     engines: {node: '>= 10'}
     cpu: [arm64]
     os: [linux]
-    libc: [musl]
 
   '@tailwindcss/oxide-linux-x64-gnu@4.0.12':
     resolution: {integrity: sha512-OSK667qZRH30ep8RiHbZDQfqkXjnzKxdn0oRwWzgCO8CoTxV+MvIkd0BWdQbYtYuM1wrakARV/Hwp0eA/qzdbw==}
     engines: {node: '>= 10'}
     cpu: [x64]
     os: [linux]
-    libc: [glibc]
 
   '@tailwindcss/oxide-linux-x64-musl@4.0.12':
     resolution: {integrity: sha512-uylhWq6OWQ8krV8Jk+v0H/3AZKJW6xYMgNMyNnUbbYXWi7hIVdxRKNUB5UvrlC3RxtgsK5EAV2i1CWTRsNcAnA==}
     engines: {node: '>= 10'}
     cpu: [x64]
     os: [linux]
-    libc: [musl]
 
   '@tailwindcss/oxide-win32-arm64-msvc@4.0.12':
     resolution: {integrity: sha512-XDLnhMoXZEEOir1LK43/gHHwK84V1GlV8+pAncUAIN2wloeD+nNciI9WRIY/BeFTqES22DhTIGoilSO39xDb2g==}
@@ -2294,6 +2286,18 @@ packages:
   jose@6.0.8:
     resolution: {integrity: sha512-EyUPtOKyTYq+iMOszO42eobQllaIjJnwkZ2U93aJzNyPibCy7CEvT9UQnaCVB51IAd49gbNdCew1c0LcLTCB2g==}
 
+  jotai@2.12.4:
+    resolution: {integrity: sha512-eFXLJol4oOLM8BS1+QV+XwaYQITG8n1tatBCFl4F5HE3zR5j2WIK8QpMt7VJIYmlogNUZfvB7wjwLoVk+umB9Q==}
+    engines: {node: '>=12.20.0'}
+    peerDependencies:
+      '@types/react': '>=17.0.0'
+      react: '>=17.0.0'
+    peerDependenciesMeta:
+      '@types/react':
+        optional: true
+      react:
+        optional: true
+
   js-base64@2.6.4:
     resolution: {integrity: sha512-pZe//GGmwJndub7ZghVHz7vjb2LgC1m8B07Au3eYqeqv9emhESByMXxaEgkUkEqJe87oBbSniGYoQNIBklc7IQ==}
 
@@ -2304,6 +2308,10 @@ packages:
   js-tokens@4.0.0:
     resolution: {integrity: sha512-RdJUflcE3cUzKiMqQgsCu06FPu9UdIJO0beYbPhHN4k6apgJtifcoCtT9bcxOpYBtpD2kCM6Sbzg4CausW/PKQ==}
 
+  jsonrepair@3.12.0:
+    resolution: {integrity: sha512-SWfjz8SuQ0wZjwsxtSJ3Zy8vvLg6aO/kxcp9TWNPGwJKgTZVfhNEQBMk/vPOpYCDFWRxD6QWuI6IHR1t615f0w==}
+    hasBin: true
+
   jstoxml@2.2.9:
     resolution: {integrity: sha512-OYWlK0j+roh+eyaMROlNbS5cd5R25Y+IUpdl7cNdB8HNrkgwQzIS7L9MegxOiWNBj9dQhA/yAxiMwCC5mwNoBw==}
 
@@ -2336,28 +2344,24 @@ packages:
     engines: {node: '>= 12.0.0'}
     cpu: [arm64]
     os: [linux]
-    libc: [glibc]
 
   lightningcss-linux-arm64-musl@1.29.2:
     resolution: {integrity: sha512-Q64eM1bPlOOUgxFmoPUefqzY1yV3ctFPE6d/Vt7WzLW4rKTv7MyYNky+FWxRpLkNASTnKQUaiMJ87zNODIrrKQ==}
     engines: {node: '>= 12.0.0'}
     cpu: [arm64]
     os: [linux]
-    libc: [musl]
 
   lightningcss-linux-x64-gnu@1.29.2:
     resolution: {integrity: sha512-0v6idDCPG6epLXtBH/RPkHvYx74CVziHo6TMYga8O2EiQApnUPZsbR9nFNrg2cgBzk1AYqEd95TlrsL7nYABQg==}
     engines: {node: '>= 12.0.0'}
     cpu: [x64]
     os: [linux]
-    libc: [glibc]
 
   lightningcss-linux-x64-musl@1.29.2:
     resolution: {integrity: sha512-rMpz2yawkgGT8RULc5S4WiZopVMOFWjiItBT7aSfDX4NQav6M44rhn5hjtkKzB+wMTRlLLqxkeYEtQ3dd9696w==}
     engines: {node: '>= 12.0.0'}
     cpu: [x64]
     os: [linux]
-    libc: [musl]
 
   lightningcss-win32-arm64-msvc@1.29.2:
     resolution: {integrity: sha512-nL7zRW6evGQqYVu/bKGK+zShyz8OVzsCotFgc7judbt6wnB2KbiKKJwBE4SGoDBQ1O94RjW4asrCjQL4i8Fhbw==}
@@ -4304,6 +4308,8 @@ snapshots:
 
   '@radix-ui/rect@1.1.0': {}
 
+  '@streamparser/json@0.0.22': {}
+
   '@swc/counter@0.1.3': {}
 
   '@swc/helpers@0.5.15':
@@ -5010,12 +5016,19 @@ snapshots:
 
   jose@6.0.8: {}
 
+  jotai@2.12.4(@types/react@19.0.10)(react@19.0.0):
+    optionalDependencies:
+      '@types/react': 19.0.10
+      react: 19.0.0
+
   js-base64@2.6.4: {}
 
   js-cookie@3.0.5: {}
 
   js-tokens@4.0.0: {}
 
+  jsonrepair@3.12.0: {}
+
   jstoxml@2.2.9: {}
 
   lightningcss-darwin-arm64@1.29.2:
diff --git a/types/analysis.ts b/types/analysis.ts
index 0de2d79..71e352a 100644
--- a/types/analysis.ts
+++ b/types/analysis.ts
@@ -15,6 +15,6 @@ export interface IMeeting {
     conclusion: string;
     summary: string;
     documentName: string;
-    isTripleOneMeeting: boolean;
+    isTiobMeeting: boolean;
     keyDecisionItems: IKeyDecisionItem[];
 }
\ No newline at end of file
